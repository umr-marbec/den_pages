[
  {
    "objectID": "pages/git/index_git.html",
    "href": "pages/git/index_git.html",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "Vous trouverez dans cette section tous les ressources en lien avec l’utilisation des systèmes de controle de version. Au niveau de l’UMR plusieurs forges sont utilisées, à savoir :\n\nGitHub MARBEC\nGitLab IRD\nGitLab Ifremer\n\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Système de contrôle de version"
    ]
  },
  {
    "objectID": "pages/liens.html",
    "href": "pages/liens.html",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "UMR MARBEC\n“Issues” du dépôt GitHub\nForum de discussion du dépôt GitHub\nULR du serveur rocket chat de l’UMR\nContact reférent(e)s du DEN\n\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/packages_logiciels/r_package_sparck.html",
    "href": "pages/packages_logiciels/r_package_sparck.html",
    "title": "Package R sparck",
    "section": "",
    "text": "Le package sparck est un package développé pour le logiciel R. Ses objectifs sont de fournir des fonctions et processus standradrisés permettant, de manière générale, d’appuyer le travail des personnes de l’UMR et pas extension de ses partenaires. Les fonctions associées vont aussi bien de sujets comme la manipulation de données, l’analyse de données ou encore la configuration de l’environnement de travail. Loin de l’idée d’aborder de manière exhaustive l’ensemble des thématiques ou sujets, sa vocation est vraiment d’apporter un standard en termes de développement afin d’améliorer la transversalité des actions et améliorer les liens associés.\nEn lien notamment avec la section “Je veux contribuer !”, n’hesitez pas à jeter un coup d’oeil à la documentation générale mais aussi la section issues du dépôt GitHub.",
    "crumbs": [
      "Liens utiles",
      "Packages et logiciels",
      "Package R sparck"
    ]
  },
  {
    "objectID": "pages/packages_logiciels/r_package_sparck.html#support-package-for-analysis-research-collaboration-and-knowledge",
    "href": "pages/packages_logiciels/r_package_sparck.html#support-package-for-analysis-research-collaboration-and-knowledge",
    "title": "Package R sparck",
    "section": "",
    "text": "Le package sparck est un package développé pour le logiciel R. Ses objectifs sont de fournir des fonctions et processus standradrisés permettant, de manière générale, d’appuyer le travail des personnes de l’UMR et pas extension de ses partenaires. Les fonctions associées vont aussi bien de sujets comme la manipulation de données, l’analyse de données ou encore la configuration de l’environnement de travail. Loin de l’idée d’aborder de manière exhaustive l’ensemble des thématiques ou sujets, sa vocation est vraiment d’apporter un standard en termes de développement afin d’améliorer la transversalité des actions et améliorer les liens associés.\nEn lien notamment avec la section “Je veux contribuer !”, n’hesitez pas à jeter un coup d’oeil à la documentation générale mais aussi la section issues du dépôt GitHub.",
    "crumbs": [
      "Liens utiles",
      "Packages et logiciels",
      "Package R sparck"
    ]
  },
  {
    "objectID": "pages/packages_logiciels/osmose.html",
    "href": "pages/packages_logiciels/osmose.html",
    "title": "Modèle Osmose",
    "section": "",
    "text": "OSMOSE est un modèle multi-espèces et basé sur l’individu (IBM) qui se concentre sur les espèces de poissons. Ce modèle suppose une prédation opportuniste basée sur la cooccurrence spatiale et l’adéquation de taille entre un prédateur et sa proie (prédation opportuniste basée sur la taille). Il représente des individus de poissons regroupés en bancs, caractérisés par leur taille, leur poids, leur âge, leur taxonomie et leur localisation géographique (modèle 2D), et qui subissent les principaux processus du cycle de vie des poissons (croissance, prédation explicite, mortalité naturelle et par inanition, reproduction et migration) et de l’exploitation par la pêche.\nLe modèle a besoin de paramètres biologiques de base qui sont souvent disponibles pour une large gamme d’espèces, et qui peuvent être trouvés dans FishBase par exemple, et de données sur la distribution spatiale des poissons. Ce paquetage fournit des outils pour construire un modèle et effectuer des simulations en utilisant le modèle OSMOSE.\nLe modèle est disponible sur GitHub.",
    "crumbs": [
      "Liens utiles",
      "Packages et logiciels",
      "Modèle Osmose"
    ]
  },
  {
    "objectID": "pages/packages_logiciels/osmose.html#simulateur-orienté-objet-des-écosystèmes-marins",
    "href": "pages/packages_logiciels/osmose.html#simulateur-orienté-objet-des-écosystèmes-marins",
    "title": "Modèle Osmose",
    "section": "",
    "text": "OSMOSE est un modèle multi-espèces et basé sur l’individu (IBM) qui se concentre sur les espèces de poissons. Ce modèle suppose une prédation opportuniste basée sur la cooccurrence spatiale et l’adéquation de taille entre un prédateur et sa proie (prédation opportuniste basée sur la taille). Il représente des individus de poissons regroupés en bancs, caractérisés par leur taille, leur poids, leur âge, leur taxonomie et leur localisation géographique (modèle 2D), et qui subissent les principaux processus du cycle de vie des poissons (croissance, prédation explicite, mortalité naturelle et par inanition, reproduction et migration) et de l’exploitation par la pêche.\nLe modèle a besoin de paramètres biologiques de base qui sont souvent disponibles pour une large gamme d’espèces, et qui peuvent être trouvés dans FishBase par exemple, et de données sur la distribution spatiale des poissons. Ce paquetage fournit des outils pour construire un modèle et effectuer des simulations en utilisant le modèle OSMOSE.\nLe modèle est disponible sur GitHub.",
    "crumbs": [
      "Liens utiles",
      "Packages et logiciels",
      "Modèle Osmose"
    ]
  },
  {
    "objectID": "pages/calendrier/calendrier.html",
    "href": "pages/calendrier/calendrier.html",
    "title": "Calendrier",
    "section": "",
    "text": "Calendrier\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Calendrier"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/index_marbec_data.html",
    "href": "pages/serveurs/marbec_data/index_marbec_data.html",
    "title": "Introduction à marbec-data",
    "section": "",
    "text": "marbec-data est un NFS. Un NFS est un protocole réseau qui permet à plusieurs appareils connectés à un réseau de partager des fichiers et des répertoires. Cela permet aux chercheurs de stocker leurs données d’entrée, leurs codes et leurs résultats, tout en bénéficiant d’une sauvegarde centralisée et de la possibilité d’accéder à leurs fichiers depuis n’importe quelle machine connectée au cluster.\nPour simplifier, et en reprenant l’analogie avec votre PC actuel, marbec-data prend la place du stockage (c’est-à-dire du disque dur) dans le HPC.\nD’un autre côté, un cluster de calcul est essentiellement un ensemble d’éléments informatiques interconnectés qui fonctionnent de manière coordonnée pour exécuter des processus de calcul complexes. Dans l’analogie avec votre PC, marbec-gpu correspond à votre processeur principal (CPU), à votre processeur graphique (GPU), à la mémoire RAM générale et à la mémoire vidéo. Bien sûr, ces simplifications laissent de côté certains détails importants que nous expliquerons plus en profondeur au fur et à mesure des besoins.\n\n\nCela dépend de ce que nous devons faire. Si nous voulons simplement jeter un coup d’œil rapide aux fichiers et vérifier certains aspects de notre compte, il suffit d’ouvrir une fenêtre de navigateur et de se rendre à l’adresse suivante : https://marbec-data.ird.fr/.\nUne interface de connexion apparaîtra, où nous devrons entrer nos identifiants (fournis par les administrateurs de marbec-gpu).\n\nUne fois connectés, nous verrons une sorte de bureau avec quelques icônes permettant d’accéder à nos répertoires partagés et à la documentation générale sur l’utilisation de la plateforme.\n\n\n\n\nCommencez par cliquer sur l’icône des options utilisateur (celle qui ressemble à une petite personne) en haut à droite du bureau, puis sélectionnez l’option Personnel.\n\nUne petite fenêtre s’ouvrira. Dans l’onglet affiché par défaut (Compte), vous aurez accès à l’option Changer le mot de passe.\nDans l’onglet Préférences d’affichage, vous pourrez également modifier certains paramètres, comme la langue de l’interface ou l’image et les couleurs du bureau.\n\n\n\n\nDepuis la même fenêtre Personnel mentionnée précédemment, dans l’onglet Quota, vous pourrez vérifier la limite de stockage qui vous est attribuée ainsi que l’espace utilisé dans chacun des dossiers associés à votre utilisateur.\nCela vous permet d’avoir une vue graphique simple de l’espace restant disponible.\nSi vous avez besoin de plus d’espace, vous pouvez en faire la demande par e-mail auprès des administrateurs de marbec-data.\n\n\n\n\n\n\n\nImportant\n\n\n\nSi, au cours de l’exécution d’un processus, la limite de quota allouée est atteinte, le système bloquera toute tentative d’enregistrement de fichiers, ce qui entraînera soit l’arrêt inopiné du processus, soit des erreurs liées aux problèmes d’écriture sur le disque.\n\n\n\n\n\nNous avons un article où nous développons ce point plus en détail.\n\n\n\n\n\n\nImportant\n\n\n\nIl est très important de définir des mots de passe robustes (composés de lettres, chiffres, symboles et majuscules/minuscules) et, de préférence, d’utiliser des mots de passe différents pour marbec-data et marbec-gpu.\nPar ailleurs, l’environnement JupyterLab permet d’utiliser les raccourcis classiques comme Ctrl+C-Ctrl+V (ou Cmd+C-Cmd+V sous macOS) pour copier-coller des chaînes de caractères. Il est donc possible de les utiliser lors du changement de mot de passe avec la commande passwd.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/index_marbec_data.html#comment-accéder-à-marbec-data",
    "href": "pages/serveurs/marbec_data/index_marbec_data.html#comment-accéder-à-marbec-data",
    "title": "Introduction à marbec-data",
    "section": "",
    "text": "Cela dépend de ce que nous devons faire. Si nous voulons simplement jeter un coup d’œil rapide aux fichiers et vérifier certains aspects de notre compte, il suffit d’ouvrir une fenêtre de navigateur et de se rendre à l’adresse suivante : https://marbec-data.ird.fr/.\nUne interface de connexion apparaîtra, où nous devrons entrer nos identifiants (fournis par les administrateurs de marbec-gpu).\n\nUne fois connectés, nous verrons une sorte de bureau avec quelques icônes permettant d’accéder à nos répertoires partagés et à la documentation générale sur l’utilisation de la plateforme.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/index_marbec_data.html#comment-changer-notre-mot-de-passe-dans-marbec-data",
    "href": "pages/serveurs/marbec_data/index_marbec_data.html#comment-changer-notre-mot-de-passe-dans-marbec-data",
    "title": "Introduction à marbec-data",
    "section": "",
    "text": "Commencez par cliquer sur l’icône des options utilisateur (celle qui ressemble à une petite personne) en haut à droite du bureau, puis sélectionnez l’option Personnel.\n\nUne petite fenêtre s’ouvrira. Dans l’onglet affiché par défaut (Compte), vous aurez accès à l’option Changer le mot de passe.\nDans l’onglet Préférences d’affichage, vous pourrez également modifier certains paramètres, comme la langue de l’interface ou l’image et les couleurs du bureau.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/index_marbec_data.html#vérifier-lespace-disponible-dans-marbec-data",
    "href": "pages/serveurs/marbec_data/index_marbec_data.html#vérifier-lespace-disponible-dans-marbec-data",
    "title": "Introduction à marbec-data",
    "section": "",
    "text": "Depuis la même fenêtre Personnel mentionnée précédemment, dans l’onglet Quota, vous pourrez vérifier la limite de stockage qui vous est attribuée ainsi que l’espace utilisé dans chacun des dossiers associés à votre utilisateur.\nCela vous permet d’avoir une vue graphique simple de l’espace restant disponible.\nSi vous avez besoin de plus d’espace, vous pouvez en faire la demande par e-mail auprès des administrateurs de marbec-data.\n\n\n\n\n\n\n\nImportant\n\n\n\nSi, au cours de l’exécution d’un processus, la limite de quota allouée est atteinte, le système bloquera toute tentative d’enregistrement de fichiers, ce qui entraînera soit l’arrêt inopiné du processus, soit des erreurs liées aux problèmes d’écriture sur le disque.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/index_marbec_data.html#comment-gérer-les-fichiers-dans-marbec-data-ou-entre-marbec-data-et-notre-pc",
    "href": "pages/serveurs/marbec_data/index_marbec_data.html#comment-gérer-les-fichiers-dans-marbec-data-ou-entre-marbec-data-et-notre-pc",
    "title": "Introduction à marbec-data",
    "section": "",
    "text": "Nous avons un article où nous développons ce point plus en détail.\n\n\n\n\n\n\nImportant\n\n\n\nIl est très important de définir des mots de passe robustes (composés de lettres, chiffres, symboles et majuscules/minuscules) et, de préférence, d’utiliser des mots de passe différents pour marbec-data et marbec-gpu.\nPar ailleurs, l’environnement JupyterLab permet d’utiliser les raccourcis classiques comme Ctrl+C-Ctrl+V (ou Cmd+C-Cmd+V sous macOS) pour copier-coller des chaînes de caractères. Il est donc possible de les utiliser lors du changement de mot de passe avec la commande passwd.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/index_marbec_gpu.html",
    "href": "pages/serveurs/marbec_gpu/index_marbec_gpu.html",
    "title": "Documentation Marbec-GPU",
    "section": "",
    "text": "Bienvenue dans la documentation du cluster Marbec-GPU. Ce document fournit un aperçu du cluster, de ses capacités et des guides disponibles pour apprendre à bien l’utiliser.\nLe cluster Marbec-GPU est conçu pour fournir des ressources informatiques de hautes performances pour l’exécution de code, Python et R notamment. Il est basé sur le noyau Linux-Ubuntu et dispose d’une interface Jupyter pour faciliter son utilisation. Plusieurs outils y sont installés, notamment Python, R, Git, Conda, CUDA et RStudio.\n\n\n\nRessources\n\n2 NVIDIA A40 GPUs\n2 Intel Xeon Platinum 8380 CPUs, 2x40 cores, 2x80 threads\n1,48 To de RAM\nInterconnexions MARBEC-DATA\n\n\n\n\n\nPour commencer à utiliser le cluster Marbec-GPU, vous devrez rejoindre le groupe Marbec-DEN. Contactez les Administrateurs pour plus de détails : Contacts administrateurs DEN\n\n\n\nPour des instructions détaillées sur l’utilisation du cluster Marbec-GPU, veuillez vous référer aux sections suivantes :\n\nGuide d’initiation (arrive bientôt)\nGuide des Commandes Linux utiles (english only)\nExécution d’un Script Basique R/Python (via SLURM)\nExécution R (english only)\n\n\n\n\nSi vous rencontrez des problèmes ou avez des questions, veillez intéragir avec le RocketChatIRD.\n\n\n\n\nDe quelles ressources ai-je besoin d’allouer?\n\nBonne question ! Cela dépend de vos données d’entrée (taille et type), de votre modèle (stochastique, statistique, réseau de neurones, etc.), de votre tâche mais surtout des packages utilisés. Par exmple, certains packages ne permettent pas de faire les calculs sur GPU, d’autres ne peuvent pas paralléliser sur plusieurs CPU. Renseigner vous donc sur les packages pour ne pas allouer des ressources qui ne seront pas utlisées et adaptez vos script en conséquent. Quelques exemples d’allocation : Entraînement Pytorch YOLO : --mem=64G, --c=16 et --gres=gpu:1 ; Exécution HSMC (TensorFlow) : --mem=64GB, --cpus-per-task=30 et --gpus-per-node=1\n\nMon script est-il compatible GPU ?\n\nNon, pas directement. Cependant, certaines bibliothèques sont compatibles GPU. Si votre framework ou script n’utilise pas spécifiquement le GPU, votre code NE tirera PAS parti du matériel GPU. Principaux exemples de bibliothèques compatibles GPU : PyTorch, TensorFlow, Keras, Theano, Caffe, etc.\n\nComment annuler un job soumis ?\n\nUtilisez la commande scancel JOBID, où JOBID est l’identifiant du job que vous souhaitez annuler. Vous pouvez trouver l’identifiant du job dans la sortie de la commande sbatch lorsque vous soumettez un job, ou en utilisant la commande squeue comme mentionné dans la question précédente, pour plus de details documentation SLURM scancel.\n\nComment accéder à la file d’attente des jobs ?\n\nUtilisez la commande suivante : squeue -O NAME,UserName,TimeUsed,tres-per-node,state,JOBID. Cette commande affiche une liste détaillée des jobs en attente, y compris le nom du job (par exemple, spawner-jupyterhub dessigne une “session-job”; sinon, le nom spécifié dans l’argument #SBATCH --job-name), le nom d’utilisateur, le temps d’exécution, le nom du noeud (eg., gres:gpu:1 pour une allocation GPU, gres:gpu:0 pour une allocation CPU), l’état du job (par exemple, PENDING pour les jobs en attente de démarrage en raison de la disponibilité des ressources ou de la planification, ou RUNNING pour les jobs en cours d’exécution) et JOBID (un identifiant unique pour chaque job), se référer à la documentation SLURM squeue pour plus de détails.\n\nComment soumettre plusieurs jobs sans bloquer les autres utilisateurs ?\n\nToute la communauté MarbecGPU vous remercie pour votre démarche coopérative et amicale. Vous pouvez utiliser le paramètre #SBATCH --dependency=afterany:JOBID, où JOBID est l’identifiant du job que vous souhaitez attendre (par exemple, 4391). Vous pouvez trouver l’identifiant du job dans la sortie de la commande sbatch lorsque vous soumettez un job, ou en utilisant la commande squeue comme mentionné dans la question précédente. Selon la documentation SLURM sbatch ce paramètre garantit que le démarrage de votre job est différé jusqu’à ce que la dépendance spécifiée soit satisfaite. Pour des dépendances basées sur des fichiers ou des cas plus complexes, vous pouvez explorer d’autres mécanismes pour retarder ou séquencer l’exécution de votre job selon vos besoins.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#caractéristiques",
    "href": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#caractéristiques",
    "title": "Documentation Marbec-GPU",
    "section": "",
    "text": "Ressources\n\n2 NVIDIA A40 GPUs\n2 Intel Xeon Platinum 8380 CPUs, 2x40 cores, 2x80 threads\n1,48 To de RAM\nInterconnexions MARBEC-DATA",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#inscription",
    "href": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#inscription",
    "title": "Documentation Marbec-GPU",
    "section": "",
    "text": "Pour commencer à utiliser le cluster Marbec-GPU, vous devrez rejoindre le groupe Marbec-DEN. Contactez les Administrateurs pour plus de détails : Contacts administrateurs DEN",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#documentation",
    "href": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#documentation",
    "title": "Documentation Marbec-GPU",
    "section": "",
    "text": "Pour des instructions détaillées sur l’utilisation du cluster Marbec-GPU, veuillez vous référer aux sections suivantes :\n\nGuide d’initiation (arrive bientôt)\nGuide des Commandes Linux utiles (english only)\nExécution d’un Script Basique R/Python (via SLURM)\nExécution R (english only)",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#support",
    "href": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#support",
    "title": "Documentation Marbec-GPU",
    "section": "",
    "text": "Si vous rencontrez des problèmes ou avez des questions, veillez intéragir avec le RocketChatIRD.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#faq",
    "href": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#faq",
    "title": "Documentation Marbec-GPU",
    "section": "",
    "text": "De quelles ressources ai-je besoin d’allouer?\n\nBonne question ! Cela dépend de vos données d’entrée (taille et type), de votre modèle (stochastique, statistique, réseau de neurones, etc.), de votre tâche mais surtout des packages utilisés. Par exmple, certains packages ne permettent pas de faire les calculs sur GPU, d’autres ne peuvent pas paralléliser sur plusieurs CPU. Renseigner vous donc sur les packages pour ne pas allouer des ressources qui ne seront pas utlisées et adaptez vos script en conséquent. Quelques exemples d’allocation : Entraînement Pytorch YOLO : --mem=64G, --c=16 et --gres=gpu:1 ; Exécution HSMC (TensorFlow) : --mem=64GB, --cpus-per-task=30 et --gpus-per-node=1\n\nMon script est-il compatible GPU ?\n\nNon, pas directement. Cependant, certaines bibliothèques sont compatibles GPU. Si votre framework ou script n’utilise pas spécifiquement le GPU, votre code NE tirera PAS parti du matériel GPU. Principaux exemples de bibliothèques compatibles GPU : PyTorch, TensorFlow, Keras, Theano, Caffe, etc.\n\nComment annuler un job soumis ?\n\nUtilisez la commande scancel JOBID, où JOBID est l’identifiant du job que vous souhaitez annuler. Vous pouvez trouver l’identifiant du job dans la sortie de la commande sbatch lorsque vous soumettez un job, ou en utilisant la commande squeue comme mentionné dans la question précédente, pour plus de details documentation SLURM scancel.\n\nComment accéder à la file d’attente des jobs ?\n\nUtilisez la commande suivante : squeue -O NAME,UserName,TimeUsed,tres-per-node,state,JOBID. Cette commande affiche une liste détaillée des jobs en attente, y compris le nom du job (par exemple, spawner-jupyterhub dessigne une “session-job”; sinon, le nom spécifié dans l’argument #SBATCH --job-name), le nom d’utilisateur, le temps d’exécution, le nom du noeud (eg., gres:gpu:1 pour une allocation GPU, gres:gpu:0 pour une allocation CPU), l’état du job (par exemple, PENDING pour les jobs en attente de démarrage en raison de la disponibilité des ressources ou de la planification, ou RUNNING pour les jobs en cours d’exécution) et JOBID (un identifiant unique pour chaque job), se référer à la documentation SLURM squeue pour plus de détails.\n\nComment soumettre plusieurs jobs sans bloquer les autres utilisateurs ?\n\nToute la communauté MarbecGPU vous remercie pour votre démarche coopérative et amicale. Vous pouvez utiliser le paramètre #SBATCH --dependency=afterany:JOBID, où JOBID est l’identifiant du job que vous souhaitez attendre (par exemple, 4391). Vous pouvez trouver l’identifiant du job dans la sortie de la commande sbatch lorsque vous soumettez un job, ou en utilisant la commande squeue comme mentionné dans la question précédente. Selon la documentation SLURM sbatch ce paramètre garantit que le démarrage de votre job est différé jusqu’à ce que la dépendance spécifiée soit satisfaite. Pour des dépendances basées sur des fichiers ou des cas plus complexes, vous pouvez explorer d’autres mécanismes pour retarder ou séquencer l’exécution de votre job selon vos besoins.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/basic_command.html",
    "href": "pages/serveurs/marbec_gpu/basic_command.html",
    "title": "Main commands in marbec-gpu Terminal",
    "section": "",
    "text": "Main commands in marbec-gpu Terminal\nThe first thing to keep in mind is that marbec-gpu has Ubuntu installed, so the commands listed below will be the same as the ones used in that OS. This article will show a description of the main usage modes for each command, but if you have any additional requirements, you can always search in forums like Stackoverflow or check the help for each command, which consists of placing the command name followed by --help. For example, if I want to know the help for the ls command, just run ls --help in the Terminal.\n\n\n\n\n\n\nUpper and lower case\n\n\n\nAs in R or Python, the use of upper or lower case when indicating an option does matter. For example, ls -D is not equivalent to ls -d, so be carefull.\n\n\n\nBrowsing within folders\n\nCommand: cd\nUsage: cd path/folder\n\nTo indicate a previous position (folder), you will use the statement .. as follows: ../path/folder1 (this indicates that there is a folder called path from the folder where you are, and that that has a folder called folder1 as well).\n\n\nCreate a folder\n\nCommand: mkdir\nUsage: mkdir path/folder\n\n\n\nGet the content of a folder as a list\n\nCommand: ls\nUsage: ls path/folder/\n\nMain options:\n\n--all (o -a): Displays all files and subfolders, including those protected (hidden) by the system.\n\n\n\nGenerate a list of files/folders and display the size of each item\n\nCommand: du\nUsage: du path/to/file.csv o du path/to/folder\n\nMain options:\n\n--human-readable (o -h): changes the units dynamically to avoid displaying all Kb. This is especially useful when you have large objects (subfolders or files).\n--summary (o -s): displays a summary table, i.e. it only includes the subfolders and files present at the first search level. This is useful when we just want to take a quick look and avoid displaying a complete listing of ALL internal subfolders.\n\nIf I want to get a list of all the files and folders inside a folder with their respective sizes (the three options are equivalent):\ndu ruta/de/folder/* --human-readable --summarize\ndu ruta/de/folder/* -h -s\ndu ruta/de/folder/* -hs\n\n\nCopy-paste\nFor this, the simplest way is through the cp command and making use of the navigation commands cited in this post (e.g. .. to indicate a previous folder). The basic syntax is the following: cp path/origin /path/destination, but there are different possible cases:\n\nCopy a file into the same folder, but with a different name (create duplicate): cp file1.csv file1-dup.csv.\nCopy a file to another folder: cp path/file1.csv path/destination.\nCopy more than one file to another folder: cp path/file1.csv path/file2.csv folder/destination\nCopy a folder to another folder: cp path/folder1 path/folder2 --recursive or cp path/folder1 path/folder2 -r.\n\n\n\n\n\n\n\nNote\n\n\n\nBy default, cp will overwrite any file with the same name. To avoid this, it is possible to add the -n option as follows: cp path/from/file1.csv path/destination -n.\n\n\n\n\nCut-paste (and also rename)\nIt will be very similar to the above, but through the mv command:\n\nRename a file (within the same folder): mv file1.csv file2.csv\nMove a file to another folder: mv path/file1.csv path/to/destination\nMove one file to another folder: mv path/file1.csv path/file2.csv path/destination\nMove one folder to another folder: mv path/old/folder path/new/folder\n\n\n\nDelete\nFor this, we will use the rm command as follows:\n\nDelete a file: rm path/to/file.csv\nDelete a folder (and all its contents): rm path/to/folder -r\n\n\n\n\n\n\n\nNo turning back\n\n\n\nWhile inside Terminal it is always possible to cancel a command using the shortcut Ctrl+C (or Cmd+C on MacOS), once the rm command completes its work, there is no way to revert the deletion or recover it from a recycle garbage can, so be very careful when using it.\n\n\n\n\nDisplay current processes\n\nCommand: top\n\nWhen you run it, it will show in interactive mode in Terminal the processes that are running, as well as the resources used by each of them (basically like a Task Manager). To exit this interactive mode, just press the q key.\n\n\nStop a process\nIf we want to force the closing or the cancellation of a process already started, we can use the shortcut Ctrl+C (or Cmd+C in MacOS). It is important to keep in mind that forcing the closing of a process that had in progress the handling of files or folders (creation, copy, etc.) can leave the generated files unusable.\n\n\nViewing a plain text file\nBy default, there are two tools available from Terminal: vi and nano. The syntax for their execution is as simple as vi path/file1.txt or nano path/file1.txt, where file1.txt can be any plain text file (e.g. an R or Python script). The navigation shortcuts within each of these environments are different, but documentation is abundant on the Internet. Choose the one you like best.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Guide des Commandes Utiles"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/marbec-data_folders.html",
    "href": "pages/serveurs/marbec_gpu/marbec-data_folders.html",
    "title": "🚀 Accéder aux dossiers de MARBEC-DATA dans JupyterHub",
    "section": "",
    "text": "Le serveur MARBEC-DATA est dédié au stockage des données et est connecté au serveur MARBEC-GPU, qui sert pour les calculs.\nLes dossiers stockés dans MARBEC-DATA sont toujours accessibles en ligne de commande\n🔍 Vous pouvez voir les dossiers disponibles en tapant :\nls /marbec-data/\nou naviguer directement vers un dossier spécifique :\ncd /marbec-data/&lt;your_folder&gt;\nCependant, ces dossiers n’apparaissent pas directement dans l’arborescence des fichiers.\nPour les voir dans l’explorateur de fichiers de Jupyter, il faut créer un lien symbolique.\n\n\n\nOuvrir un terminal dans JupyterHub.\nSe positionner dans l’endroit où vous voulez voir apparaître le dossier :\n\ncd /home/your_username/\n\nCréer le lien symbolique, le nom de votre dossier dans MARBEC-DATA :\n\nln -s /marbec-data/&lt;your_folder&gt;\n\nActualiser l’interface de Jupyter pour voir le dossier apparaître.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Accéder aux dossiers de MARBEC-DATA"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/marbec-data_folders.html#créer-un-lien-symbolique",
    "href": "pages/serveurs/marbec_gpu/marbec-data_folders.html#créer-un-lien-symbolique",
    "title": "🚀 Accéder aux dossiers de MARBEC-DATA dans JupyterHub",
    "section": "",
    "text": "Ouvrir un terminal dans JupyterHub.\nSe positionner dans l’endroit où vous voulez voir apparaître le dossier :\n\ncd /home/your_username/\n\nCréer le lien symbolique, le nom de votre dossier dans MARBEC-DATA :\n\nln -s /marbec-data/&lt;your_folder&gt;\n\nActualiser l’interface de Jupyter pour voir le dossier apparaître.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Accéder aux dossiers de MARBEC-DATA"
    ]
  },
  {
    "objectID": "pages/formations/git.html",
    "href": "pages/formations/git.html",
    "title": "Atelier Git",
    "section": "",
    "text": "Atelier Git\nLe code source de la formation Git est accessible sur GitHub. La formation est accessible ci-dessous.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Formations",
      "Formation Git"
    ]
  },
  {
    "objectID": "pages/formations/tidyverse.html",
    "href": "pages/formations/tidyverse.html",
    "title": "Formation tidyverse",
    "section": "",
    "text": "Formation tidyverse\nLe code source de la formation tidyverse est accessible sur le dépot GitHub. La présentation associée est disponible à l’adresse suivante.\nUne prochaine session devrait avoir lieu courant 2025 et des précisions seront communiquées ultérieurement.\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Formations",
      "Formation Tidyverse"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bienvenue !",
    "section": "",
    "text": "Bienvenue !\nL’objectif de ce site est de centraliser et mettre facilement à disposition des ressources informatiques, procédures et autres supports permettant d’appuyer de manière globale les travaux des personnelles et personnes associées de l’UMR MARBEC. Cette structuration s’appuie notamment sur Dispositif d’Ecologie Numérique, ou DEN, qui est une structure transversale associée à l’UMR. Ces missions sont la mise en place, la coordination et la mutualisation des moyens techniques ainsi que l’échange de méthodologies et de nouvelles approches en support aux aspects numériques des travaux de recherche scientifique.\nVous disposez aussi d’une section Issues vous permettant par exemple de faire remonter un problème dans le code source du site ou encore proposer une amélioration ou du contenu. Ces “GitHub Issues” sont vraiment à voir comme des objets s’apparentent davantage à des éléments « à faire » et sont axées sur les tâches à accomplir (par exemple via la création de branche dédié au sujet).\nDe plus, vous trouverez un forum de discussion afin d’échanger sur des sujets ou des problématiques communes. Les discussions sont destinées aux conversations qui doivent être transparentes et accessibles, mais qui n’ont pas besoin d’être suivies sur un projet et qui ne sont pas liées au code, contrairement aux “GitHub Issues”.\nPour information, l’UMR dispose aussi d’un serveur Rocket chat accessible via l’URL suivante https://tchat.ird.fr/home. Il est possible d’accéder à l’espace de travail directement depuis l’URL ou en installant un client lourd (=logiciel) sur votre ordinateur et en ajoutant l’URL dans la section “add workspace”.\nPar ailleurs, afin de faciliter l’accès et l’utilisation par le plus grand nombre, vous trouverez ce site et les ressources associées en français (par défaut) mais aussi en anglais (utilisez le bouton à gauche de barre de recherche pour changer de langue).\nN’hésitez pas visiter aussi la section “Je veux contribuer !” si vous disposez de ressources susceptibles d’alimenter celles disponibles via ce site ou même de manière générale si vous voulez contribuer à la mise a disposition de ressources communes.\nEn cas de besoin spécifique, vous pouvez contacter les représentant(e)s et référent(e)s du DEN à l’adresse suivante : marbec-den-admin@listes.ird.fr\nPour information, ce site a été généré via le système de publication Quarto.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/support/index_support.html",
    "href": "pages/support/index_support.html",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "Cette section est dédiée aux procédures et processus permettant d’apporter un support global aux personnelles de l’UMR. Cela va aussi bien de l’aide à la configuration de certains logiciels (comme les clients lourds de messagerie) ou encore des processus plus généraux comme la mise en place de solution de sauvegarde quotidienne ou encore par exemple des suggestions pour la gestion des mots de passe.\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Support global"
    ]
  },
  {
    "objectID": "pages/formations/index_formations.html",
    "href": "pages/formations/index_formations.html",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "Cette section est dédié à référencer les formations et supports associés mis à disposition de l’UMR et de ses partenaires. En lien avec le caractère spécifique des formations, il est possible que les supports associés ne soient pas disponibles en plusieurs langues. Par ailleurs en suivante ce lien à définir vous trouverez une liste des formations dispensée par l’UMR et surtout les prochaines dates de réalisation.\nPour information, la plupart des sous-sections suivantes renvoi vers des dépôts Git ou sont stockées sur les ressources des formations. Si vous avez des questions en rapport avec ces dernières, le mieux est d’utiliser les services mis à disposition du dépôt (la section “Issues” par exemple) ou à défaut de contacter directement la ou les personnes-ressources associées.\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Formations"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/intro_marbec_gpu.html",
    "href": "pages/serveurs/marbec_gpu/intro_marbec_gpu.html",
    "title": "Initiation au cluster de calcul Marbec-GPU",
    "section": "",
    "text": "Initiation au cluster de calcul Marbec-GPU\nUne video de présentation du cluster sera bientôt disponible.\n\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Initiation"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/basic_example.html",
    "href": "pages/serveurs/marbec_gpu/basic_example.html",
    "title": "Exécuter un exemple simple sur Marbec-GPU",
    "section": "",
    "text": "Tout au long de ce tutoriel, vous trouverez tout ce dont vous avez besoin pour éxécuter un script Python ou R ( afficher “Hello World &lt;3”), ainsi que des conseils et des ressources supplémentaires qui vous seront utiles pour d’autres tâches sur MARBEC-GPU.\nIl y a deux grandes manières pour exécuter un programme sur Marbec-GPU. La première est d’utiliser un script de soumission de tâche, la deuxième est d’utiliser la session de manière intéractive. Dans cet exemple, nous allons utiliser la première méthode qui est de loin la plus adpatée et facilment adaptable pour des programme plus complexe.\n\n\n\n\n\n\nNote\n\n\n\nLorque vous voudrez exécuter un programme plus complexe, assurez-vous que votre projet fonctionne localement (sur votre ordinateur personnel). Cela signifie configurer votre environnement correctement et déboguer votre script localement. Une fois que tout fonctionne avec succès sur votre PC (même en utilisant seulement 1% de l’ensemble de données si vous rencontrez des contraintes de calcul), vous pouvez ensuite déployer votre projet sur MARBEC-GPU.\n\n\nCommencez par créer un dossier de travail dans lequel les différents fichiers seront créés. En commande bash cela donnerait :\ncd ~  # aller dans le répertoire personnel\nmkdir mon_projet_python  # créer un dossier pour le projet\nSinon il est possible d’utliser l’interface Jupyter pour créer un dossier de travail avec l’icone encadrée en rouge ci-dessous :\n\n\n\nCréer un dossier de travail\n\n\nPlacez vous ensuite dans ce dossier ( cd mon_projet_python/ ou doucle clic sur le dossier visible sur la gauche de l’interphace).",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Soumission SLURM  : Exemple R/Python Basique"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/basic_example.html#préparer-le-script-python-ou-r",
    "href": "pages/serveurs/marbec_gpu/basic_example.html#préparer-le-script-python-ou-r",
    "title": "Exécuter un exemple simple sur Marbec-GPU",
    "section": "1. Préparer le script Python ou R",
    "text": "1. Préparer le script Python ou R\nCréez un script python ou R simple qui affiche “Hello World &lt;3”. Voici un exemple de script :\nprint(\"Hello World &lt;3\")\nEnregistrez ce script dans un fichier nommé main.py ou main.R (en fonction du languge voulu) dans le dossier de travail que vous avez créé précédemment.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Soumission SLURM  : Exemple R/Python Basique"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/basic_example.html#préparer-un-script-bash-avec-les-arguments-slurm",
    "href": "pages/serveurs/marbec_gpu/basic_example.html#préparer-un-script-bash-avec-les-arguments-slurm",
    "title": "Exécuter un exemple simple sur Marbec-GPU",
    "section": "2. Préparer un script Bash avec les arguments SLURM",
    "text": "2. Préparer un script Bash avec les arguments SLURM\nAfin de d’exécuter correctement le script vous aurez besion de créer un script bash launch.sh en prenant soin de mentionner :\n\nles arguments SLURM, permmant de spécifier quelles ressources allouer, le nom du job, le fichier de sortie, etc.\nl’exécution du script Python/R.\n\nVoici un exemple minimal de script bash :\n#!/bin/bash\n\n#SBATCH --job-name=my_job         # Job name\n#SBATCH --output=job_%j.out`      # Standard output and error log\n#SBATCH --gres=gpu:1             # Number of GPUs (Supprimer la ligne si aucun GPU n’est requis.)\n#SBATCH --mem=4G                  # Memory allocation (4 GB)\n#SBATCH -c 1                      # Number of CPU cores\n\n# execute python file\npython main.py                    \n\n# execute R file\nRscript main.R\nIl possible de spécifier d’autres arguments SLURM. Pour plus d’informations sur les arguments SLURM, vous pouvez consulter la documentation officielle de SLURM ici.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Soumission SLURM  : Exemple R/Python Basique"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/basic_example.html#exécuter-le-script-bash",
    "href": "pages/serveurs/marbec_gpu/basic_example.html#exécuter-le-script-bash",
    "title": "Exécuter un exemple simple sur Marbec-GPU",
    "section": "3. Exécuter le script Bash",
    "text": "3. Exécuter le script Bash\nA l’issu des 2 étapes précédentes, le dossier de travail devrait contenir les fichiers suivants : launch.sh et main.py/main.R :  La dernière étape consiste à soumettre votre script launch.sh créé à la partie précédente. Pour cela vous devez utiliser la commande sbatch (voir documentation).\nDans le terminal, exécutez la commande suivante : &gt; sbatch launch.sh\nSi les parramètres SLURM (#SBATCH arg) sont bien renseignés, vous devriez voir un message de confirmation de soumission de votre job : Submitted batch job 1234567. Sinon un message d’erreur s’affiche à la place. Lors d’une soumission réussie, SLURM regarde les ressources demandées et place le job en file d’attente ( état PENDING) tant que les ressources ne sont pas disponibles. Une fois les ressources disponibles, le job s’exécute (état RUNNING). Un fichier de sortie est alors créé dans le répertoire courant avec le nom renseigné dans le script bash (#SBATCH --output=job_%j.out). Un deuxième fichier contenant les messages d’erreur peut apparaître si cela est spécifié (#SBATCH --error=job_%j.err).\nIl est possible de suivre l’avancement de votre job avec la commande squeue -u $USER ou squeue -j 1234567 (avec 1234567 le numéro de votre job). Mais aussi de lister tous les jobs en cours d’exécution ou en file d’attente avec squeue -O NAME,UserName,TimeUsed,tres-per-node,state,JOBID. La colonne STATE notamment indique l’état du job (PENDING RUNNING). Pour plus de détail sur la command squeue vous pouvez consulter la documentation.\nPour annuler un job (en cours d’éxecution ou encore en file d’attente), utilisez la commande scancel 1234567 (avec 1234567 le numéro de votre job).\nLe fichier output.log contenant les sorties de votre script python est créé dans le répertoire courant. Vous pouvez le consulter avec la commande cat output.log ou simplement en double-cliquant dessus. Si tout s’est bien passé, le fichier doit ressembler à ceci :\nHello World &lt;3",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Soumission SLURM  : Exemple R/Python Basique"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/run_r_script.html",
    "href": "pages/serveurs/marbec_gpu/run_r_script.html",
    "title": "Running R scripts in marbec-gpu",
    "section": "",
    "text": "As when working with RStudio locally (i.e. on our PC), it is recommended to clearly define our working directory. This is extremely important because any process we run (either from RStudio or Terminal) will use that directory as a reference to find input files, output files or even other scripts.\nFor our case, we have created a folder called mgpu-examples/ where there is a subfolder called code/. The creation of folders in marbec-data can be done directly from the web interface (by clicking on File station and then using the Create folder button), the command mkdir, but we can also copy-paste the elements already existing in our PC into the working folder.\n\n\n\nThe following is NOT mandatory, but very useful, especially when working with RStudio and that is to create an RStudio project. To do this, we will go to File and then New Project.\n\nThen, in the window that appears, click on Existing directory, then on Browse and click on the folder that we have defined as our working directory (in our case, mgpu-examples/). Then, OK and finally click on the Create Project button. Rstudio will flicker a little bit and then will show us the same window, but inside the set project. The easiest way to check that the project has been created in the correct folder (mgpu-examples/ in our case) is to verify that right in the Console panel, to the right of the R version, appears only the path of our main folder (and not any of the subfolders, e.g. mgpu-examples/code/ or mgpu-examples/inputs/).\n\n\n\n\n\n\n\nJust before to say hello\n\n\n\nmarbec-gpu incorporates the possibility of working with RStudio (Server); however, this interface should be used ONLY to PREPARE our scripts before being executed using all the power of our server. In other words, within the RStudio environment we will be able to load not so big files and perform basic operations, but at no time should we execute a complex (heavy) process from there, but from Terminal.\n\n\n\n\n\n\n\n\nWe will start with the simplest: create a script in R and print the (very famous) “Hello world!” message.\n\nWe will start by opening an RStudio session from the JupyterLab environment (if you want to know how to get there, check the post of Introduction to marbec-gpu).\nOnce inside the RStudio environment, we will create a new script (File -&gt; New file -&gt; R script) which will contain a single line:\n\n\nprint(\"Hello world and hello marbec-gpu!\")\n\nThen, we will save that script with the name code/ex1-1.R (code/ refers to a subfolder created previously inside the working directory of our project in RStudio).\nNow comes the interesting part, inside our browser, we must go back to the Launcher tab and open a Terminal window (clicking on the corresponding icon).\nBy default, Terminal will open a session in the local folder assigned to our user. From there, we must get to the folder we have set as working directory; that is, the folder that our script will recognize as working directory (whether we have decided to use RStudio or not to create it or create a project inside it). Assuming that our working directory is the mgpu-examples/ folder, we must reach it using the cd command:\n\ncd mgpu-examples/\n\n\n\n\n\n\nHow do we know that we have arrived at the correct folder?\n\n\n\nFirst, the prompt will indicate the name of the folder in which it is located.\n\nIn addition, we can run the ls command which will show the subfolders and files inside the folder we have reached. If everything matches, then we did well.\n\n\n\n\nNext, we execute the following command in the Terminal: Rscript code/ex1-1.R and the result should be just what would be shown in a usual R session.\n\n\n\n\n\nIn this next example, we will show a script that generates and saves files in our working directory where previously, we will create two new folders (figures/ and outputs/) through the mkdir command as follows:\nmkdir figures/ outputs/\n\n\n\n\n\n\nNote\n\n\n\nWithin the Terminal environment, it is not possible to observe graphics interactively (as in RStudio), so if you want to keep any figure, you must always include the code to save it within the script you execute. Depending on the graphical environment, we can use functions such as png, bmp, jpeg, pdf (for graphics environment), or ggsave (for ggplot2 environment).\n\n\n\nNow, let’s go to RStudio to create the following script and save it in code/ex1-2.R:\n\n# Print mtcars\nprint(mtcars)\n\n# Export mtcars as a csv\nwrite.csv(x = mtcars, file = \"outputs/mtcars.csv\")\n \n# Create and save a scatterplot\npng(filename = \"figures/fig_1-1.png\")\n\nplot(x = mtcars$mpg, y = mtcars$disp, \n     xlab = \"Miles per (US) gallon\", ylab = \"Displacement (cu.in.)\")\n\ndev.off()\n\nNext, we go back to the Terminal environment and run our new script with the command Rscript code/ex1-2.R. Immediately, the mtcars table will be displayed as that is what the first line of our script commands.\n\n\n\nHowever, if we run the ls command in Terminal for the figures/ and outputs/ folders, we will see that the two files we ordered to be created inside our script appear.\n\n\n\nIf the files created are the ones we expect to collect from our analysis, we can download them through Filezilla (see the corresponding post).\n\n\n\n\n\n\n\nPreviewing figures\n\n\n\nWhile it is not possible to preview figures in Terminal or JupyterLab because they do not have an image viewer, it is possible to do so from the marbec-data web environment. However, this is a basic viewer and only available for the most common file types.\n\n\n\n\n\n\n\n\n\nWe will start by creating a script (which we will save as code/ex2-1.R) containing a simple loop that generates 20 100x100 arrays with random values and saves them in separate csv files inside the outputs/ex2-rndmats/ folder (remember to create that folder beforehand using mkdir):\n\n# Setting number of rows and columns\nrow_n &lt;- 100\ncol_n &lt;- 100\n\nfor(i in seq(20)){\n  # Create random matrix\n  rndMat &lt;- matrix(data = runif(n = row_n*col_n), nrow = row_n, ncol = col_n)\n  \n  # Save matrix\n  write.csv(x = rndMat, \n            file = sprintf(fmt = \"outputs/ex2-rndmats/mat_%02d.csv\", i), \n            row.names = FALSE)\n  \n  # Print a message at the end of each step\n  cat(sprintf(fmt = \"Matrix %02d finished!\\n\", i))\n}\n\nNow, we will run our script in Terminal (with the command Rscript code/ex2-1.R) and we will observe that everything went well if the messages at the end of each step of the loop are displayed correctly and also if when we run the command ls on the target folder we see the files created:\n\n\n\n\n\n\n\n\nRun a small example first\n\n\n\nBeing already in a real execution, it is highly recommended always to try with a small example that allows us to corroborate that our script goes well BEFORE to pull out all the stops trying to execute the heavy process. In addition, if our script returns figures or files, executing a small corroboration script allows us to quickly check if the generated files are consistent with what we expect to obtain.\n\n\n\n\n\n\nStarting from the previous example, we will convert our script into one that executes the processes in parallel. For this we will take advantage of the tools of the packages foreach and doParallel. Note that the names of the files of this script will begin with the letters mc_ to be able to recognize them with respect to those obtained in the previous example:\n\n# Setting number of rows and columns\nrow_n &lt;- 100\ncol_n &lt;- 100\n\nrequire(foreach)\nrequire(doParallel)\n\n# Registering cluster\ncl &lt;- makeCluster(spec = 20)\nregisterDoParallel(cl = cl)\n\n# Run multithread process\nout &lt;- foreach(i = seq(20), .inorder = FALSE) %dopar% {\n# Create random matrix\n  rndMat &lt;- matrix(data = runif(n = row_n*col_n), nrow = row_n, ncol = col_n)\n  \n  # Save matrix\n  write.csv(x = rndMat, \n            file = sprintf(fmt = \"outputs/ex2-rndmats/mc_mat_%02d.csv\", i), \n            row.names = FALSE)\n  \n  NULL\n}\n\n# Finish cluster\nstopCluster(cl)\n\nNow, we will run our script in Terminal (with the command Rscript code/ex2-2.R) and we will observe that everything has gone well if when executing the command ls on the target folder we see the created files:\n\n\n\n\n\n\n\n\nNote\n\n\n\nA couple of things:\n\nIn the script of the second example, foreach is assigned to an object (out) which will receive the last object generated within each step of the loop. If you only want to get files to be exported (figures, tables, NetCDF, etc.), be sure to leave a NULL in the last line of the loop. On the other hand, if you want to get an object and it is placed in that position, foreach will compile it using the list function, i.e. the final object (out) will be a list that will have as many levels as there are steps in the loop. Also, it is important to note that internally foreach runs a separate small R session so it is necessary to indicate the additional packages required through the .packages argument (see the following example).\nThe argument spec = 20 inside makeCluster refers to the amount of threads that will be used to execute the loop. Remember that one of the options when creating your server in marbec-gpu was to choose the amount of CPUs (2, 4, 8, 16, 32…)? Well, it is precisely with this argument where you will indicate that amount of logical cores. Remember that another important aspect is the RAM. At a given time each process running within each thread will have to load everything that a single simple process would need. In other words, if in a single core process, in each step of our loop we have to load 5 NetCDF files that occupy 5 GB in RAM, if we run that process in multicore and we define spec = 40, at a given moment we will have to load 5GBx40 (200 GB) in RAM simultaneously. So not only you must choose well the configuration of your server (regarding the script you plan to run), but also an approximate of what is consumed in each independent process, in order not to saturate your server. marbec-gpu is great, but it has its limits.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "R Scripts Running"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/run_r_script.html#lets-tidy-up-a-bit",
    "href": "pages/serveurs/marbec_gpu/run_r_script.html#lets-tidy-up-a-bit",
    "title": "Running R scripts in marbec-gpu",
    "section": "",
    "text": "As when working with RStudio locally (i.e. on our PC), it is recommended to clearly define our working directory. This is extremely important because any process we run (either from RStudio or Terminal) will use that directory as a reference to find input files, output files or even other scripts.\nFor our case, we have created a folder called mgpu-examples/ where there is a subfolder called code/. The creation of folders in marbec-data can be done directly from the web interface (by clicking on File station and then using the Create folder button), the command mkdir, but we can also copy-paste the elements already existing in our PC into the working folder.\n\n\n\nThe following is NOT mandatory, but very useful, especially when working with RStudio and that is to create an RStudio project. To do this, we will go to File and then New Project.\n\nThen, in the window that appears, click on Existing directory, then on Browse and click on the folder that we have defined as our working directory (in our case, mgpu-examples/). Then, OK and finally click on the Create Project button. Rstudio will flicker a little bit and then will show us the same window, but inside the set project. The easiest way to check that the project has been created in the correct folder (mgpu-examples/ in our case) is to verify that right in the Console panel, to the right of the R version, appears only the path of our main folder (and not any of the subfolders, e.g. mgpu-examples/code/ or mgpu-examples/inputs/).\n\n\n\n\n\n\n\nJust before to say hello\n\n\n\nmarbec-gpu incorporates the possibility of working with RStudio (Server); however, this interface should be used ONLY to PREPARE our scripts before being executed using all the power of our server. In other words, within the RStudio environment we will be able to load not so big files and perform basic operations, but at no time should we execute a complex (heavy) process from there, but from Terminal.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "R Scripts Running"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/run_r_script.html#hello-world-simple-examples",
    "href": "pages/serveurs/marbec_gpu/run_r_script.html#hello-world-simple-examples",
    "title": "Running R scripts in marbec-gpu",
    "section": "",
    "text": "We will start with the simplest: create a script in R and print the (very famous) “Hello world!” message.\n\nWe will start by opening an RStudio session from the JupyterLab environment (if you want to know how to get there, check the post of Introduction to marbec-gpu).\nOnce inside the RStudio environment, we will create a new script (File -&gt; New file -&gt; R script) which will contain a single line:\n\n\nprint(\"Hello world and hello marbec-gpu!\")\n\nThen, we will save that script with the name code/ex1-1.R (code/ refers to a subfolder created previously inside the working directory of our project in RStudio).\nNow comes the interesting part, inside our browser, we must go back to the Launcher tab and open a Terminal window (clicking on the corresponding icon).\nBy default, Terminal will open a session in the local folder assigned to our user. From there, we must get to the folder we have set as working directory; that is, the folder that our script will recognize as working directory (whether we have decided to use RStudio or not to create it or create a project inside it). Assuming that our working directory is the mgpu-examples/ folder, we must reach it using the cd command:\n\ncd mgpu-examples/\n\n\n\n\n\n\nHow do we know that we have arrived at the correct folder?\n\n\n\nFirst, the prompt will indicate the name of the folder in which it is located.\n\nIn addition, we can run the ls command which will show the subfolders and files inside the folder we have reached. If everything matches, then we did well.\n\n\n\n\nNext, we execute the following command in the Terminal: Rscript code/ex1-1.R and the result should be just what would be shown in a usual R session.\n\n\n\n\n\nIn this next example, we will show a script that generates and saves files in our working directory where previously, we will create two new folders (figures/ and outputs/) through the mkdir command as follows:\nmkdir figures/ outputs/\n\n\n\n\n\n\nNote\n\n\n\nWithin the Terminal environment, it is not possible to observe graphics interactively (as in RStudio), so if you want to keep any figure, you must always include the code to save it within the script you execute. Depending on the graphical environment, we can use functions such as png, bmp, jpeg, pdf (for graphics environment), or ggsave (for ggplot2 environment).\n\n\n\nNow, let’s go to RStudio to create the following script and save it in code/ex1-2.R:\n\n# Print mtcars\nprint(mtcars)\n\n# Export mtcars as a csv\nwrite.csv(x = mtcars, file = \"outputs/mtcars.csv\")\n \n# Create and save a scatterplot\npng(filename = \"figures/fig_1-1.png\")\n\nplot(x = mtcars$mpg, y = mtcars$disp, \n     xlab = \"Miles per (US) gallon\", ylab = \"Displacement (cu.in.)\")\n\ndev.off()\n\nNext, we go back to the Terminal environment and run our new script with the command Rscript code/ex1-2.R. Immediately, the mtcars table will be displayed as that is what the first line of our script commands.\n\n\n\nHowever, if we run the ls command in Terminal for the figures/ and outputs/ folders, we will see that the two files we ordered to be created inside our script appear.\n\n\n\nIf the files created are the ones we expect to collect from our analysis, we can download them through Filezilla (see the corresponding post).\n\n\n\n\n\n\n\nPreviewing figures\n\n\n\nWhile it is not possible to preview figures in Terminal or JupyterLab because they do not have an image viewer, it is possible to do so from the marbec-data web environment. However, this is a basic viewer and only available for the most common file types.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "R Scripts Running"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/run_r_script.html#hello-universe-parallel-process",
    "href": "pages/serveurs/marbec_gpu/run_r_script.html#hello-universe-parallel-process",
    "title": "Running R scripts in marbec-gpu",
    "section": "",
    "text": "We will start by creating a script (which we will save as code/ex2-1.R) containing a simple loop that generates 20 100x100 arrays with random values and saves them in separate csv files inside the outputs/ex2-rndmats/ folder (remember to create that folder beforehand using mkdir):\n\n# Setting number of rows and columns\nrow_n &lt;- 100\ncol_n &lt;- 100\n\nfor(i in seq(20)){\n  # Create random matrix\n  rndMat &lt;- matrix(data = runif(n = row_n*col_n), nrow = row_n, ncol = col_n)\n  \n  # Save matrix\n  write.csv(x = rndMat, \n            file = sprintf(fmt = \"outputs/ex2-rndmats/mat_%02d.csv\", i), \n            row.names = FALSE)\n  \n  # Print a message at the end of each step\n  cat(sprintf(fmt = \"Matrix %02d finished!\\n\", i))\n}\n\nNow, we will run our script in Terminal (with the command Rscript code/ex2-1.R) and we will observe that everything went well if the messages at the end of each step of the loop are displayed correctly and also if when we run the command ls on the target folder we see the files created:\n\n\n\n\n\n\n\n\nRun a small example first\n\n\n\nBeing already in a real execution, it is highly recommended always to try with a small example that allows us to corroborate that our script goes well BEFORE to pull out all the stops trying to execute the heavy process. In addition, if our script returns figures or files, executing a small corroboration script allows us to quickly check if the generated files are consistent with what we expect to obtain.\n\n\n\n\n\n\nStarting from the previous example, we will convert our script into one that executes the processes in parallel. For this we will take advantage of the tools of the packages foreach and doParallel. Note that the names of the files of this script will begin with the letters mc_ to be able to recognize them with respect to those obtained in the previous example:\n\n# Setting number of rows and columns\nrow_n &lt;- 100\ncol_n &lt;- 100\n\nrequire(foreach)\nrequire(doParallel)\n\n# Registering cluster\ncl &lt;- makeCluster(spec = 20)\nregisterDoParallel(cl = cl)\n\n# Run multithread process\nout &lt;- foreach(i = seq(20), .inorder = FALSE) %dopar% {\n# Create random matrix\n  rndMat &lt;- matrix(data = runif(n = row_n*col_n), nrow = row_n, ncol = col_n)\n  \n  # Save matrix\n  write.csv(x = rndMat, \n            file = sprintf(fmt = \"outputs/ex2-rndmats/mc_mat_%02d.csv\", i), \n            row.names = FALSE)\n  \n  NULL\n}\n\n# Finish cluster\nstopCluster(cl)\n\nNow, we will run our script in Terminal (with the command Rscript code/ex2-2.R) and we will observe that everything has gone well if when executing the command ls on the target folder we see the created files:\n\n\n\n\n\n\n\n\nNote\n\n\n\nA couple of things:\n\nIn the script of the second example, foreach is assigned to an object (out) which will receive the last object generated within each step of the loop. If you only want to get files to be exported (figures, tables, NetCDF, etc.), be sure to leave a NULL in the last line of the loop. On the other hand, if you want to get an object and it is placed in that position, foreach will compile it using the list function, i.e. the final object (out) will be a list that will have as many levels as there are steps in the loop. Also, it is important to note that internally foreach runs a separate small R session so it is necessary to indicate the additional packages required through the .packages argument (see the following example).\nThe argument spec = 20 inside makeCluster refers to the amount of threads that will be used to execute the loop. Remember that one of the options when creating your server in marbec-gpu was to choose the amount of CPUs (2, 4, 8, 16, 32…)? Well, it is precisely with this argument where you will indicate that amount of logical cores. Remember that another important aspect is the RAM. At a given time each process running within each thread will have to load everything that a single simple process would need. In other words, if in a single core process, in each step of our loop we have to load 5 NetCDF files that occupy 5 GB in RAM, if we run that process in multicore and we define spec = 40, at a given moment we will have to load 5GBx40 (200 GB) in RAM simultaneously. So not only you must choose well the configuration of your server (regarding the script you plan to run), but also an approximate of what is consumed in each independent process, in order not to saturate your server. marbec-gpu is great, but it has its limits.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "R Scripts Running"
    ]
  },
  {
    "objectID": "pages/serveurs/index_serveurs.html",
    "href": "pages/serveurs/index_serveurs.html",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "Le DEN Marbec propose deux serveurs, un serveur de calcul MARBEC-GPU et un serveur de stockage MARBEC-DATA. Une documentation collaborative est en cours de rédaction pour vous permettre de vous familiariser avec ces serveurs. Vous pouvez dès maintenant consulter les pages de présentation de ces serveurs et quelques basiques tutoriels pour vous aider à démarrer :\n\nMARBEC-GPU Intro\nTutoriels MARBEC-GPU\nMARBEC-DATA Intro\nGestion des données sur MARBEC-DATA\n\nTout utilisateur voulant contribuer à la documentation ou faire des retours est le bienvenu : comment contribuer.\nBonne utilisation !\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Serveurs"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/manage_files.html",
    "href": "pages/serveurs/marbec_data/manage_files.html",
    "title": "Managing files from/to marbec-data",
    "section": "",
    "text": "Image credits: Declan Sun at Unplash",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA",
      "Gestion des Fichiers"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/manage_files.html#create-a-shared-work-folder",
    "href": "pages/serveurs/marbec_data/manage_files.html#create-a-shared-work-folder",
    "title": "Managing files from/to marbec-data",
    "section": "Create a shared work folder",
    "text": "Create a shared work folder\n[Content in preparation]",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA",
      "Gestion des Fichiers"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/manage_files.html#linking-a-working-folder-to-marbec-gpu.",
    "href": "pages/serveurs/marbec_data/manage_files.html#linking-a-working-folder-to-marbec-gpu.",
    "title": "Managing files from/to marbec-data",
    "section": "Linking a working folder to marbec-gpu.",
    "text": "Linking a working folder to marbec-gpu.\n[Content in preparation]",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA",
      "Gestion des Fichiers"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/manage_files.html#managing-files-between-marbec-data-and-our-pc-filezilla",
    "href": "pages/serveurs/marbec_data/manage_files.html#managing-files-between-marbec-data-and-our-pc-filezilla",
    "title": "Managing files from/to marbec-data",
    "section": "Managing files between marbec-data and our PC (FileZilla)",
    "text": "Managing files between marbec-data and our PC (FileZilla)\n\nInstalling FileZilla and connecting to marbec-data.\nThe easiest way to move (copy, cut and paste) files from our PC to one of our shared work folders or to our marbec-gpu user folder is through the (free) FileZilla software. To download the installer, just go to its official website https://filezilla-project.org/ and select the Download FileZilla Client button.\n\nThen, by default we will be offered to download the version corresponding to the operating system (OS) where we are running our browser, but we can always choose the most appropriate version in the section More download options.\n\n\n\n\n\n\n\nOperating systems and CPU architectures\n\n\n\nIn recent years, processors with ARM architecture have been incorporated into the PC market. The most recent and famous example is Apple’s Mx series (e.g. M1); however, in recent months laptops with ARM processors (from the Snapdragon brand, for instance) have also appeared. Software compiled for an ARM architecture will not work on an x86 architecture (which is the architecture manufactured by brands such as Intel or AMD) and vice versa, so it will always be important to know not only which OS our PC is running (Windows, MacOS or Linux), but also the architecture of our processor.\n\n\nOnce the file has been downloaded, it will be enough to run it leaving most of the options by default (except those that offer us to install some additional program that we do not need, e.g. Chrome). After that, we will be able to run the program and we will obtain an environment that will look like this:\n\nThe next thing we will do is to establish a connection to marbec-data. To do this, at the top, we will fill in the following fields:\n\nServer: marbec-data.ird.fr\nUser: youruser\nPassword: yourpassword\nPort: 22\n\nIf all goes well, a message indicating that the connection has been successful will be displayed in the panel immediately below. In addition, the next two lower panels to the right will show those folders already linked and available in our marbec-data account.\n\n\n\n\n\n\n\nNote\n\n\n\nIt is not necessary to log in every time we log back into FileZilla. We could save our login and skip the above steps by clicking the small arrow to the right of Quick Login and selecting our saved login. Of course, allowing our login credentials to be saved should ONLY occur on our personal PC.\n\n\n\nAnd that is all! In the left panels, we will be able to navigate in the directories of our PC, while in the right panels we will be able to do it in the marbec-gpu and marbec-data ones.\n\n\nCopying files and folders\nIt will be as simple as dragging the element between the left and right panels. The process will start and the bottom pane (the last one) will show the queued, completed and failed transfers.\n\nAlso, if at any time FileZilla detects that there are repeated items, it will show a small window with multiple options available (overwrite and skip, verify differences in sizes or names, apply the selected option to future cases in the transfer queue, etc.).",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA",
      "Gestion des Fichiers"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/manage_files.html#manage-files-within-marbec-data.",
    "href": "pages/serveurs/marbec_data/manage_files.html#manage-files-within-marbec-data.",
    "title": "Managing files from/to marbec-data",
    "section": "Manage files within marbec-data.",
    "text": "Manage files within marbec-data.\nWhile the marbec-data web environment explorer offers the options to copy, paste, delete, etc., it is not an efficient method when our files are medium or large (&gt;10 MB). Here is how to perform these operations from Terminal.\n\nCopy-paste\nFor this, the simplest way is through the cp command and making use of the navigation commands cited in this post (e.g. .. to indicate a previous folder). The basic syntax is the following: cp path/origin /path/destination, but there are different possible cases:\n\nCopy a file into the same folder, but with a different name (create duplicate): cp file1.csv file1-dup.csv.\nCopy a file to another folder: cp path/file1.csv path/destination.\nCopy more than one file to another folder: cp path/file1.csv path/file2.csv folder/destination\nCopy a folder to another folder: cp path/folder1 path/folder2 --recursive or cp path/folder1 path/folder2 -r.\n\n\n\n\n\n\n\nNote\n\n\n\nBy default, cp will overwrite any file with the same name. To avoid this, it is possible to add the -n option as follows: cp path/from/file1.csv path/destination -n.\n\n\n\n\nCut-paste (and also rename)\nIt will be very similar to the above, but through the mv command:\n\nRename a file (within the same folder): mv file1.csv file2.csv\nMove a file to another folder: mv path/file1.csv path/to/destination\nMove one file to another folder: mv path/file1.csv path/file2.csv path/destination\nMove one folder to another folder: mv path/old/folder path/new/folder\n\n\n\nDelete\nFor this, we will use the rm command as follows:\n\nDelete a file: rm path/to/file.csv\nDelete a folder (and all its contents): rm path/to/folder -r\n\n\n\n\n\n\n\nNo turning back\n\n\n\nWhile inside Terminal it is always possible to cancel a command using the shortcut Ctrl+C (or Cmd+C on MacOS), once the rm command completes its work, there is no way to revert the deletion or recover it from a recycle garbage can, so be very careful when using it.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA",
      "Gestion des Fichiers"
    ]
  },
  {
    "objectID": "pages/packages_logiciels/ichthyop.html",
    "href": "pages/packages_logiciels/ichthyop.html",
    "title": "Logiciel Ichthyop",
    "section": "",
    "text": "Ichthyop est un outil Java gratuit conçu pour étudier les effets des facteurs physiques et biologiques sur la dynamique de l’ichtyoplancton.\nIl intègre les processus les plus importants impliqués dans les premiers stades de la vie des poissons : le frai, le mouvement, la croissance, la mortalité et le recrutement. L’outil utilise en entrée des séries temporelles de champs de vitesse, de température et de salinité archivées à partir des modèles océaniques ROMS, MARS, NEMO ou SYMPHONIE (sous forme de fichiers ou d’OpenDAP).\nLe logiciel Ichthyop et ses ressources associées sont disponibles sur GitHub.",
    "crumbs": [
      "Liens utiles",
      "Packages et logiciels",
      "Logiciel Ichthyop"
    ]
  },
  {
    "objectID": "pages/packages_logiciels/ichthyop.html#outil-lagrangien-pour-la-simulation-de-la-dynamique-de-lichthyoplancton",
    "href": "pages/packages_logiciels/ichthyop.html#outil-lagrangien-pour-la-simulation-de-la-dynamique-de-lichthyoplancton",
    "title": "Logiciel Ichthyop",
    "section": "",
    "text": "Ichthyop est un outil Java gratuit conçu pour étudier les effets des facteurs physiques et biologiques sur la dynamique de l’ichtyoplancton.\nIl intègre les processus les plus importants impliqués dans les premiers stades de la vie des poissons : le frai, le mouvement, la croissance, la mortalité et le recrutement. L’outil utilise en entrée des séries temporelles de champs de vitesse, de température et de salinité archivées à partir des modèles océaniques ROMS, MARS, NEMO ou SYMPHONIE (sous forme de fichiers ou d’OpenDAP).\nLe logiciel Ichthyop et ses ressources associées sont disponibles sur GitHub.",
    "crumbs": [
      "Liens utiles",
      "Packages et logiciels",
      "Logiciel Ichthyop"
    ]
  },
  {
    "objectID": "pages/packages_logiciels/index_packages_logiciels.html",
    "href": "pages/packages_logiciels/index_packages_logiciels.html",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "Vous trouverez dans cette section tous les packages, logiciels ou de manière générale les ressources informatiques developés ou utilisés par les personnels et partenaires associés de l’UMR MARBEC.\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Packages et logiciels"
    ]
  },
  {
    "objectID": "pages/contribution.html",
    "href": "pages/contribution.html",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "Vous faites partir de l’UMR, ou non, et vous avez des bouts de codes, documentations techniques ou n’importe quelles ressources informatiques que vous aimeriez tester, standardiser ou même mutualiser ? Vous avez une idée et vous demandez si le processus associé n’a pas déjà été développé par quelqu’un ? Vous êtes au bon endroit !\nCe site, et par addition les ressources associées, sont le fruit de nombreuses heures de travail et de réflexions communes sur des sujets qui au final sont souvent transervaux entre les personnes. Son but est vraiment de centraliser et standardiser au maximum ce qui a été fait et son succès ne dépend que de la synergie que nous mettons en œuvre pour créer du contenu. Par ailleurs, ces ressources ne sont que la partie émergée de l’iceberg qui favorise les relations et les liens que nous pouvons créer entre nous sur nos travaux.\nSi vous voulez contribuer d’une manière ou d’une autre, la clé est vraiment de ne pas se décourager par la tache globale qui peut faire peur, mais vraiment de commencer par un premier pas. Vous constaterez rapidement que derrière un problème ou un obstacle, vous trouverez ici une communauté riche et bienveillante qui saura vous aider, toujours avec un objectif de mutualisation et d’optimisation des ressources informatiques.\nDerrière la multitude de types de contenu que nous pouvons partagé entre nous, qui va d’une documentation en markdown jusqu’a des packages ou des logiciels développés par la communauté, l’idée est d’établir entre nous certains standards permettant de garantir l’intégrité et l’interopérabilité des contenus et ressources disponibles. Ces standards peuvent être vus comme des règles, mais en aucun cas ils ne doivent être assimilés à des freins à votre implication. Par exemple si certains points sont bloquants (par exemple la traduction d’une procédure dans une autre langue ou la méconnaissance de l’utilisation des forges telles que les git), tournés vers la communauté et vous trouverez tout l’aide dont vous avez besoin.\nDe manière générale voici quelques lignes directrices à prendre en compte avant de publier des ressources :\n\nles ressources de ce site sont dédiées à être utilisé par tous le personnel de l’UMR, mais potentiellement les partenaires associés. Par défaut le contenu doit être publié en français, mais aussi en anglais afin de garantir l’accessibilité au “maximum”. Certains contenus, comme les formations, peuvent s’abroger de règles si cela est pertinent. Encore une fois ne vous laissez pas bloqué par la barrière de la langue, vous trouverez forcément quelqu’un de notre communauté qui peut vous aider pour traduire.\nsuivante le type de contenu que vous voulez publiez, le mieux est parfois de ce tourner vers des personnes-ressources ou référentes qui pourront vous apporter des solutions ou des propositions pour vous guider dans la mutualisation de vos ressources. La liste de ces personnes clés sera mise à disposition sous peu et en attendant si vous ne savez pas vers qui vous tourner vous pouvez envoyer un mail aux administrateurs du DEN.\ntoujours dans un but de mutualisation et globalement d’harmonie des templates seront proposés pour les différents types de ressources. En attendant, n’hésitez pas à échanger avec les personnes de la communauté pour essayer de trouver, autant que possible, une structure commune.\nmême si l’utilisation des ressources informatique au sein de l’UMR doit vraiment être vu de manière transversale et sans “frontières” associées, la mutualisation et l’accessibilité de ces derniers est vraiment en lien avec le Dispositif d’Ecologie Numérique, ou DEN. Cette entité, transversale au niveau de l’UMR à comme objectifs la mise en place, la coordination et la mutualisation des moyens techniques ainsi que l’échange de méthodologies et de nouvelles approches en support aux aspects numériques des travaux de recherche scientifique. Vous rapprocher de ce dispositif et des sous-entités qui le composent peut être judicieux et vous apporter un support non négligeable au sein de vos activités.\nde par sa nature, ce site est voué à évoluer en lien avec les besoins. N’hésitez pas à faire des suggestions d’améliorations, proposer de nouvelles sections ou même une organisation différente. Au final cela ne pourra être que bénéfique à la communauté.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Je veux contribuer !"
    ]
  },
  {
    "objectID": "pages/git/miroir_github_git.html",
    "href": "pages/git/miroir_github_git.html",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "Dès lors que l’on commence à vouloir travailler en équipe sur des bouts de code, voir de manière générale sur des développements informatiques, l’utilisation d’un outil de contrôle de version est rapidement un outil incontournable et un allié précieux pour toute personne soucieuse de gérer efficacement son travail. Ici nous n’aborderons pas les caractéristiques d’un git, ou système de contrôle de version, mais nous proposons une solution pouvant aider à résoudre une question que l’on se pose souvent, à savoir vers quel système, ou forge, se tourner.\nUn rapide coup d’œil sur internet vous montrera qu’il existe plusieurs forges. L’une des plus populaires est GitHub mais il en existe d’autres comme GitLab ou encore Bitbucket. Il est aussi tout à fait possible que votre institut ou organisme utilise l’un de ces systèmes pour héberger sa propre forge (jeter un coup d’œil ici). Chaque système présente des avantages et des inconvénients et votre choix doit être guidé par vos besoins. À titre d’exemple vous trouverez un rapide comparatif des principales forges dans le tableau ci-dessous.\n\n\n\n\n\n\n\n\n\n\nCritères\nGitHub\nGitLab\nBitbucket\nGitea\n\n\n\n\nPopularité\nTrès élevée\nÉlevée\nMoyenne\nFaible\n\n\nCI/CD intégré\nGitHub Actions (simple et puissant)\nTrès robuste et flexible\nIntégré, mais limité\nDépends de l’intégration manuelle\n\n\nOpen source\nNon\nOui\nNon\nOui\n\n\nHébergement gratuit\nDépôt privé gratuit illimité\nDépôt privé gratuit illimité\nDépôt privé gratuit illimité\nNécessite un serveur\n\n\nAutohébergement\nNon\nOui\nOui\nOui\n\n\nFocus équipes privées\nMoyen\nFort\nTrès fort (intégré à Jira)\nAdapté",
    "crumbs": [
      "Liens utiles",
      "Système de contrôle de version",
      "Miroir depuis Github vers un dépôt git"
    ]
  },
  {
    "objectID": "pages/git/miroir_github_git.html#pourquoi-utiliser-une-forge-git",
    "href": "pages/git/miroir_github_git.html#pourquoi-utiliser-une-forge-git",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "Dès lors que l’on commence à vouloir travailler en équipe sur des bouts de code, voir de manière générale sur des développements informatiques, l’utilisation d’un outil de contrôle de version est rapidement un outil incontournable et un allié précieux pour toute personne soucieuse de gérer efficacement son travail. Ici nous n’aborderons pas les caractéristiques d’un git, ou système de contrôle de version, mais nous proposons une solution pouvant aider à résoudre une question que l’on se pose souvent, à savoir vers quel système, ou forge, se tourner.\nUn rapide coup d’œil sur internet vous montrera qu’il existe plusieurs forges. L’une des plus populaires est GitHub mais il en existe d’autres comme GitLab ou encore Bitbucket. Il est aussi tout à fait possible que votre institut ou organisme utilise l’un de ces systèmes pour héberger sa propre forge (jeter un coup d’œil ici). Chaque système présente des avantages et des inconvénients et votre choix doit être guidé par vos besoins. À titre d’exemple vous trouverez un rapide comparatif des principales forges dans le tableau ci-dessous.\n\n\n\n\n\n\n\n\n\n\nCritères\nGitHub\nGitLab\nBitbucket\nGitea\n\n\n\n\nPopularité\nTrès élevée\nÉlevée\nMoyenne\nFaible\n\n\nCI/CD intégré\nGitHub Actions (simple et puissant)\nTrès robuste et flexible\nIntégré, mais limité\nDépends de l’intégration manuelle\n\n\nOpen source\nNon\nOui\nNon\nOui\n\n\nHébergement gratuit\nDépôt privé gratuit illimité\nDépôt privé gratuit illimité\nDépôt privé gratuit illimité\nNécessite un serveur\n\n\nAutohébergement\nNon\nOui\nOui\nOui\n\n\nFocus équipes privées\nMoyen\nFort\nTrès fort (intégré à Jira)\nAdapté",
    "crumbs": [
      "Liens utiles",
      "Système de contrôle de version",
      "Miroir depuis Github vers un dépôt git"
    ]
  },
  {
    "objectID": "pages/git/miroir_github_git.html#pourquoi-se-tourner-vers-github",
    "href": "pages/git/miroir_github_git.html#pourquoi-se-tourner-vers-github",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "Pourquoi se tourner vers GitHub ?",
    "text": "Pourquoi se tourner vers GitHub ?\nLa procédure que vous êtes en train de lire vous propose une solution afin de copier de manière automatique le contenu d’un dépôt GitHub vers le dépôt d’une autre forge, tel que GitLab. Sans rentrer trop dans les délais et toujours en gardant à l’esprit que la selection de votre forge doit se faire en accord avec vos besoins, pourquoi avons-nous fait le choix de se tourner vers GitHub.\nLa raison principale est que GitHub propose par défaut un écosystème riche et surtout des intégrations natives, notamment via les GitHub actions. Ces outils sont vraiment des alliés très efficaces pour vos développements et facilitent grandement les processus d’intégration/déploiement continus. De nombreuses communautés, tels que la celle de R, a déjà mis à disposition de nombreuses “Github actions”. Ces dernières permettent d’automatiser de nombreux processus, qui vont aussi bien de la vérification de votre code, que de la publication de documentation associée aux développements/packages. De plus, une grande partie des workflows peut être centralisée via GitHub, ce qui réduit considérable la dépendance à d’autres outils tiers.\nPar ailleurs, GitHub est la forge la plus utilisée au monde, avec une immense communauté d’utilisateur. Concrètement il est très difficile pour une autre forge de rivaliser au niveau du référencement ou de la visibilité de GitHub. De plus, de nombreuses fonctionnalités, comme la section Discussions ou encore l’affichage ouvert des contributions, renforcent la collaboration et son interface est souvent perçue comme étant la plus simple et intuitive parmi les forges.\nOutre le fait qu’il soit largement adopté par les entreprises et les projets open source, le volet IA de GitHub, via son utilitaire GitHub Copilot, peut être une aide dans la construction de vos ressources.\nPour finir, la version gratuite est déjà très performante et présente l’avantage de proposer des dépôts privés illimités ainsi que la collaboration avec plusieurs contributeurs sans frais supplémentaires.",
    "crumbs": [
      "Liens utiles",
      "Système de contrôle de version",
      "Miroir depuis Github vers un dépôt git"
    ]
  },
  {
    "objectID": "pages/git/miroir_github_git.html#pourquoi-ne-pas-utiliser-uniquement-github",
    "href": "pages/git/miroir_github_git.html#pourquoi-ne-pas-utiliser-uniquement-github",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "Pourquoi ne pas utiliser uniquement GitHub ?",
    "text": "Pourquoi ne pas utiliser uniquement GitHub ?\nAu vu de la section précédente, on peut se demander pourquoi ne pas utiliser uniquement GitHub qui semble être le choix le plus judicieux. Malgré tous ces avantages, il ne faut pas oublier que GitHub reste la propriété de Microsoft et que par conséquent il est possible qu’un futur changement de la politique commerciale de Microsoft ne devienne pénalisant ou même incompatible avec votre travail. Même s’il est peu probable qu’une telle évolution soit “brutale” au point de ne pas vous permettre de prendre les mesures nécessaires, il peut être judicieux de réfléchir à des solutions permettant en quelque sorte de profiter du meilleur des mondes mis à notre disposition.\nL’objectif de cette procédure est donc de fournir une solution qui permet de copier, de manière automatique, l’intégralité d’un dépôt GitHub vers une autre forge. Pour ce tutoriel nous prendrons l’exemple d’une forge GitLab hébergé par l’IRD.",
    "crumbs": [
      "Liens utiles",
      "Système de contrôle de version",
      "Miroir depuis Github vers un dépôt git"
    ]
  },
  {
    "objectID": "pages/git/miroir_github_git.html#procédure-pour-créer-un-miroir-entre-deux-dépôts-github-vers-gitlab-ird",
    "href": "pages/git/miroir_github_git.html#procédure-pour-créer-un-miroir-entre-deux-dépôts-github-vers-gitlab-ird",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "Procédure pour créer un miroir entre deux dépôts (GitHub vers GitLab IRD)",
    "text": "Procédure pour créer un miroir entre deux dépôts (GitHub vers GitLab IRD)\n\nPrérequis et cadre de la procédure\nAfin de suivre au mieux la procédure, il est conseillé d’être un minimum familiarisé avec l’utilisation d’une forge git, idéalement GitHub. Par ailleurs, nous partirons du principe que vous disposez d’un compte correctement configuré sur GitHub et la forge de destination (pour l’exemple ici le GitLab de l’IRD). Au besoin, vous trouverez l’adresse mail de la personne ressource à l’origine de cette procédure en haut de la page. N’hésitez pas à la contacter si vous avez besoin d’aide.\nPour informatique, les images en lien avec la procédure ont été générées via des interfaces en anglais, ce qui devrait être la configuration par défaut sur la majorité des logiciels concernés.\n\nTableau 1 : État des tests de la procédure.\n\n\n\n\n\n\n\nSystème d’exploitation\nProcédure fonctionnelle\nÉdition et version\n\n\n\n\nWindows\nOui\n11 Professionnel, version 23H2\n\n\nMac\nNon testée\n\n\n\nLinux\nNon testée\n\n\n\n\n\n\n1. Initialisation des dépôts\n\n1.1 Création d’un dépôt source sur GitHub\nTout d’abord nous allons créer un dépôt source sur la forge GitHub. Pour l’exemple ici nous avons créé un dépôt public nommé “my_github_repository” avec des paramètres initiaux configuré globalement pour abriter des codes R (figure 1).\n\n\n\n\nFigure 1 : Configuration du dépôt source GitHub\n\n\n\nPour information notre test ici créer un dépôt “public”, car nous sommes parties du principe que notre contenu en développement a vocation à être partagé avec tout le monde et ne présente aucun caractère confidentiel ou privé. Vous pouvez tout à fait appliquer cette procédure sur un dépôt “private” (à tester, peut-être certains paramètres en lien avec les secrets cités plus loin devront être modifiés), mais dans ce cas il est judicieux de réfléchir à la véracité d’utiliser GitHub pour des données qui présentent un caractère privé. Cela ne veut pas dire de ne jamais publier des répertoires privés sur GitHub, mais de ne pas oublier que malgré tous les bénéfices, GitHub reste une forge propriétaire de Microsoft.\n\n\n1.2 Création d’un dépôt cible sur une autre forge\nLa seconde étape est de créer un second dépôt cible sur une autre forge. Comme cité précédemment, nous allons utiliser une forge GitLab hébergé par l’IRD, auquel les personnels de l’UMR peuvent avoir accès. Vous trouverez dans la figure 2 ci-dessous un exemple de configuration.\n\n\n\n\nFigure 2 : Configuration du dépôt cible GitLab\n\n\n\nVous noterez, en opposition à notre configuration de notre dépôt source GitHub, que notre dépôt est ici publié en “private”. Cela se justifie afin de minimiser les “interactions” que les utilisateurs peuvent avoir sur ce dépôt. Vous allez voir par la suite que nous allons automatiser le flux de données entre notre dépôt source (GitHub) et notre dépôt cible (GitLab de l’IRD) et au final vous n’allez pas interagir directement sur le dépôt cible, comme l’on va le faire sur notre dépôt source au cours de sa vie. Encore pire, le flux de données que nous allons créer va être un flux unidirectionnel vers notre dépôt source, des modifications directes sur ce dépôt ne seront surement pas sauvegardées, risqueraient de provoquer des troubles dans l’automatisation et seraient même contraires à la logique de la procédure.\n\n\n\n2. Connexion entre les deux forges\nMaintenant que nous avons créé les deux dépôts, il va falloir établir une connexion entre eux. Il y a plusieurs manières de faire, mais ce que nous allons utiliser ici s’appelle la création d’un jeton d’accès, ou “token”. Certains d’entre vous ont déjà dû effectuer cette action, notamment si vous avez fait une connexion entre un git et Rstudio. Nous n’allons pas rentrer dans les détails de la création d’un jeton d’accès et si besoin une procédure plus détaillée pourra être réalisée Juste pour résumer, nous allons créer un jeton d’accès depuis la forge du dépôt cible, que nous allons renseigner ensuite au niveau du dépôt source.\n\n2.1 Création d’un jeton d’accès sur le dépôt cible\nPour effectuer cela, il suffit de se placer au niveau de la racine de notre dépôt cible (ici celui que nous avons appelé “my_gitlabird_repository”). Dans le menu à gauche vous devriez voir une section “Settings” et une sous-section “Access tokens”. Cela devrait sous amener sur l’onglet de la figure 3.\n\n\n\n\nFigure 3 : Onglet “Access tokens”\n\n\n\nPour créer un nouveau jeton d’accès, il suffit de cliquer sur l’onglet “Add new token”. Dans la nouvelle fenêtre, vous trouverez plusieurs onglets à renseigner :\n\n“Token name”, le nom du jeton d’accès. Idéalement le nom doit être assez explicite et vous permettre de comprendre à quoi il sert. La plupart d’entre nous n’auront pas plus d’un jeton d’accès par dépôt, mais il est possible d’en ajouter plusieurs et dans ce cas il faut pouvoir les identifier.\n“Expiration date”, il s’agit de la date d’expiration du jeton d’accès. D’un point de vue sécuritaire, il peut être dangereux de créer un jeton qui ne possède pas de date d’expiration (si on clique sur la croix à droite de la date). Au-delà de la simplicité de faire cela (on n’a plus à s’occuper de notre connexion), créer une connexion via un jeton d’accès va créer une “faille” potentielle dans la sécurité de votre dépôt qui pourra servir de point d’entrée à de potentielles attaques malveillantes. Il ne faut pas devenir paranoïaque, mais l’idée est plus d’avoir une réflexion sur la durée de vie de votre jeton. Mon projet est-il un projet à court terme ? Y a-t-il une échéance future qui est susceptible de modifier la pertinence de ce jeton (par exemple modification de l’intégrité du dépôt source) ? concrètement vais-je penser à supprimer mon jeton d’accès si je n’en ai plus besoin. Libre à vous de fixer vos propres règles. Ici par exemple nous avons identifié un jeton qui sera valide jusqu’au 01/05/2025.\n“Select a role”. Dans le cas de l’utilisation d’un jeton d’accès personnel pour effectuer des actions de miroir depuis GitHub vers GitLab, nous n’avons pas besoin de nous concentrer directement sur les rôles, car les “scopes” de la section suivante sont ce qui détermine les permissions du jeton. Cependant, le rôle associé à un jeton d’accès personnel peut influencer certaines permissions d’accès à des projets ou des groupes. Si l’on veut être rigoureux, le plus judicieux est de choisir un rôle comme “Developer”. Un développeur va être une entité qui peut pousser du code, créer des branches, faire des “pull requests” et gérer les dépôts (ce que nous voulons faire ici).\n“Selected scopes”. Cette dernière section celle qui va définir les permissions et concrètement à quoi l’on peut avoir accès grâce à notre jeton. Pour faire un miroir, nous avons besoin de 3 droits spécifiques :\n\n“api” : permets d’effectuer toutes les actions de l’API, y compris la gestion des dépôts, des projets, etc.\n“write_repository” : permets de pousser dans les dépôts GitLab (nécessaire pour le miroir).\n“read_repository” : permets de lire les dépôts GitLab (si nécessaire pour la configuration ou la vérification).\n\n\n\n\n\n\nFigure 4 : Configuration du jeton d’accés\n\n\n\nValider votre configuration via le bouton “Create project access token” en bas.\nLa prochaine page qui s’affiche devrait vous indiquer la validation de la création de votre jeton d’accès, mais aussi vous présenter sa valeur. Vous pouvez l’afficher en cliquant sur bouton en forme d’œil. Juste en dessous de votre jeton, vous remarquerez un message vous indiquant que ce jeton ne sera dévoilé uniquement maintenant et il ne sera plus possible par la suite de la visualiser (dans un souci de sécurité). L’idée est de le copier (cliquez que le bouton situé à droite de celui en forme d’œil), de le stocker quelque part (par exemple dans un gestionnaire de mots de passe) car nous allons devoir le renseigner dans notre a source GitHub.\n\n\n2.2 Renseignement de notre jeton d’accès sur le dépôt source\nMaintenant que nous avons notre jeton d’accès pour notre dépôt cible, il va falloir le renseigner au niveau de notre dépôt source. Pour cela, il faut se rendre sur la page de notre dépôt source (dans l’exemple, le dépôt GitHub que nous avons appelé “my_github_repository”), de cliquer sur l’onglet “Settings”, la section “Secrets and variables” et la sous-section “Actions”. Dans la nouvelle page qui s’affiche, cliquez sur le bouton “New respository secret” situé dans la partie “Repository secrets”. Il vous suffit ensuite de renseigner un nom pour ce secret (comme précédent il doit être parlant pour l’utilisateur) et de coller la valeur de votre jeton dans la partie “Secret” (figure 5).\n\n\n\n\nFigure 5 : Configuration d’un secret associé à un dépôt GitHub\n\n\n\n\n\n\n3. Création du processus de miroir et automatisation\n\n3.1 Création du script “GitHub Action”\nNos deux dépôts étant connectés, nous pouvons maintenant commencer à travailler sur la création du processus de miroir ainsi que son automatisation. Pour faire cela, nous allons créer une “GitHub action”. Nous en avons parlé précédemment, mais ce type de processus va nous permettre d’exécuter des processus en arrière-plan et surtout d’automatiser le lancement de ces derniers.\nPour faire cela, nous avons deux possibilités, (1) créer et adapter manuellement notre fichier yaml associé à la “GitHub Action” ou (2) utiliser une fonction du package sparck qui va nous simplifier les étapes de création.\n\n3.1.1 Création et adaptation manuelle de la “GitHub Action”\nConcrètement pour cela, nous devons nous rendre à la racine de notre dépôt source GitHub et de créer un dossier “.github” ainsi qu’un sous dossier “workflows”. À l’intérieur de ce dernier dossier, nous allons copier le code ci-dessous dans un éditeur de code source (type Notepad ou encore Visual Studio Code).\nname: GitHub to GitLab IRD mirror with release assets\n\non:\n  push: \n    branches:\n      - '**'\n    tags:\n      - '**'\n  pull_request:\n    branches:\n      - '**'\n  delete:\n    branches:\n      - '**'\n    tags:\n      - '**'\n  release:\n    types:\n      - created\n      - published\n      - edited\n      - deleted\n\njobs:\n  mirror:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Clone repository as bare\n        run: |\n          git clone --bare &lt;github_repository_source_url&gt;.git my-github-repository.git\n\n      - name: Set up Git\n        run: |\n          git config --global user.name \"GitHub Actions\"\n          git config --global user.email \"github-actions@users.noreply.github.com\"\n\n      - name: Add forge remote\n        run: |\n          cd my-github-repository.git\n          git remote add mirror https://oauth2:${{ secrets.&lt;secret_token_name&gt; }}@&lt;git_repository_target_url&gt;.git\n  \n      - name: Push to forge\n        run: |\n          cd my-github-repository.git\n          git push --mirror mirror\n\n  download-release-assets:\n      runs-on: ubuntu-latest\n      needs: mirror\n\n      steps:\n        - name: Set up Git (Authentication)\n          run: |\n            git config --global user.name \"GitHub Actions\"\n            git config --global user.email \"github-actions@users.noreply.github.com\"\n\n        - name: Fetch release(s) from GitHub\n          id: fetch_releases\n          run: |\n            RESPONSE=$(curl -s -H \"Authorization: token ${{ secrets.GITHUB_TOKEN }}\" \\\n              \"https://api.github.com/repos/&lt;github_repository_source_url_api&gt;/releases\")\n          \n            RELEASE_IDS_NAMES=$(echo \"$RESPONSE\" | jq -r '.[] | \"\\(.id) \\(.name)\"')\n\n            if [ -z \"$RELEASE_IDS_NAMES\" ]; then\n              echo \"No release found. No action required.\"\n              echo \"SKIP_NEXT_STEP=true\" &gt;&gt; $GITHUB_ENV\n              exit 0\n            fi\n\n            NUM_RELEASES=$(echo \"$RELEASE_IDS_NAMES\" | wc -l)\n            echo \"Number of releases found: $NUM_RELEASES\"\n            echo \"NUM_RELEASES=$NUM_RELEASES\" &gt;&gt; $GITHUB_ENV\n\n            RELEASE_IDS=\"\"\n            RELEASE_NAMES=\"\"\n            \n            while IFS= read -r line; do\n              RELEASE_ID=$(echo \"$line\" | awk '{print $1}')\n              RELEASE_NAME=$(echo \"$line\" | awk '{print $2}')\n              RELEASE_IDS=\"$RELEASE_IDS$RELEASE_ID,\"\n              RELEASE_NAMES=\"$RELEASE_NAMES$RELEASE_NAME,\"\n            done &lt;&lt;&lt; \"$RELEASE_IDS_NAMES\"\n\n            RELEASE_IDS=${RELEASE_IDS%,}\n            RELEASE_NAMES=${RELEASE_NAMES%,}\n\n            echo \"RELEASE_IDS=$RELEASE_IDS\" &gt;&gt; $GITHUB_ENV\n            echo \"RELEASE_NAMES=$RELEASE_NAMES\" &gt;&gt; $GITHUB_ENV\n\n        - name: Download release(s) asset(s) from GitHub\n          id: download_assets\n          if: ${{ env.SKIP_NEXT_STEP != 'true' }}\n          run: |\n            ASSETS_FOUND=false\n            NUM_RELEASES=${{ env.NUM_RELEASES }}\n            RELEASE_IDS=${{ env.RELEASE_IDS }}\n            RELEASE_NAMES=${{ env.RELEASE_NAMES }}\n            IFS=',' read -ra RELEASE_IDS_ARRAY &lt;&lt;&lt; \"$RELEASE_IDS\"\n            IFS=',' read -ra RELEASE_NAMES_ARRAY &lt;&lt;&lt; \"$RELEASE_NAMES\"\n            for num_release in $(seq 0 $((NUM_RELEASES - 1))); do\n              RELEASE_ID=\"${RELEASE_IDS_ARRAY[$num_release]}\"\n              RELEASE_NAME=\"${RELEASE_NAMES_ARRAY[$num_release]}\"\n              echo \"Processing release ID: $RELEASE_ID with Name: $RELEASE_NAME\"\n              ASSETS=$(curl -s \\\n                -H \"Authorization: token ${{ secrets.GITHUB_TOKEN }}\" \\\n                \"https://api.github.com/repos/&lt;github_repository_source_url_api&gt;/releases/$RELEASE_ID/assets\" \\\n                | jq -r '.[].browser_download_url')\n              if [ -z \"$ASSETS\" ]; then\n                echo \"No assets found for release $RELEASE_ID ($RELEASE_NAME). Skipping download step.\"\n                continue\n              else\n                ASSETS_FOUND=true\n                mkdir -p \"release-assets/$RELEASE_ID\"_\"$RELEASE_NAME\"\n                cd \"release-assets/$RELEASE_ID\"_\"$RELEASE_NAME\"\n        \n                for URL in $ASSETS; do\n                  echo \"Downloading $URL\"\n                  curl -L -o \"$(basename \"$URL\")\" -H \"Authorization: token ${{ secrets.GITHUB_TOKEN }}\" \"$URL\"\n                done\n        \n                cd -\n              fi\n            done\n            if [ \"$ASSETS_FOUND\" = false ]; then\n              echo \"No assets found for any release. Exiting.\"\n              echo \"SKIP_NEXT_STEP=true\" &gt;&gt; $GITHUB_ENV\n              exit 0\n            fi\n\n        - name: Push asset(s) to mirror repository\n          id: push_mirror\n          if: ${{ env.SKIP_NEXT_STEP != 'true' }}\n          run: |\n            git clone https://oauth2:${{ secrets.&lt;secret_token_name&gt; }}@&lt;git_repository_target_url&gt;.git\n            cd test_miroir_github\n\n            if [ -d \"release-assets\" ]; then\n              echo \"Removing existing release-assets directory from the mirror repository.\"\n              rm -rf release-assets\n            fi\n\n            echo \"Copying local release-assets directory to the mirror repository.\"\n            cp -r \"../release-assets\" .\n\n            git add .\n            git commit -m \"Add release assets from GitHub releases\"\n\n            BRANCH_NAME=$(git symbolic-ref --short HEAD)\n\n            git push origin \"$BRANCH_NAME\"\nDans ce script il sera nécessaire d’adapter certaines variables en fonction de votre environnement :\n\n&lt;github_repository_source_url&gt; pour l’adresse URL de votre répertoire source GitHub. Pour l’exemple ici on aura la valeur “https://github.com/umr-marbec/my_github_repository” (sans les guillemets, idem pour toutes les variables suivantes).\n&lt;secret_token_name&gt; qui va renseigner le nom du secret que nous avons identifié au niveau du dépôt source GitHub (lien section 2.2). Ici nous utiliserons “TOKEN_MY_GITLABIRD_REPOSITORY”. Attention, si vous remarquez dans la figure 5, le nom de mon secret était en minuscule. Par défaut, GitHub passe tous les caractères en majuscule.\n&lt;git_repository_target_url&gt; pour l’adresse ULR de votre dépôt cible, sans la valeur “https://” en début de chaine. Par exemple ici pour la forge de l’IRD on utilisera la valeur “forge.ird.fr/marbec/private/depetris-mathieu/my_gitlabird_repository”.\n&lt;github_repository_source_url_api&gt; pour l’adresse URD du répertoire source GitHub, mais en version “light” (sans “https://github.com/”). Pour notre exemple la valeur sera “umr-marbec/my_github_repository”.\n\nUne fois que vous avez correctement remplacé ces variables, il vous suffit d’enregistrer le fichier au format YAML (au besoin l’extension à renseigner est .yml). Pour notre exemple ici, mon fichier s’appellera mirror_github_to_irdgitlab.yml et il sera placé comme indiqué précédemment dans le répertoire “workflows” que nous créer sur le dépôt cible GitHub.\n\n\n3.1.2 Utilisation de la fonction add_github_action() du package sparck\nSi vous préférez utiliser une approche simplifiée, vous pouvez utiliser comme cité précédemment le package R sparck et plus précisément la fonction associée add_github_action().\nPour cela, il faut commencer par l’installer sous R via la commande suivante :\n# Vous allez avoir besoin du package devtools pour récupérer le package sparck qui se trouve un dépôt GitHub\n# Si besoin utilisez install.packages(\"devtools\")\ndevtools::install_github(\"https://github.com/umr-marbec/sparck\")\nPour la suite, il faut définir le répertoire de travail de R comme étant celui de votre dépôt. Si vous utilisez un dépôt pour des codes en lien avec R, il est possible que vous ayez un fichier .Rproj dans ce dernier qui vous permet de lancer une session R directement dans le dépôt.\nLa dernière étape est de lancer la fonction add_github_action() avec les paramètres de configurations en lien avec votre environnement. Si nous reprenons notre exemple pour cette procédure, la ligne de commande sera la suivante :\nadd_github_action(github_action_name = \"mirror_github_git\",\n                  arguments = c(\"github_repository_source_url\" = \"https://github.com/umr-marbec/my_github_repository\",\n                                \"secret_token_name\" = \"TOKEN_MY_GITLABIRD_REPOSITORY\",\n                                \"git_repository_target_url\" = \"https://forge.ird.fr/marbec/private/depetris-mathieu/my_gitlabird_repository\"))\nEn comparaison d’une modification manuelle de notre “GitHub Action” (étape en 3.1.1), vous constaterez que les variables à renseigner sont beaucoup plus “simple” et que la fonction s’occupe automatiquement du formatage et de la création du dossier “.github” et sous-dossier “workflows” dans votre répertoire de travail (vous devez pour cela avoir les droits associés pour modifier votre système de fichiers).\n\n\n\n3.2 Configuration de la branche principale du dépôt cible\nÀ ce stage de la procédure, votre “GitHub action” devrais être fonctionnelle. Cependant si elle se lance (par exemple en faisant une modification, comme un “push”, sur notre dépôt source GitHub) vous devriez avoir une erreur comme celle illustrée sur la figure 6.\n\n\n\n\nFigure 6 : Erreur en lien avec une branche protégée\n\n\n\nRapidement cette erreur vous indique que la branche de notre dépôt cible est protégée et ne permet pas à notre processus de procéder à une synchronisation. Pour résoudre ce problème, il suffit de se rendre sur le dépôt cible, comme précédemment se aller sur l’onglet “Settings”, section “Repository” et sous-section “Protected branches” (figure 7).\n\n\n\n\nFigure 7 : Page “Protected branches”\n\n\n\nDe manière générale, les branches par défaut des gits sont souvent protégées. Cela permet à la majorité des utilisateurs d’appliquer automatique des mesures se sécurité qui permettent d’éviter d’opérer par mégarde des actes pouvant toucher à l’intégrité du dépôt. Dans notre cas, nous savons ce que nous voulons faire et nous avons besoin de lever ces protections afin de pouvoir effectuer notre miroir. Pour cela il suffit de cliquer sur le bouton rouge “Unprotect” sur votre branche par défaut (à ce stade vous ne devriez en avoir qu’une) et de l’action dans le popup qui s’affiche.\n\n\n\n4. Petit mot de la fin\nFélicitations, si vous êtes arrivé à ce point, vous devriez avoir un miroir fonctionnel entre vos deux dépôts, qui lance son processus associé à chaque modification sur le dépôt source.\nQuelques petits conseils pour la suite :\n\nn’hésitez pas à faire des retours sur cette procédure, surtout si vous avez des suggestions d’améliorations. Par exemple, le test de cette procédure sur plusieurs systèmes d’exploitation ou encore avec des spécifications différentes de celles cadrées ici (comme le test sur un dépôt source privée) seraient des retours très enrichissants.\nlors des tests ad hoc, nous avons noté certains ratés dans les processus de miroir. Concrètement vos actions “ordinaires” liées à l’intégration de codes, la création de branches ou la majorité des actions basiques n’ont montré aucune défaillance. Par contre quand vous allez commencer à effectuer des “realeases”, ajouter des “assets” à ces dernières, jouer un peu avec les limites en supprimant ces dernières, les “tags” associés …. il est arrivé que le miroir ne se déclenche pas. Normalement la chose est rapidement compensée par le prochain miroir sur un “commit” par exemple, mais n’hésitez pas à faire remonter des défaillances afin que nous puissions améliorer la procédure.",
    "crumbs": [
      "Liens utiles",
      "Système de contrôle de version",
      "Miroir depuis Github vers un dépôt git"
    ]
  }
]