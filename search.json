[
  {
    "objectID": "pages/serveurs/marbec_data/index_marbec_data.html",
    "href": "pages/serveurs/marbec_data/index_marbec_data.html",
    "title": "Introduction à marbec-data",
    "section": "",
    "text": "marbec-data est un NFS. Un NFS est un protocole réseau qui permet à plusieurs appareils connectés à un réseau de partager des fichiers et des répertoires. Cela permet aux chercheurs de stocker leurs données d’entrée, leurs codes et leurs résultats, tout en bénéficiant d’une sauvegarde centralisée et de la possibilité d’accéder à leurs fichiers depuis n’importe quelle machine connectée au cluster.\nPour simplifier, et en reprenant l’analogie avec votre PC actuel, marbec-data prend la place du stockage (c’est-à-dire du disque dur) dans le HPC.\nD’un autre côté, un cluster de calcul est essentiellement un ensemble d’éléments informatiques interconnectés qui fonctionnent de manière coordonnée pour exécuter des processus de calcul complexes. Dans l’analogie avec votre PC, marbec-gpu correspond à votre processeur principal (CPU), à votre processeur graphique (GPU), à la mémoire RAM générale et à la mémoire vidéo. Bien sûr, ces simplifications laissent de côté certains détails importants que nous expliquerons plus en profondeur au fur et à mesure des besoins.\n\n\nCela dépend de ce que nous devons faire. Si nous voulons simplement jeter un coup d’œil rapide aux fichiers et vérifier certains aspects de notre compte, il suffit d’ouvrir une fenêtre de navigateur et de se rendre à l’adresse suivante : https://marbec-data.ird.fr/.\nUne interface de connexion apparaîtra, où nous devrons entrer nos identifiants (fournis par les administrateurs de marbec-gpu).\n\nUne fois connectés, nous verrons une sorte de bureau avec quelques icônes permettant d’accéder à nos répertoires partagés et à la documentation générale sur l’utilisation de la plateforme.\n\n\n\n\nCommencez par cliquer sur l’icône des options utilisateur (celle qui ressemble à une petite personne) en haut à droite du bureau, puis sélectionnez l’option Personnel.\n\nUne petite fenêtre s’ouvrira. Dans l’onglet affiché par défaut (Compte), vous aurez accès à l’option Changer le mot de passe.\nDans l’onglet Préférences d’affichage, vous pourrez également modifier certains paramètres, comme la langue de l’interface ou l’image et les couleurs du bureau.\n\n\n\n\nDepuis la même fenêtre Personnel mentionnée précédemment, dans l’onglet Quota, vous pourrez vérifier la limite de stockage qui vous est attribuée ainsi que l’espace utilisé dans chacun des dossiers associés à votre utilisateur.\nCela vous permet d’avoir une vue graphique simple de l’espace restant disponible.\nSi vous avez besoin de plus d’espace, vous pouvez en faire la demande par e-mail auprès des administrateurs de marbec-data.\n\n\n\n\n\n\n\nImportant\n\n\n\nSi, au cours de l’exécution d’un processus, la limite de quota allouée est atteinte, le système bloquera toute tentative d’enregistrement de fichiers, ce qui entraînera soit l’arrêt inopiné du processus, soit des erreurs liées aux problèmes d’écriture sur le disque.\n\n\n\n\n\nNous avons un article où nous développons ce point plus en détail.\n\n\n\n\n\n\nImportant\n\n\n\nIl est très important de définir des mots de passe robustes (composés de lettres, chiffres, symboles et majuscules/minuscules) et, de préférence, d’utiliser des mots de passe différents pour marbec-data et marbec-gpu.\nPar ailleurs, l’environnement JupyterLab permet d’utiliser les raccourcis classiques comme Ctrl+C-Ctrl+V (ou Cmd+C-Cmd+V sous macOS) pour copier-coller des chaînes de caractères. Il est donc possible de les utiliser lors du changement de mot de passe avec la commande passwd.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/index_marbec_data.html#comment-accéder-à-marbec-data",
    "href": "pages/serveurs/marbec_data/index_marbec_data.html#comment-accéder-à-marbec-data",
    "title": "Introduction à marbec-data",
    "section": "",
    "text": "Cela dépend de ce que nous devons faire. Si nous voulons simplement jeter un coup d’œil rapide aux fichiers et vérifier certains aspects de notre compte, il suffit d’ouvrir une fenêtre de navigateur et de se rendre à l’adresse suivante : https://marbec-data.ird.fr/.\nUne interface de connexion apparaîtra, où nous devrons entrer nos identifiants (fournis par les administrateurs de marbec-gpu).\n\nUne fois connectés, nous verrons une sorte de bureau avec quelques icônes permettant d’accéder à nos répertoires partagés et à la documentation générale sur l’utilisation de la plateforme.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/index_marbec_data.html#comment-changer-notre-mot-de-passe-dans-marbec-data",
    "href": "pages/serveurs/marbec_data/index_marbec_data.html#comment-changer-notre-mot-de-passe-dans-marbec-data",
    "title": "Introduction à marbec-data",
    "section": "",
    "text": "Commencez par cliquer sur l’icône des options utilisateur (celle qui ressemble à une petite personne) en haut à droite du bureau, puis sélectionnez l’option Personnel.\n\nUne petite fenêtre s’ouvrira. Dans l’onglet affiché par défaut (Compte), vous aurez accès à l’option Changer le mot de passe.\nDans l’onglet Préférences d’affichage, vous pourrez également modifier certains paramètres, comme la langue de l’interface ou l’image et les couleurs du bureau.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/index_marbec_data.html#vérifier-lespace-disponible-dans-marbec-data",
    "href": "pages/serveurs/marbec_data/index_marbec_data.html#vérifier-lespace-disponible-dans-marbec-data",
    "title": "Introduction à marbec-data",
    "section": "",
    "text": "Depuis la même fenêtre Personnel mentionnée précédemment, dans l’onglet Quota, vous pourrez vérifier la limite de stockage qui vous est attribuée ainsi que l’espace utilisé dans chacun des dossiers associés à votre utilisateur.\nCela vous permet d’avoir une vue graphique simple de l’espace restant disponible.\nSi vous avez besoin de plus d’espace, vous pouvez en faire la demande par e-mail auprès des administrateurs de marbec-data.\n\n\n\n\n\n\n\nImportant\n\n\n\nSi, au cours de l’exécution d’un processus, la limite de quota allouée est atteinte, le système bloquera toute tentative d’enregistrement de fichiers, ce qui entraînera soit l’arrêt inopiné du processus, soit des erreurs liées aux problèmes d’écriture sur le disque.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/index_marbec_data.html#comment-gérer-les-fichiers-dans-marbec-data-ou-entre-marbec-data-et-notre-pc",
    "href": "pages/serveurs/marbec_data/index_marbec_data.html#comment-gérer-les-fichiers-dans-marbec-data-ou-entre-marbec-data-et-notre-pc",
    "title": "Introduction à marbec-data",
    "section": "",
    "text": "Nous avons un article où nous développons ce point plus en détail.\n\n\n\n\n\n\nImportant\n\n\n\nIl est très important de définir des mots de passe robustes (composés de lettres, chiffres, symboles et majuscules/minuscules) et, de préférence, d’utiliser des mots de passe différents pour marbec-data et marbec-gpu.\nPar ailleurs, l’environnement JupyterLab permet d’utiliser les raccourcis classiques comme Ctrl+C-Ctrl+V (ou Cmd+C-Cmd+V sous macOS) pour copier-coller des chaînes de caractères. Il est donc possible de les utiliser lors du changement de mot de passe avec la commande passwd.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA"
    ]
  },
  {
    "objectID": "pages/serveurs/index_serveurs.html",
    "href": "pages/serveurs/index_serveurs.html",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "Le DEN Marbec propose deux serveurs, un serveur de calcul MARBEC-GPU et un serveur de stockage MARBEC-DATA. Une documentation collaborative est en cours de rédaction pour vous permettre de vous familiariser avec ces serveurs. Vous pouvez dès maintenant consulter les pages de présentation de ces serveurs et quelques basiques tutoriels pour vous aider à démarrer :\n\nMARBEC-GPU Intro\nTutoriels MARBEC-GPU\nMARBEC-DATA Intro\nGestion des données sur MARBEC-DATA\n\nTout utilisateur voulant contribuer à la documentation ou faire des retours est le bienvenu : comment contribuer.\nBonne utilisation !\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Serveurs"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/run_r_script.html",
    "href": "pages/serveurs/marbec_gpu/run_r_script.html",
    "title": "Running R scripts in marbec-gpu",
    "section": "",
    "text": "As when working with RStudio locally (i.e. on our PC), it is recommended to clearly define our working directory. This is extremely important because any process we run (either from RStudio or Terminal) will use that directory as a reference to find input files, output files or even other scripts.\nFor our case, we have created a folder called mgpu-examples/ where there is a subfolder called code/. The creation of folders in marbec-data can be done directly from the web interface (by clicking on File station and then using the Create folder button), the command mkdir, but we can also copy-paste the elements already existing in our PC into the working folder.\n\n\n\nThe following is NOT mandatory, but very useful, especially when working with RStudio and that is to create an RStudio project. To do this, we will go to File and then New Project.\n\nThen, in the window that appears, click on Existing directory, then on Browse and click on the folder that we have defined as our working directory (in our case, mgpu-examples/). Then, OK and finally click on the Create Project button. Rstudio will flicker a little bit and then will show us the same window, but inside the set project. The easiest way to check that the project has been created in the correct folder (mgpu-examples/ in our case) is to verify that right in the Console panel, to the right of the R version, appears only the path of our main folder (and not any of the subfolders, e.g. mgpu-examples/code/ or mgpu-examples/inputs/).\n\n\n\n\n\n\n\nCautionJust before to say hello\n\n\n\nmarbec-gpu incorporates the possibility of working with RStudio (Server); however, this interface should be used ONLY to PREPARE our scripts before being executed using all the power of our server. In other words, within the RStudio environment we will be able to load not so big files and perform basic operations, but at no time should we execute a complex (heavy) process from there, but from Terminal.\n\n\n\n\n\n\n\n\nWe will start with the simplest: create a script in R and print the (very famous) “Hello world!” message.\n\nWe will start by opening an RStudio session from the JupyterLab environment (if you want to know how to get there, check the post of Introduction to marbec-gpu).\nOnce inside the RStudio environment, we will create a new script (File -&gt; New file -&gt; R script) which will contain a single line:\n\n\nprint(\"Hello world and hello marbec-gpu!\")\n\nThen, we will save that script with the name code/ex1-1.R (code/ refers to a subfolder created previously inside the working directory of our project in RStudio).\nNow comes the interesting part, inside our browser, we must go back to the Launcher tab and open a Terminal window (clicking on the corresponding icon).\nBy default, Terminal will open a session in the local folder assigned to our user. From there, we must get to the folder we have set as working directory; that is, the folder that our script will recognize as working directory (whether we have decided to use RStudio or not to create it or create a project inside it). Assuming that our working directory is the mgpu-examples/ folder, we must reach it using the cd command:\n\ncd mgpu-examples/\n\n\n\n\n\n\nTipHow do we know that we have arrived at the correct folder?\n\n\n\nFirst, the prompt will indicate the name of the folder in which it is located.\n\nIn addition, we can run the ls command which will show the subfolders and files inside the folder we have reached. If everything matches, then we did well.\n\n\n\n\nNext, we execute the following command in the Terminal: Rscript code/ex1-1.R and the result should be just what would be shown in a usual R session.\n\n\n\n\n\nIn this next example, we will show a script that generates and saves files in our working directory where previously, we will create two new folders (figures/ and outputs/) through the mkdir command as follows:\nmkdir figures/ outputs/\n\n\n\n\n\n\nNote\n\n\n\nWithin the Terminal environment, it is not possible to observe graphics interactively (as in RStudio), so if you want to keep any figure, you must always include the code to save it within the script you execute. Depending on the graphical environment, we can use functions such as png, bmp, jpeg, pdf (for graphics environment), or ggsave (for ggplot2 environment).\n\n\n\nNow, let’s go to RStudio to create the following script and save it in code/ex1-2.R:\n\n# Print mtcars\nprint(mtcars)\n\n# Export mtcars as a csv\nwrite.csv(x = mtcars, file = \"outputs/mtcars.csv\")\n \n# Create and save a scatterplot\npng(filename = \"figures/fig_1-1.png\")\n\nplot(x = mtcars$mpg, y = mtcars$disp, \n     xlab = \"Miles per (US) gallon\", ylab = \"Displacement (cu.in.)\")\n\ndev.off()\n\nNext, we go back to the Terminal environment and run our new script with the command Rscript code/ex1-2.R. Immediately, the mtcars table will be displayed as that is what the first line of our script commands.\n\n\n\nHowever, if we run the ls command in Terminal for the figures/ and outputs/ folders, we will see that the two files we ordered to be created inside our script appear.\n\n\n\nIf the files created are the ones we expect to collect from our analysis, we can download them through Filezilla (see the corresponding post).\n\n\n\n\n\n\n\nTipPreviewing figures\n\n\n\nWhile it is not possible to preview figures in Terminal or JupyterLab because they do not have an image viewer, it is possible to do so from the marbec-data web environment. However, this is a basic viewer and only available for the most common file types.\n\n\n\n\n\n\n\n\n\nWe will start by creating a script (which we will save as code/ex2-1.R) containing a simple loop that generates 20 100x100 arrays with random values and saves them in separate csv files inside the outputs/ex2-rndmats/ folder (remember to create that folder beforehand using mkdir):\n\n# Setting number of rows and columns\nrow_n &lt;- 100\ncol_n &lt;- 100\n\nfor(i in seq(20)){\n  # Create random matrix\n  rndMat &lt;- matrix(data = runif(n = row_n*col_n), nrow = row_n, ncol = col_n)\n  \n  # Save matrix\n  write.csv(x = rndMat, \n            file = sprintf(fmt = \"outputs/ex2-rndmats/mat_%02d.csv\", i), \n            row.names = FALSE)\n  \n  # Print a message at the end of each step\n  cat(sprintf(fmt = \"Matrix %02d finished!\\n\", i))\n}\n\nNow, we will run our script in Terminal (with the command Rscript code/ex2-1.R) and we will observe that everything went well if the messages at the end of each step of the loop are displayed correctly and also if when we run the command ls on the target folder we see the files created:\n\n\n\n\n\n\n\n\nTipRun a small example first\n\n\n\nBeing already in a real execution, it is highly recommended always to try with a small example that allows us to corroborate that our script goes well BEFORE to pull out all the stops trying to execute the heavy process. In addition, if our script returns figures or files, executing a small corroboration script allows us to quickly check if the generated files are consistent with what we expect to obtain.\n\n\n\n\n\n\nStarting from the previous example, we will convert our script into one that executes the processes in parallel. For this we will take advantage of the tools of the packages foreach and doParallel. Note that the names of the files of this script will begin with the letters mc_ to be able to recognize them with respect to those obtained in the previous example:\n\n# Setting number of rows and columns\nrow_n &lt;- 100\ncol_n &lt;- 100\n\nrequire(foreach)\nrequire(doParallel)\n\n# Registering cluster\ncl &lt;- makeCluster(spec = 20)\nregisterDoParallel(cl = cl)\n\n# Run multithread process\nout &lt;- foreach(i = seq(20), .inorder = FALSE) %dopar% {\n# Create random matrix\n  rndMat &lt;- matrix(data = runif(n = row_n*col_n), nrow = row_n, ncol = col_n)\n  \n  # Save matrix\n  write.csv(x = rndMat, \n            file = sprintf(fmt = \"outputs/ex2-rndmats/mc_mat_%02d.csv\", i), \n            row.names = FALSE)\n  \n  NULL\n}\n\n# Finish cluster\nstopCluster(cl)\n\nNow, we will run our script in Terminal (with the command Rscript code/ex2-2.R) and we will observe that everything has gone well if when executing the command ls on the target folder we see the created files:\n\n\n\n\n\n\n\n\nNote\n\n\n\nA couple of things:\n\nIn the script of the second example, foreach is assigned to an object (out) which will receive the last object generated within each step of the loop. If you only want to get files to be exported (figures, tables, NetCDF, etc.), be sure to leave a NULL in the last line of the loop. On the other hand, if you want to get an object and it is placed in that position, foreach will compile it using the list function, i.e. the final object (out) will be a list that will have as many levels as there are steps in the loop. Also, it is important to note that internally foreach runs a separate small R session so it is necessary to indicate the additional packages required through the .packages argument (see the following example).\nThe argument spec = 20 inside makeCluster refers to the amount of threads that will be used to execute the loop. Remember that one of the options when creating your server in marbec-gpu was to choose the amount of CPUs (2, 4, 8, 16, 32…)? Well, it is precisely with this argument where you will indicate that amount of logical cores. Remember that another important aspect is the RAM. At a given time each process running within each thread will have to load everything that a single simple process would need. In other words, if in a single core process, in each step of our loop we have to load 5 NetCDF files that occupy 5 GB in RAM, if we run that process in multicore and we define spec = 40, at a given moment we will have to load 5GBx40 (200 GB) in RAM simultaneously. So not only you must choose well the configuration of your server (regarding the script you plan to run), but also an approximate of what is consumed in each independent process, in order not to saturate your server. marbec-gpu is great, but it has its limits.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "R Scripts Running"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/run_r_script.html#lets-tidy-up-a-bit",
    "href": "pages/serveurs/marbec_gpu/run_r_script.html#lets-tidy-up-a-bit",
    "title": "Running R scripts in marbec-gpu",
    "section": "",
    "text": "As when working with RStudio locally (i.e. on our PC), it is recommended to clearly define our working directory. This is extremely important because any process we run (either from RStudio or Terminal) will use that directory as a reference to find input files, output files or even other scripts.\nFor our case, we have created a folder called mgpu-examples/ where there is a subfolder called code/. The creation of folders in marbec-data can be done directly from the web interface (by clicking on File station and then using the Create folder button), the command mkdir, but we can also copy-paste the elements already existing in our PC into the working folder.\n\n\n\nThe following is NOT mandatory, but very useful, especially when working with RStudio and that is to create an RStudio project. To do this, we will go to File and then New Project.\n\nThen, in the window that appears, click on Existing directory, then on Browse and click on the folder that we have defined as our working directory (in our case, mgpu-examples/). Then, OK and finally click on the Create Project button. Rstudio will flicker a little bit and then will show us the same window, but inside the set project. The easiest way to check that the project has been created in the correct folder (mgpu-examples/ in our case) is to verify that right in the Console panel, to the right of the R version, appears only the path of our main folder (and not any of the subfolders, e.g. mgpu-examples/code/ or mgpu-examples/inputs/).\n\n\n\n\n\n\n\nCautionJust before to say hello\n\n\n\nmarbec-gpu incorporates the possibility of working with RStudio (Server); however, this interface should be used ONLY to PREPARE our scripts before being executed using all the power of our server. In other words, within the RStudio environment we will be able to load not so big files and perform basic operations, but at no time should we execute a complex (heavy) process from there, but from Terminal.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "R Scripts Running"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/run_r_script.html#hello-world-simple-examples",
    "href": "pages/serveurs/marbec_gpu/run_r_script.html#hello-world-simple-examples",
    "title": "Running R scripts in marbec-gpu",
    "section": "",
    "text": "We will start with the simplest: create a script in R and print the (very famous) “Hello world!” message.\n\nWe will start by opening an RStudio session from the JupyterLab environment (if you want to know how to get there, check the post of Introduction to marbec-gpu).\nOnce inside the RStudio environment, we will create a new script (File -&gt; New file -&gt; R script) which will contain a single line:\n\n\nprint(\"Hello world and hello marbec-gpu!\")\n\nThen, we will save that script with the name code/ex1-1.R (code/ refers to a subfolder created previously inside the working directory of our project in RStudio).\nNow comes the interesting part, inside our browser, we must go back to the Launcher tab and open a Terminal window (clicking on the corresponding icon).\nBy default, Terminal will open a session in the local folder assigned to our user. From there, we must get to the folder we have set as working directory; that is, the folder that our script will recognize as working directory (whether we have decided to use RStudio or not to create it or create a project inside it). Assuming that our working directory is the mgpu-examples/ folder, we must reach it using the cd command:\n\ncd mgpu-examples/\n\n\n\n\n\n\nTipHow do we know that we have arrived at the correct folder?\n\n\n\nFirst, the prompt will indicate the name of the folder in which it is located.\n\nIn addition, we can run the ls command which will show the subfolders and files inside the folder we have reached. If everything matches, then we did well.\n\n\n\n\nNext, we execute the following command in the Terminal: Rscript code/ex1-1.R and the result should be just what would be shown in a usual R session.\n\n\n\n\n\nIn this next example, we will show a script that generates and saves files in our working directory where previously, we will create two new folders (figures/ and outputs/) through the mkdir command as follows:\nmkdir figures/ outputs/\n\n\n\n\n\n\nNote\n\n\n\nWithin the Terminal environment, it is not possible to observe graphics interactively (as in RStudio), so if you want to keep any figure, you must always include the code to save it within the script you execute. Depending on the graphical environment, we can use functions such as png, bmp, jpeg, pdf (for graphics environment), or ggsave (for ggplot2 environment).\n\n\n\nNow, let’s go to RStudio to create the following script and save it in code/ex1-2.R:\n\n# Print mtcars\nprint(mtcars)\n\n# Export mtcars as a csv\nwrite.csv(x = mtcars, file = \"outputs/mtcars.csv\")\n \n# Create and save a scatterplot\npng(filename = \"figures/fig_1-1.png\")\n\nplot(x = mtcars$mpg, y = mtcars$disp, \n     xlab = \"Miles per (US) gallon\", ylab = \"Displacement (cu.in.)\")\n\ndev.off()\n\nNext, we go back to the Terminal environment and run our new script with the command Rscript code/ex1-2.R. Immediately, the mtcars table will be displayed as that is what the first line of our script commands.\n\n\n\nHowever, if we run the ls command in Terminal for the figures/ and outputs/ folders, we will see that the two files we ordered to be created inside our script appear.\n\n\n\nIf the files created are the ones we expect to collect from our analysis, we can download them through Filezilla (see the corresponding post).\n\n\n\n\n\n\n\nTipPreviewing figures\n\n\n\nWhile it is not possible to preview figures in Terminal or JupyterLab because they do not have an image viewer, it is possible to do so from the marbec-data web environment. However, this is a basic viewer and only available for the most common file types.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "R Scripts Running"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/run_r_script.html#hello-universe-parallel-process",
    "href": "pages/serveurs/marbec_gpu/run_r_script.html#hello-universe-parallel-process",
    "title": "Running R scripts in marbec-gpu",
    "section": "",
    "text": "We will start by creating a script (which we will save as code/ex2-1.R) containing a simple loop that generates 20 100x100 arrays with random values and saves them in separate csv files inside the outputs/ex2-rndmats/ folder (remember to create that folder beforehand using mkdir):\n\n# Setting number of rows and columns\nrow_n &lt;- 100\ncol_n &lt;- 100\n\nfor(i in seq(20)){\n  # Create random matrix\n  rndMat &lt;- matrix(data = runif(n = row_n*col_n), nrow = row_n, ncol = col_n)\n  \n  # Save matrix\n  write.csv(x = rndMat, \n            file = sprintf(fmt = \"outputs/ex2-rndmats/mat_%02d.csv\", i), \n            row.names = FALSE)\n  \n  # Print a message at the end of each step\n  cat(sprintf(fmt = \"Matrix %02d finished!\\n\", i))\n}\n\nNow, we will run our script in Terminal (with the command Rscript code/ex2-1.R) and we will observe that everything went well if the messages at the end of each step of the loop are displayed correctly and also if when we run the command ls on the target folder we see the files created:\n\n\n\n\n\n\n\n\nTipRun a small example first\n\n\n\nBeing already in a real execution, it is highly recommended always to try with a small example that allows us to corroborate that our script goes well BEFORE to pull out all the stops trying to execute the heavy process. In addition, if our script returns figures or files, executing a small corroboration script allows us to quickly check if the generated files are consistent with what we expect to obtain.\n\n\n\n\n\n\nStarting from the previous example, we will convert our script into one that executes the processes in parallel. For this we will take advantage of the tools of the packages foreach and doParallel. Note that the names of the files of this script will begin with the letters mc_ to be able to recognize them with respect to those obtained in the previous example:\n\n# Setting number of rows and columns\nrow_n &lt;- 100\ncol_n &lt;- 100\n\nrequire(foreach)\nrequire(doParallel)\n\n# Registering cluster\ncl &lt;- makeCluster(spec = 20)\nregisterDoParallel(cl = cl)\n\n# Run multithread process\nout &lt;- foreach(i = seq(20), .inorder = FALSE) %dopar% {\n# Create random matrix\n  rndMat &lt;- matrix(data = runif(n = row_n*col_n), nrow = row_n, ncol = col_n)\n  \n  # Save matrix\n  write.csv(x = rndMat, \n            file = sprintf(fmt = \"outputs/ex2-rndmats/mc_mat_%02d.csv\", i), \n            row.names = FALSE)\n  \n  NULL\n}\n\n# Finish cluster\nstopCluster(cl)\n\nNow, we will run our script in Terminal (with the command Rscript code/ex2-2.R) and we will observe that everything has gone well if when executing the command ls on the target folder we see the created files:\n\n\n\n\n\n\n\n\nNote\n\n\n\nA couple of things:\n\nIn the script of the second example, foreach is assigned to an object (out) which will receive the last object generated within each step of the loop. If you only want to get files to be exported (figures, tables, NetCDF, etc.), be sure to leave a NULL in the last line of the loop. On the other hand, if you want to get an object and it is placed in that position, foreach will compile it using the list function, i.e. the final object (out) will be a list that will have as many levels as there are steps in the loop. Also, it is important to note that internally foreach runs a separate small R session so it is necessary to indicate the additional packages required through the .packages argument (see the following example).\nThe argument spec = 20 inside makeCluster refers to the amount of threads that will be used to execute the loop. Remember that one of the options when creating your server in marbec-gpu was to choose the amount of CPUs (2, 4, 8, 16, 32…)? Well, it is precisely with this argument where you will indicate that amount of logical cores. Remember that another important aspect is the RAM. At a given time each process running within each thread will have to load everything that a single simple process would need. In other words, if in a single core process, in each step of our loop we have to load 5 NetCDF files that occupy 5 GB in RAM, if we run that process in multicore and we define spec = 40, at a given moment we will have to load 5GBx40 (200 GB) in RAM simultaneously. So not only you must choose well the configuration of your server (regarding the script you plan to run), but also an approximate of what is consumed in each independent process, in order not to saturate your server. marbec-gpu is great, but it has its limits.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "R Scripts Running"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/intro_marbec_gpu.html",
    "href": "pages/serveurs/marbec_gpu/intro_marbec_gpu.html",
    "title": "Initiation au cluster de calcul Marbec-GPU",
    "section": "",
    "text": "Initiation au cluster de calcul Marbec-GPU\nUne video de présentation du cluster sera bientôt disponible.\n\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Initiation"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/basic_example.html",
    "href": "pages/serveurs/marbec_gpu/basic_example.html",
    "title": "Exécuter un exemple simple sur Marbec-GPU",
    "section": "",
    "text": "Tout au long de ce tutoriel, vous trouverez tout ce dont vous avez besoin pour éxécuter un script Python ou R ( afficher “Hello World &lt;3”), ainsi que des conseils et des ressources supplémentaires qui vous seront utiles pour d’autres tâches sur MARBEC-GPU.\nIl y a deux grandes manières pour exécuter un programme sur Marbec-GPU. La première est d’utiliser un script de soumission de tâche, la deuxième est d’utiliser la session de manière intéractive. Dans cet exemple, nous allons utiliser la première méthode qui est de loin la plus adpatée et facilment adaptable pour des programme plus complexe.\n\n\n\n\n\n\nNote\n\n\n\nLorque vous voudrez exécuter un programme plus complexe, assurez-vous que votre projet fonctionne localement (sur votre ordinateur personnel). Cela signifie configurer votre environnement correctement et déboguer votre script localement. Une fois que tout fonctionne avec succès sur votre PC (même en utilisant seulement 1% de l’ensemble de données si vous rencontrez des contraintes de calcul), vous pouvez ensuite déployer votre projet sur MARBEC-GPU.\n\n\nCommencez par créer un dossier de travail dans lequel les différents fichiers seront créés. En commande bash cela donnerait :\ncd ~  # aller dans le répertoire personnel\nmkdir mon_projet_python  # créer un dossier pour le projet\nSinon il est possible d’utliser l’interface Jupyter pour créer un dossier de travail avec l’icone encadrée en rouge ci-dessous :\n\n\n\nCréer un dossier de travail\n\n\nPlacez vous ensuite dans ce dossier ( cd mon_projet_python/ ou doucle clic sur le dossier visible sur la gauche de l’interphace).",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Soumission SLURM  : Exemple R/Python Basique"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/basic_example.html#préparer-le-script-python-ou-r",
    "href": "pages/serveurs/marbec_gpu/basic_example.html#préparer-le-script-python-ou-r",
    "title": "Exécuter un exemple simple sur Marbec-GPU",
    "section": "1. Préparer le script Python ou R",
    "text": "1. Préparer le script Python ou R\nCréez un script python ou R simple qui affiche “Hello World &lt;3”. Voici un exemple de script :\nprint(\"Hello World &lt;3\")\nEnregistrez ce script dans un fichier nommé main.py ou main.R (en fonction du languge voulu) dans le dossier de travail que vous avez créé précédemment.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Soumission SLURM  : Exemple R/Python Basique"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/basic_example.html#préparer-un-script-bash-avec-les-arguments-slurm",
    "href": "pages/serveurs/marbec_gpu/basic_example.html#préparer-un-script-bash-avec-les-arguments-slurm",
    "title": "Exécuter un exemple simple sur Marbec-GPU",
    "section": "2. Préparer un script Bash avec les arguments SLURM",
    "text": "2. Préparer un script Bash avec les arguments SLURM\nAfin de d’exécuter correctement le script vous aurez besion de créer un script bash launch.sh en prenant soin de mentionner :\n\nles arguments SLURM, permmant de spécifier quelles ressources allouer, le nom du job, le fichier de sortie, etc.\nl’exécution du script Python/R.\n\nVoici un exemple minimal de script bash :\n#!/bin/bash\n\n#SBATCH --job-name=my_job         # Job name\n#SBATCH --output=job_%j.out`      # Standard output and error log\n#SBATCH --gres=gpu:1             # Number of GPUs (Supprimer la ligne si aucun GPU n’est requis.)\n#SBATCH --mem=4G                  # Memory allocation (4 GB)\n#SBATCH -c 1                      # Number of CPU cores\n\n# execute python file\npython main.py                    \n\n# execute R file\nRscript main.R\nIl possible de spécifier d’autres arguments SLURM. Pour plus d’informations sur les arguments SLURM, vous pouvez consulter la documentation officielle de SLURM ici.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Soumission SLURM  : Exemple R/Python Basique"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/basic_example.html#exécuter-le-script-bash",
    "href": "pages/serveurs/marbec_gpu/basic_example.html#exécuter-le-script-bash",
    "title": "Exécuter un exemple simple sur Marbec-GPU",
    "section": "3. Exécuter le script Bash",
    "text": "3. Exécuter le script Bash\nA l’issu des 2 étapes précédentes, le dossier de travail devrait contenir les fichiers suivants : launch.sh et main.py/main.R :  La dernière étape consiste à soumettre votre script launch.sh créé à la partie précédente. Pour cela vous devez utiliser la commande sbatch (voir documentation).\nDans le terminal, exécutez la commande suivante : &gt; sbatch launch.sh\nSi les parramètres SLURM (#SBATCH arg) sont bien renseignés, vous devriez voir un message de confirmation de soumission de votre job : Submitted batch job 1234567. Sinon un message d’erreur s’affiche à la place. Lors d’une soumission réussie, SLURM regarde les ressources demandées et place le job en file d’attente ( état PENDING) tant que les ressources ne sont pas disponibles. Une fois les ressources disponibles, le job s’exécute (état RUNNING). Un fichier de sortie est alors créé dans le répertoire courant avec le nom renseigné dans le script bash (#SBATCH --output=job_%j.out). Un deuxième fichier contenant les messages d’erreur peut apparaître si cela est spécifié (#SBATCH --error=job_%j.err).\nIl est possible de suivre l’avancement de votre job avec la commande squeue -u $USER ou squeue -j 1234567 (avec 1234567 le numéro de votre job). Mais aussi de lister tous les jobs en cours d’exécution ou en file d’attente avec squeue -O NAME,UserName,TimeUsed,tres-per-node,state,JOBID. La colonne STATE notamment indique l’état du job (PENDING RUNNING). Pour plus de détail sur la command squeue vous pouvez consulter la documentation.\nPour annuler un job (en cours d’éxecution ou encore en file d’attente), utilisez la commande scancel 1234567 (avec 1234567 le numéro de votre job).\nLe fichier output.log contenant les sorties de votre script python est créé dans le répertoire courant. Vous pouvez le consulter avec la commande cat output.log ou simplement en double-cliquant dessus. Si tout s’est bien passé, le fichier doit ressembler à ceci :\nHello World &lt;3",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Soumission SLURM  : Exemple R/Python Basique"
    ]
  },
  {
    "objectID": "pages/packages_logiciels/ichthyop.html",
    "href": "pages/packages_logiciels/ichthyop.html",
    "title": "Logiciel Ichthyop",
    "section": "",
    "text": "Ichthyop est un outil Java gratuit conçu pour étudier les effets des facteurs physiques et biologiques sur la dynamique de l’ichtyoplancton.\nIl intègre les processus les plus importants impliqués dans les premiers stades de la vie des poissons : le frai, le mouvement, la croissance, la mortalité et le recrutement. L’outil utilise en entrée des séries temporelles de champs de vitesse, de température et de salinité archivées à partir des modèles océaniques ROMS, MARS, NEMO ou SYMPHONIE (sous forme de fichiers ou d’OpenDAP).\nLe logiciel Ichthyop et ses ressources associées sont disponibles sur GitHub.",
    "crumbs": [
      "Liens utiles",
      "Packages et logiciels",
      "Logiciel Ichthyop"
    ]
  },
  {
    "objectID": "pages/packages_logiciels/ichthyop.html#outil-lagrangien-pour-la-simulation-de-la-dynamique-de-lichthyoplancton",
    "href": "pages/packages_logiciels/ichthyop.html#outil-lagrangien-pour-la-simulation-de-la-dynamique-de-lichthyoplancton",
    "title": "Logiciel Ichthyop",
    "section": "",
    "text": "Ichthyop est un outil Java gratuit conçu pour étudier les effets des facteurs physiques et biologiques sur la dynamique de l’ichtyoplancton.\nIl intègre les processus les plus importants impliqués dans les premiers stades de la vie des poissons : le frai, le mouvement, la croissance, la mortalité et le recrutement. L’outil utilise en entrée des séries temporelles de champs de vitesse, de température et de salinité archivées à partir des modèles océaniques ROMS, MARS, NEMO ou SYMPHONIE (sous forme de fichiers ou d’OpenDAP).\nLe logiciel Ichthyop et ses ressources associées sont disponibles sur GitHub.",
    "crumbs": [
      "Liens utiles",
      "Packages et logiciels",
      "Logiciel Ichthyop"
    ]
  },
  {
    "objectID": "pages/packages_logiciels/osmose.html",
    "href": "pages/packages_logiciels/osmose.html",
    "title": "Modèle Osmose",
    "section": "",
    "text": "OSMOSE est un modèle multi-espèces et basé sur l’individu (IBM) qui se concentre sur les espèces de poissons. Ce modèle suppose une prédation opportuniste basée sur la cooccurrence spatiale et l’adéquation de taille entre un prédateur et sa proie (prédation opportuniste basée sur la taille). Il représente des individus de poissons regroupés en bancs, caractérisés par leur taille, leur poids, leur âge, leur taxonomie et leur localisation géographique (modèle 2D), et qui subissent les principaux processus du cycle de vie des poissons (croissance, prédation explicite, mortalité naturelle et par inanition, reproduction et migration) et de l’exploitation par la pêche.\nLe modèle a besoin de paramètres biologiques de base qui sont souvent disponibles pour une large gamme d’espèces, et qui peuvent être trouvés dans FishBase par exemple, et de données sur la distribution spatiale des poissons. Ce paquetage fournit des outils pour construire un modèle et effectuer des simulations en utilisant le modèle OSMOSE.\nLe modèle est disponible sur GitHub.",
    "crumbs": [
      "Liens utiles",
      "Packages et logiciels",
      "Modèle Osmose"
    ]
  },
  {
    "objectID": "pages/packages_logiciels/osmose.html#simulateur-orienté-objet-des-écosystèmes-marins",
    "href": "pages/packages_logiciels/osmose.html#simulateur-orienté-objet-des-écosystèmes-marins",
    "title": "Modèle Osmose",
    "section": "",
    "text": "OSMOSE est un modèle multi-espèces et basé sur l’individu (IBM) qui se concentre sur les espèces de poissons. Ce modèle suppose une prédation opportuniste basée sur la cooccurrence spatiale et l’adéquation de taille entre un prédateur et sa proie (prédation opportuniste basée sur la taille). Il représente des individus de poissons regroupés en bancs, caractérisés par leur taille, leur poids, leur âge, leur taxonomie et leur localisation géographique (modèle 2D), et qui subissent les principaux processus du cycle de vie des poissons (croissance, prédation explicite, mortalité naturelle et par inanition, reproduction et migration) et de l’exploitation par la pêche.\nLe modèle a besoin de paramètres biologiques de base qui sont souvent disponibles pour une large gamme d’espèces, et qui peuvent être trouvés dans FishBase par exemple, et de données sur la distribution spatiale des poissons. Ce paquetage fournit des outils pour construire un modèle et effectuer des simulations en utilisant le modèle OSMOSE.\nLe modèle est disponible sur GitHub.",
    "crumbs": [
      "Liens utiles",
      "Packages et logiciels",
      "Modèle Osmose"
    ]
  },
  {
    "objectID": "pages/support/achats.html",
    "href": "pages/support/achats.html",
    "title": "Support et guide concernant les achats de ressources informatiques",
    "section": "",
    "text": "L’achat de matériels informatiques peut vite devenir compliqué, voir un enfer, dès que l’on commence à se poser des questions et que l’on cherche à optimiser son achat. Souvent il n’y a pas de réponse “parfaite” pour une ressource, et l’équation de décision d’achat qui est associé est souvent la combinaison de nombreux facteurs qui change tout le temps, notamment en lien avec les avancés technologiques et les besoins de chaque utilisateur (ces derniers étant bien sûr différent pour chacun de nous).\nL’objectif de cette page est de vous pousser à vous poser les bonnes questions, afin de pouvoir effectuer vos achats de manière éclairée et optimiser, surtout toujours en relation avec vos besoins. Par ailleurs, tout en étant très loin de l’exhaustivité des ressources types vous seront proposées en rapport avec des schémas logiques de besoins. Les achats sur les marchés publics seront prioritaires dans les propositions, mais pas exclusifs. Le moteur principal est votre besoin et ce n’est pas vous qui deviez répondre au besoin du marché, mais le contraire. Si ce dernier n’est pas en mesure de vous proposer le meilleur produit et le plus adapté à vos besoins, il ne fait pas son travail correctement.\nPour finir, sachez qu’au sein de l’UMR vous disposez de nombreux interlocuteurs qui peuvent vous aider et vous guider. Cela passe par les services informatiques des tutelles ou encore par des personnes comme les correspondants informatiques. En cas de doute, vous pouvez envoyer un mail à l’adresse suivante, marbec-correspondants-info@listes.ird.fr. Même si vous n’êtes pas au bon endroit, on vous redirigera avec plaisir vers la ou les bonnes personnes.",
    "crumbs": [
      "Liens utiles",
      "Support global",
      "Assistance pour l'achat de ressources informatiques"
    ]
  },
  {
    "objectID": "pages/support/achats.html#vitesse-de-transfert",
    "href": "pages/support/achats.html#vitesse-de-transfert",
    "title": "Support et guide concernant les achats de ressources informatiques",
    "section": "1.1 - Vitesse de transfert",
    "text": "1.1 - Vitesse de transfert\nLe premier element est en rapport avec le vitesse de transfert. Même s’il y a de nombreux paramètres dans l’équation globale (le controleur interne, le type de mémoire ou encore le système de fichiers), le plus simple est de regarder 3 paramètres: la vitesse de lecture et d’écriture séquentielle et le type d’interface USB.\nConcernant la vitesse de lecture et d’écriture séquentielle plus les valeurs associées seront élevés, plus la vitesse de transfert sera importante. Le mot d’ordre est de ne pas faire confiance aux données renseignées par défaut par le constructeur. Cela donne un ordre d’idée, mais souvent ces chiffres ne reflètent pas la réalité et ne tiennent pas compte d’autres variables, comme le déplacement de gros ou petits fichiers, d’un ou plusieurs à la fois ou même encore la dissipation thermique de la clé au cours du temps. Le mieux dans la pratique et de regarder les données indiquées par le fabricant pour avoir un ordre d’idée et de chercher sur internet des tests d’utilisation (pour cela il y a de très bons sites comme frandroid. Attention cependant quand vous regardez des tests, car les résultats peuvent être différent en fonction de la taille de stockage du périphérique (un résultat vrai pour une clé USB de 64 Go ne le sera pas forcément pour son équivalent en 512 Go). Concernant la notion de dissipation thermique, il est globalement déconseillé de se tourner vers des périphériques très compacts (par exemple des clés USB de la taille d’un ongle). Derrière l’aspect pratique, le connecteur n’est souvent pas protégé et les performances thermiques ne sont pas exceptionnelles (le périphérique chauffe beaucoup).\nL’autre paramètre important en rapport avec la vitesse de transfert est le type d’interface USB. Souvent il y a confusion entre l’interface (ou norme de vitesse) et le type de connecteur (la forme que prend le connecteur, figure 1).\n\n\n\nFigure 1 : Connecteurs USB\n\n\nPour s’y retrouver, voici ci-dessous un tableau résumé (Tableau 1)\n\n\nTableau 1 : Caractéristiques des interfaces USB\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterface\nDébit thérorique\nConnecteur\nCompatibilité\nPrend en charge la video\nPrend en charge le chargement\n\n\n\n\nUSB 1.0 - 1.1\n12 Mbit/s maximum (≈ 1.5 Mo/s)\nType-A et B\nUSB 1.x uniquement\nNon\nTrès faible (≤ 2.5W)\n\n\nUSB 2.0\n480 Mb/s (≈ 60 Mo/s)\nType-A et B\nUSB 1.x\nNon\nJusqu’a 2.5W\n\n\nUSB 3.0 et 3.2 Gen 1\n5 Gb/s (≈ 625 Mo/s)\nType-A et B\nUSB 2.0\nNon\nJusqu’a 4.5W\n\n\nUSB 3.1 et 3.2 Gen 2\n10 Gb/s (≈ 1.25 Go/s)\nType-A et C\nUSB 2.0 et 3.0\nNon\nJusqu’à 15W\n\n\nThunderbolt 1 et 2\n10/20 Gb/s\nMini DisplayPort\nMac/Intel uniquement\nOui\n- Jusqu’à ~10W (non standardisé)\n\n\nUSB 3.2 Gen 2x2\n20 Gb/s (≈ 2.5 Go/s)\nType-C\nUSB 3.x\nNon\nJusqu’à 100W (Power Delivery 3.0)\n\n\nThunderbolt 3 et 4\n40 Gb/s\nType-C (logo éclair)\nUSB 4, USB 3.x, DisplayPort et PCIe pour v4\nOui\nJusqu’à 100W (Power Delivery 3.0)\n\n\nUSB 4\n40 Gb/s (≈ 5 Go/s)\nType-C\nUSB 3.x et Thunderbolt 3\nOui\nJusqu’à 100W (Power Delivery 3.1)\n\n\nThunderbolt 5\n80 Gb/s bidirectionnel, 120 Gb/s en mode asymétrique (transfert vidéo)\nType-C (logo éclair)\nTB4 / USB4 / PCIe / DisplayPort\nOui\nJusqu’à 240W (Power Delivery Extended)\n\n\n\nCe qu’il y a retenir c’est plus en va vers le bas du tableau, plus l’interface est récent et donc à une vitesse de transfert importante et plus on va “ajouter” des choses comme par exemple le transfert de la vidéo, de la connexion internet (“viable” à partir de l’USB 3.0) et du chargement.\nLa couleur des ports peut aussi aider, un port blanc ou noir sera une interface inférieur ou égale a de l’USB 2.0, alors qu’une couleur bleu ou rouge indique souvent au moins de l’USB 3.0.",
    "crumbs": [
      "Liens utiles",
      "Support global",
      "Assistance pour l'achat de ressources informatiques"
    ]
  },
  {
    "objectID": "pages/support/achats.html#capacité-de-stockage",
    "href": "pages/support/achats.html#capacité-de-stockage",
    "title": "Support et guide concernant les achats de ressources informatiques",
    "section": "1.2 - Capacité de stockage",
    "text": "1.2 - Capacité de stockage\nLe second élément à prendre en compte est en lien avec la capacité de stockage, qui va dépendre de votre besoin. Il est important de trouver le bon équilibre en termes d’evolution et pris en compte des besoins actuels (on achète du matériel avec l’objectif qu’il dure dans le temps). Par ailleurs, c’est important de bien dimensionner la capacité, car cela va avoir un impact sur le budget. Globalement, on va se diriger vers des capacités de l’ordre de 64, 128 ou encore 512 Go avec un usage nomade ou transfert (typiquement une clé USB) et vers des capacités de plusieurs To quand on va vouloir faire des backups ou encore du stockage.",
    "crumbs": [
      "Liens utiles",
      "Support global",
      "Assistance pour l'achat de ressources informatiques"
    ]
  },
  {
    "objectID": "pages/support/achats.html#type-de-stockage",
    "href": "pages/support/achats.html#type-de-stockage",
    "title": "Support et guide concernant les achats de ressources informatiques",
    "section": "1.3 - Type de stockage",
    "text": "1.3 - Type de stockage\nChaque type de stockage presentent des avantages et des inconcevenients. L’idée est d’avoir une vision globale et de piocher dans ce panel en fonction de vos besoins. Concrétement, on va voir trois types.\nLe premier sont les plus connu, à savoir les disques dur mecanique (HDD). Ce sont des disques à plateaux rotatifs avec un bras qui va écrire sur ces derniers. Associé à ces disques on vois souvent des notions comme la vitesse de rotation (5400, 7200, 10000 tr/min) qui a un impact direct sur les performances (plus la valeur est haute, plus c’est rapide). Le prix par rapport au Go est très intéressant, mais du fait de leur conception interne (des bras qui vont écrire sur des plateaux) ils sont fragiles et peuvent etre facilement endommagées. Par exemple la chute d’un disque dur qui était en train de travailler, entraine souvent la mort de ce dernier. Pour résumer ils vont surtout être utilisé de manière interne dans des serveurs, notamment en raison de leur bon rapport capacité/prix.\nLe second type est ce qu’on appelle les disques SSD, à état solide ou encore à mémoire flash. Véritable révolution quand ces derniers sont arrivés sur le marché, ils n’utilisent pas des plateaux rotatifs et des têtes de lecture, mais stockent les données sur des puces de mémoire flash (du coup aucune pièce mobile). Pour faire simple, cela les rend plus rapides, plus résistants aux chocs, plus silencieux et moins énergivores. Au début de leur arrivée, il avait le désavantage d’être moins durable qu’un HDD classique, avec une usure en lien avec la répétition des cycles d’écritures sur les cellules à mémoire flash. Cependant, cela a beaucoup changé avec l’évolution des technologies et aujourd’hui leur durée de vie est même supérieure aux HDD. Le seul désavantage est qu’ils présentent un prix plus élevé qu’un HDD, mais pour une capacité de l’ordre de quelques To maximum ils restent le choix le plus judicieux.\nLe dernier type, qui est en faite un dérivé des deux premiers, sont les clés USB. Leurs objectifs sont de fournir un stockage fiable, principalement pour les transferts rapides de petits fichiers. La portabilité est un point important et le plus se sont des dispositifs ultra-compacts qui tiennent dans une poche. Idéal pour un usage nomade, des présentations ou encore des transferts ponctuels entre des machines. Par ailleurs son prix est généralement plus abordable qu’un disque dur externe. Cependant, ce type de support n’est pas à privilégier pour des backups sur le long terme ou des sauvegardes régulières.\nPour information, nous pouvez aussi trouver des peripheriques hybrides, mélange entre HDD et SSD. Ce type de stockage reste minoritaire sur le marché et la fiabilité et durée de vie sont discutbale. On aura donc tendance à les eviter sous si vous avez un besoin vraiment spécifique.",
    "crumbs": [
      "Liens utiles",
      "Support global",
      "Assistance pour l'achat de ressources informatiques"
    ]
  },
  {
    "objectID": "pages/support/achats.html#format-et-alimentation",
    "href": "pages/support/achats.html#format-et-alimentation",
    "title": "Support et guide concernant les achats de ressources informatiques",
    "section": "1.4 - Format et alimentation",
    "text": "1.4 - Format et alimentation\nTout d’abord, vous entendez souvent les mots disque dur internes ou externes. Garder en tête que c’est exactement le même type de disque entre les deux, il n’y a que la structure autour qui change. Un disque dur interne va donc être localisé dans une infrastructure comme un ordinateur ou un serveur (et connecté via des connectiques spécifiques) alors qu’un disque dur externe va le plus souvent avoir un boitier dédié associé à des connecteurs USB.\nAu niveau du format, vous pouvez aussi trouver des formats 3.5”, 2.5”, SSD ou même UBS. Sachez que le format 3.5” (le plus grand et souvent à l’intérieur des serveurs) nécessite une alimentation externe alors que les autres peuvent être alimentés par USB.",
    "crumbs": [
      "Liens utiles",
      "Support global",
      "Assistance pour l'achat de ressources informatiques"
    ]
  },
  {
    "objectID": "pages/support/achats.html#sécurité-et-chiffrement",
    "href": "pages/support/achats.html#sécurité-et-chiffrement",
    "title": "Support et guide concernant les achats de ressources informatiques",
    "section": "1.5 - Sécurité et chiffrement",
    "text": "1.5 - Sécurité et chiffrement\nLa notion de chiffrage est à prendre en compte. Nous y reviendrons à un autre moment, car c’est souvent une obligation des Politiques de Sécurité des Systèmes d’Information de chiffrer ses périphériques de stockage, mais sachez que tous les périphériques sont chiffrables, mais pas tous nativement. Il y a plusieurs types de chiffrage, logiciel et matériel, le premier étant universel, alors que le second, plus rapide et sécurisé, dépend du modèle. Il faudra jeter un coup d’œil à cela lors de l’achat.",
    "crumbs": [
      "Liens utiles",
      "Support global",
      "Assistance pour l'achat de ressources informatiques"
    ]
  },
  {
    "objectID": "pages/support/achats.html#exemple-de-clés-usb",
    "href": "pages/support/achats.html#exemple-de-clés-usb",
    "title": "Support et guide concernant les achats de ressources informatiques",
    "section": "1.6 - Exemple de clés USB",
    "text": "1.6 - Exemple de clés USB\nComme cité plus haut, l’objectif d’une clé USB est de stocker et transporter facilement des données. Vous trouverez ci-dessous quelques références qui font partie aujourd’hui du haut du panier.\nTout d’abord si vous disposez d’un ordinateur récent avec des ports USB de type USB-C (à partir des données du tableau 1, il faut au moins des interfaces en USB 3.1 ou 3.2 Gen 2 pour ne pas brider la clé) et que le vitesse de transfert est le point le plus important pour vous, la clé Kingston DataTraveler Max est ce qui ce fait de mieux. Elle est légèrement plus chère qu’une clé USB “classique” mais elle est vraiment très rapide et fonctionne aussi bien sur un pc que sur un smarphone. À note quand même que le connecteur USB-C est légèrement plus fragile qu’un connecteur USB de type A et que cette clé n’est pas étanche ou antichoc. Si vous voulez en savoir plus, vous trouverez un test de performance ici.\nMaintenant, si cherche une clé USB simple et efficace, un bon rapport qualité/prix est la Samsung Bar Plus. Ici on est sur un connecteur USB de type A avec un interface USB 3.1, la clé est fabriquée en métal et surtout est résistante aux chocs et à l’eau. La taille reste contenue pour une clé USB et coté vitesse on va être dans les 400 Mo/s et 100 Mo/s en lecture séquentielle (les valeurs chutent lorsque l’on s’attaque aux gros fichiers, test ici). On est loin de la foudre de guerre de la Kingston DataTraveler Max mais pour un usage “basique” et durable, associé à un cout maitrisé cela reste un bon compromis.\nSi votre besoin se focalise sur la resistance, le mieux est de vous tourner vers la Corsair Flash Survivor Stealth. Sa conception et design sont loin d’être nouveaux, car la marque les propose depuis plus de 10 ans. La clé est protégée par un tube en aluminium qui, une fois vissé, protège des chocs, des vibrations, mais résiste aussi à une immersion jusqu’à 200m. Les débits sont bons, sans être exceptionnel (180 Mo/s en lecture et 90 Mo/s en écriture. Ici on vise vraiment la robustesse des composants. Vous trouverez un test ici.\n\n\n\n\n\n\nNote\n\n\n\nN’oubliez pas qu’une clé USB n’a pas forcément besoin de disposer d’un espace de stockage monstrueux, l’objectif étant le transport rapide de données souvent “petites”. Cela doit bien sûr être en adéquation avec vos besoins, mais demandez-vous de combien de place avez-vous vraiment besoin ? Votre budget vous dira merci et si vous avez vraiment besoin de beaucoup de place, demandez-vous s’il n’est pas plus judicieux d’orienter votre achat vers un disque dur externe (généralement plus durable).\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNous parlions de chiffrement précédemment. Ces clés USB ne disposent pas de chiffrement matériel (= pour faire simple intégré dans le matériel), mais il est tout à fait possible d’effectuer du chiffrement logiciel (= via un logiciel) pour les sécuriser. Il existe des clés UBS, comme les clés Kingston IronKey mais elles ne sont à privilégier que si le chiffrage matériel représente l’un de vos besoins.",
    "crumbs": [
      "Liens utiles",
      "Support global",
      "Assistance pour l'achat de ressources informatiques"
    ]
  },
  {
    "objectID": "pages/support/achats.html#exemple-de-disques-durs-externe",
    "href": "pages/support/achats.html#exemple-de-disques-durs-externe",
    "title": "Support et guide concernant les achats de ressources informatiques",
    "section": "1.7 - Exemple de disques durs externe",
    "text": "1.7 - Exemple de disques durs externe\nConcernant les disques durs externes, le mieux si cela est possible est de s’orienter vers un SSD. Comme expliqué dans la section 1.3, ce type de disque sera plus rapide, plus résistant aux chocs, plus silencieux et moins énergivores qu’un disque HDD “classique”. Le seul hic est qu’ils sont généralement plus chers que les HDD. Mais encore une fois, posez-vous les bonnes questions dès le début : un SSD aura une durée de vie comprise entre 5 et 10 ans (selon l’usage et la charge de travail associé) contre 3 à 7 ans contre un disque HDD. Si on lisse la différence de prix sur la durée de vie, la différence est rarement significative. Par ailleurs, garder en mémoire que l’on parle ici de stocker vos données. Il suffit de perdre une fois ces données pour comprendre à quel point elles sont précieuses. Prenez ça en compte lors de votre achat et ne vous arrêtez pas uniquement au prix.\nL’un des meilleurs disque SSD externe est sans doute la gamme des Sandisk Extreme. Vous trouverez 3 versions (attention à ne pas vous mélanger) :\n\nle Extreme Portable SSD disposant d’une interface USB 3.2 Gen 2 (vitesse lecture/ecriture maximum théorique de 1050/1000 Mo/s)\nle Extreme PRO Portable SSD avec une interface USB 3.2 Gen 2x2 (vitesse lecture/ecriture maximum théorique de 2000 Mo/s)\npour finir un monstre, le Extreme PRO USB4 avec interface USB4 ou Thunderbolt 4 (vitesse lecture/ecriture maximum théorique de 3800/3700 Mo/s).\n\nToute la gamme est IP65, posséde un chiffrement matériel intégré (AES 256 bits) et est livré avec un adaptateur USB-C vers USB-A (au cas ou).\nIci il faut bien faire attention aux types d’interface que vous avez sur vos ordinateurs. Il ne sert à rien de prendre une interface USB4 si vous n’en disposez pas (les débits seront bridés), sauf si dans votre réflexion vous intégrez le long terme et potentiellement le changement de votre matériel actuel. Par ailleurs, la première version en USB 3.2 Gen 2 présente déjà des débits très intéressants. Je vous conseille donc de vous tourner vers cette version ou à la rigueur vers la seconde en USB 3.2 Gen 2x2 si par exemple en réduisant le taille du stockage afin de rester dans la même gamme de prix.\nVous trouverez des tests ici et ici pour la version Extreme Portable SSD et ici pour la version Extreme PRO Portable SSD.\nSi vous avez vraiment un budget serré et que vous souhaitez vous tourner vers des HDD (notamment en raison d’un grand besoin de stockage), il existe le Toshiba Canvio Basics. Interface USB 3.0 (environ 130 Mo/s) et disque au format 2,5 pouces (donc pas d’alimentation externe) cela permet d’avoir un disque fiable, économique et silencieux. Vous trouverez un test ici. Si vous avez encore besoin de plus grande capacité, il existe des disques chez Western Digital tels que les My Book en interface USB 3.2 Gen 1. Avec ce format par contre vous aurez besoin d’une alimentation externe. Attention par contre avec ce type de stockage, car une panne risque de faire beaucoup de dégât au vu de la quantité de données associée au stockage.\nAttention avec des dernières références, par de chiffrement matériel, il faudra passer par du chiffrement logiciel.\n\n\n\n\n\n\nNote\n\n\n\nSi vous avez besoin d’un stockage vraiment important, le mieux est de vous tourner vers l’UMR via des structures comme le DEN pour voir s’il existe déjà des solutions de stockage mutualisé.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAttention, n’oubliez pas qu’on mise ici sur le fait de prendre un bon disque dur qui va durer longtemps. Par conséquent, un disque dur doit “forcement” venir avec une sacoche ou une protection pour le transporter. Vous en trouverez à des prix aux alentours de 10€. Veuillez à faire attention à sa taille (en lien avec la section 1.4) et se possible le prendre rigide ou semi-rigide.",
    "crumbs": [
      "Liens utiles",
      "Support global",
      "Assistance pour l'achat de ressources informatiques"
    ]
  },
  {
    "objectID": "pages/support/gestionnaire_mots_de_passe.html",
    "href": "pages/support/gestionnaire_mots_de_passe.html",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "L’authentification des utilisateurs, allant des simples utilisateurs aux administrateurs, joue un rôle important dans la gestion de la sécurité d’un système d’information. Dans la pratique, l’accès à de nombreux services numériques repose sur l’utilisation de mots de passe, qui reste un des moyens le plus simples et le moins coûteux à déployer pour contrôler un accès et éventuellement prouver son identité. Cependant, la gestion de ces mots de passe ou la définition de ces derniers peut devenir laborieuse et peut même présenter des failles dans le système. À titre d’exemple, une étude de Verizon de 2021 estime que 81 % des notifications de violations de données mondiales seraient liées à une problématique de mots de passe. Pire encore, en France environ 60 % des notifications reçues par là CNIL depuis le début de l’année 2021 sont liées à du piratage et un grand nombre aurait pu être évité par le respect de bonnes pratiques en matière de mots de passe.\nL’objectif de cette ressource n’est pas d’énoncer et rentrer en détail dans les recommandations à suivre afin d’élaborer la “meilleur” des mesures d’authentification, mais plutôt de vous donner une solution clé en main permettent de mettre en place gestionnaire de mots de passe et surtout de vous sensibiliser à son utilisation.\nDe manière dérivée, nous aborderons succinctement certaines stratégies de bonnes pratiques en matière d’authentification, mais si vous voulez en savoir plus, il est vivement conseillé de se tourner vers les ressources de l’ANSSI et la CNIL à ce sujet. Vous trouverez par exemple ci-dessous deux ressources accessibles en termes de contenu et facilement appréhendables, notamment vis-à-vis des applications associées :\n\nANSSI, Recommandations relatives à l’authentification multifacteur et aux mots de passe,\nCNIL, Mots de passe : une nouvelle recommandation pour maîtriser sa sécurité.",
    "crumbs": [
      "Liens utiles",
      "Support global",
      "Gestionnaire de mots de passe"
    ]
  },
  {
    "objectID": "pages/support/gestionnaire_mots_de_passe.html#lauthentification-daccès-un-élément-fondamental-dans-la-gestion-de-la-sécurité-dun-système-dinformation",
    "href": "pages/support/gestionnaire_mots_de_passe.html#lauthentification-daccès-un-élément-fondamental-dans-la-gestion-de-la-sécurité-dun-système-dinformation",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "L’authentification des utilisateurs, allant des simples utilisateurs aux administrateurs, joue un rôle important dans la gestion de la sécurité d’un système d’information. Dans la pratique, l’accès à de nombreux services numériques repose sur l’utilisation de mots de passe, qui reste un des moyens le plus simples et le moins coûteux à déployer pour contrôler un accès et éventuellement prouver son identité. Cependant, la gestion de ces mots de passe ou la définition de ces derniers peut devenir laborieuse et peut même présenter des failles dans le système. À titre d’exemple, une étude de Verizon de 2021 estime que 81 % des notifications de violations de données mondiales seraient liées à une problématique de mots de passe. Pire encore, en France environ 60 % des notifications reçues par là CNIL depuis le début de l’année 2021 sont liées à du piratage et un grand nombre aurait pu être évité par le respect de bonnes pratiques en matière de mots de passe.\nL’objectif de cette ressource n’est pas d’énoncer et rentrer en détail dans les recommandations à suivre afin d’élaborer la “meilleur” des mesures d’authentification, mais plutôt de vous donner une solution clé en main permettent de mettre en place gestionnaire de mots de passe et surtout de vous sensibiliser à son utilisation.\nDe manière dérivée, nous aborderons succinctement certaines stratégies de bonnes pratiques en matière d’authentification, mais si vous voulez en savoir plus, il est vivement conseillé de se tourner vers les ressources de l’ANSSI et la CNIL à ce sujet. Vous trouverez par exemple ci-dessous deux ressources accessibles en termes de contenu et facilement appréhendables, notamment vis-à-vis des applications associées :\n\nANSSI, Recommandations relatives à l’authentification multifacteur et aux mots de passe,\nCNIL, Mots de passe : une nouvelle recommandation pour maîtriser sa sécurité.",
    "crumbs": [
      "Liens utiles",
      "Support global",
      "Gestionnaire de mots de passe"
    ]
  },
  {
    "objectID": "pages/support/gestionnaire_mots_de_passe.html#un-gestionnaire-de-mots-de-passe-cest-quoi-pourquoi-est-ce-utile",
    "href": "pages/support/gestionnaire_mots_de_passe.html#un-gestionnaire-de-mots-de-passe-cest-quoi-pourquoi-est-ce-utile",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "Un gestionnaire de mots de passe, c’est quoi ? Pourquoi est-ce utile ?",
    "text": "Un gestionnaire de mots de passe, c’est quoi ? Pourquoi est-ce utile ?\nUn gestionnaire de mots de passe, encore appelé coffre-fort de mots de passe est un stockage virtuel des identifiants de connexion, ou toutes les informations sont chiffrés. En plus du stockage pur, ces solutions permettent souvent de remplir automatiquement les identifiants des sites internet ou encore de synchroniser les informations sur plusieurs appareils en même temps, par exemple entre deux ordinateurs et encore avec des smartphones. Par ailleurs, la création des mots de passe est souvent facilitée, via une organisation en groupe et sous-groupes, ou encore par la génération des mots de passe afin qu’ils se plient aux recommandations et bonnes pratiques associées. En pratique, cela prend souvent la forme d’un mot de passe, dit mot de passe “maître”, robuste et mémorisé par un humain, qui permet de déverrouiller l’intégralité de la base des mots de passe (et donc leur accès aux ressources associé). Une alternative à ce système consiste par exemple à utiliser un fichier bureautique protégé par un mot de passe. Cette solution n’est bien sûr pas à privilégier, car elles n’apportent pas du tout le même niveau de protection qu’un coffre-fort de mots de passe conçu à cette fin. Pour finir, l’utilisation d’un gestionnaire de mots de passe est l’une des recommandations préconisées par l’ANSSI (n°31) concernant “l’authentification multifacteur et mots de passe”.\nDans ce monde de logiciel de coffre-fort numérique nous allons trouver des solutions payantes, comme par exemple NordPass ou encore Bitwarden, mais il existe une très bonne solution libre et open source KeePass, qui à l’avantage d’être certifié par l’ANSSI dans sa version 2.10 portable.\nDans notre proposition ci-dessous, nous utiliserons un petit frère de KeePass, nommé KeePassXC, qui est basé sur l’architecture de KeePass, mais avec l’ajout de la composante multi-plate-forme. Plus concrètement, il n’y a rien de fondamentalement incorrect dans l’utilisation de KeePass, cependant, il est développé en C# et nécessite donc la plate-forme .NET de Microsoft alors que KeePassXC est développé en C++ et fonctionne nativement sous Linux, macOS et Windows, ce qui permet de bénéficier de la meilleure intégration possible.\nPour conclure cette partie et surtout pour approfondir le choix de certains utilisateurs plus avancés en termes d’utilisation :\n\nKeePassXC ne supporte pas les plugins de KeePass. Ce n’est pas forcément une mauvaise chose, car les plugins peuvent être dangereux et KeePassXC fournit déjà de nombreuses fonctionnalités qui nécessitent des plugins tiers dans KeePass, de sorte que pour la plupart des choses, vous ne devriez jamais en avoir besoin.\nPetit bonus, même si c’est à la sécurité qui est importante, l’interface de KeePassXC présente une belle interface et est plus agréable à utiliser sur KeePass.\nKeePassXC est disponible nativement en français.\nSi vous désirez vous faire votre propre idée, le fichier de base de données de KeePass est parfaitement compatible avec KeePassXC (et vis et versa). Vous pouvez donc passer d’un système à l’autre en conservant vos informations.",
    "crumbs": [
      "Liens utiles",
      "Support global",
      "Gestionnaire de mots de passe"
    ]
  },
  {
    "objectID": "pages/support/gestionnaire_mots_de_passe.html#installation-et-configuration-de-keepassxc",
    "href": "pages/support/gestionnaire_mots_de_passe.html#installation-et-configuration-de-keepassxc",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "1 - Installation et configuration de KeePassXC",
    "text": "1 - Installation et configuration de KeePassXC\n\n1.1 - Prérequis et cadre de la procédure\nPour cette procédure nous aurons les objectifs suivant :\n\ninstaller et configurer correctement KeePassXC\nrapide tour d’horizon de l’utilisation du logiciel\ninstaller et configurer une extension permettant d’associer notre gestionnaire de mots de passe à mon navigateur pour une remplissage semi-automatique des mots de passe des sites internet\nmise en place d’une synchronisation entre deux ordinateurs et un smartphone Android\ninstallation d’une application Android KeePass\n\nIMPORTANT : la mise en place d’un ou plusieurs processus de synchronisation ne doit pas être considérée comme une procédure de sauvegarde et ne doit jamais remplacer une sauvegarde dédiée de votre base de données avec vos données personnelles. Par exemple, si un problème arrive sur une base de données sur un appareil, la synchronisation avec d’autres appareils aura comme conséquence une propagation du problème.\nEn cas de besoin vous trouverez aussi une documentation (en anglais) très bien fournie sur le lien suivant.\n\nTableau 1 : État des tests de la procédure.\n\n\n\n\n\n\n\nSystème d’exploitation\nProcédure fonctionnelle\nÉdition et version\n\n\n\n\nWindows\nOui\n11 Professionnel, version 24H2\n\n\nMac\nNon testée\n\n\n\nLinux\nOui\nUbuntu 24.04.2 LTS\n\n\nAndroid\nOui\nVersion 13 & 15\n\n\niOS\nNon testée\n\n\n\n\n\n\n1.2 - Téléchargement et installation de KeePassXC\n\n1.2.1 - Sous Microsoft Windows\nRendez-vous sur la page de téléchargement du site officiel via le lien suivant et téléchargez l’archive msi. Suivre les étapes d’installation courantes en veillant à avoir lancé l’installation en mode administrateur (au besoin, clique droit sur l’exécutable et cliquez sur “Exectuer en tant qu’administrateur”). Si vous avez bien effectué la manipulation, vous devriez avoir une fenêtre comme sur la figure 1. Vous pouvez cocher la case “Create a shortcut on the desktop” qui aura comme conséquence de vous placer un raccourci de lancement sur votre bureau.\n\n\n\nFigure 1 : Assistant d’installation Windows\n\n\nSi le chemin d’installation par défaut pointe vers quelque chose comme “C:\\Users\\nom_utilisateur” c’est que vous n’avez pas lancé l’installation avec les droits administateur.\nNoter que pour certains utilisateurs, le logiciel ne se lance pas après l’installation, même si l’on clique sur le raccourci d’exécution. Pour remédier à cela, il est nécessaire d’installer les dernières bibliothèques Microsoft Visual C++. Vous pourrez les trouver via le lien suivant.\n\n\n1.2.2 - Sous Linux\nIl vous suffit de télécharger l’AppImage de KeepPassXC pour linux à partir du lien officiel et de l’installer sur votre système.\n\n\n1.2.3 - Sous macOS\nPour les systèmes macOS, télécharger l’image dmg à partir du lien officiel et installer le logiciel dans vos applications.\n\n\n1.2.4 - Configuration initiale et création de votre base de mots de passe\nMaintenant que l’application est correctement installée sur votre système, vous devriez tomber sur une fenêtre d’accueil comme sur la figure 2.\n\n\n\nFigure 2 : Accueil application\n\n\nPar défaut, la langue de l’application est réglée sur celle du système. En lien avec ma configuration actuelle, les prochaines captures d’écran seront donc en français.\nMaintenant, nous allons créer notre fichier de base de données qui contiendra tous nos mots de passe. Pour cela il suffit de cliquer sur l’onglet “Créer une base de données”. La fenêtre suivante vous invite à donner un nom à cette base. Cette base de données va prendre l’apparence d’un fichier .kdbx qui sera stocké sur notre disque dur. Pour éviter tout incident de compatibilité, privilégier un nom dans le caractère spécial (pas d’accent ou d’espace). Ici pour l’exemple ma base s’appellera “bdd_test_keepassxc” (figure 3).\n\n\n\nFigure 3 : Création de la base de données\n\n\nPas besoin de modifier les “Paramètres de chiffrement” sauf si voulez les personnalisées en fonctions de vos exigences. La fenêtre suivante “Identifiants de la base de données” vous permet de définir le mot de passe “maître” qui va protéger votre base de données (et donc tout son contenu). Pour résumer :\n\nsi vous ne devez retenir qu’un seul mot de passe, c’est celui-là !\nil est considéré comme celui qui débloque tous les autres, il doit donc être compliqué et respecter un minimum de règles de sécurité. Sans rentrer trop dans les détails de ces règles, vous pouvez cliquer sur l’icône du carré avec 3 points afin d’ouvrir un utilitaire d’aide à la génération (figure 4).\nce mot de passe est très important et sa perte, en règle générale, entrainera l’impossibilité d’ouvrir la base et donc d’accéder à vos mots de passe (par défaut par de processus de récupération de mots de passe).\nvous avez un onglet en dessous pour “Ajouter une autre protection”. Les options disponibles ne seront pas abordées ici, mais sachez que vous pouvez ajouter des options de sécurité et d’accès, comme par exemple un fichier clé ou encore des questions-réponses.\n\n\n\n\nFigure 4 : Définition des identifiants pour accéder à la base de données\n\n\nLa dernière étape vous demande où vous désirez sauvegarder votre base de données et quel nom vous souhaitez lui donner. Dans mon exemple, ma base de données sera sauvegardée dans un fichier bdd_test_keepassxc.kdbx. Par ailleurs, si vous souhaitez synchroniser votre base de données entre plusieurs appareils (voir la section 4, par exemple pour une synchronisation entre un ordinateur et un smartphone), le mieux est de placer ce fichier dans un dossier. À titre d’exemple ici, mon fichier .kdbx sera stocké dans un fichier nommé “keepass”.\nAvant de se lancer dans la création de mes premiers mots de passe, faites un tour au niveau des paramètres de l’application. Pour cela il suffit de cliquer sur la roue crantée, ou alors de cliquer sur l’onglet “Outils” puis sur “Paramètres” (figure 5).\n\n\n\nFigure 5 : Accès aux paramètres de l’application\n\n\nLibre à vous de modifier ces paramètres suivant vos préférences, mais je vous conseille au minimum les paramètres suivants afin d’améliorer votre interface et vos interactions. À savoir que ces options peuvent légèrement différer entre les versions (en lien avec les OSs), notamment entre Windows et Linux.\nDans l’onglet “Général”, section “Démarrage” (figure 6) :\n\ncochez si cela n’est pas déjà fait “Lancer automatiquement KeePassXC au démarrage du système. À chaque lancement de votre système, le logiciel se lancera automatiquement et vous demandera votre mot de passe”maître” pour déverrouiller votre base de données,\ncochez l’onglet “Réduire la fenêtre après déverrouillage de la base de données”. Si on couple votre utilisation avec l’option précédente, le déverrouillage de votre base de données n’implique pas que vous ayez besoin toute de suite d’utiliser un mot de passe. Par conséquent pas besoin que l’application reste en avant sur votre bureau.\n\n\n\n\nFigure 6 : Onglet ‘Général’, section ‘Démarrage’\n\n\nDans l’onglet “Général”, section “Gestion des entrées” (figure 7) :\n\ncochez “Copier les données en double-cliquant sur le champ de l’entrée affichée”\ncochez “Réduire lors de l’ouverture d’une URL”\n\n\n\n\nFigure 7 : Onglet ‘Général’, section ‘Gestion des entrées’\n\n\nDans l’onglet “Général”, section “Interface utilisateur” (figure 8) :\n\ncochez “Réduire au lieu de fermer l’appli”\ncochez “Afficher une icône dans la zone de notification”\ncochez “Cacher la fenêtre dans la zone de notification une fois minimisée”\n\n\n\n\nFigure 8 : Onglet ‘Général’, section ‘Interface utilisateur’\n\n\nAvec ces paramètres, quand vous fermez ou minimisez la fenêtre de l’application, cette dernière vient de placer dans votre zone de notification (elle peut être dans la zone cachée la première fois, figure 9) au lieu de fermer définitivement l’application (pour faire cela, il faut cliquer sur l’onglet “Base de données”, puis “Fermer” tout en bas). Quand votre application est dans cette zone, il vous suffit de double cliquer dessus pour l’ouvrir.\n\n\n\nFigure 9 : Application dans la zone de notification",
    "crumbs": [
      "Liens utiles",
      "Support global",
      "Gestionnaire de mots de passe"
    ]
  },
  {
    "objectID": "pages/support/gestionnaire_mots_de_passe.html#tour-dhorizon-de-lapplication",
    "href": "pages/support/gestionnaire_mots_de_passe.html#tour-dhorizon-de-lapplication",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "2 - Tour d’horizon de l’application",
    "text": "2 - Tour d’horizon de l’application\n\n2.1 - Interface de l’application\nL’interface de votre base de données est divisée en 4 parties (figure 10).\n\n\n\nFigure 10 : Interface principale de la base de données\n\n\nLa première partie regroupe la liste de vos mots de passe. Vous pouvez les organiser en groupe et même sous-groupe (ici par défaut un groupe nommé “Racine” a été créé) et vous pouvez même changer les icônes des éléments.\nLa seconde partie regroupe la liste des entrées présente dans vos groupes et de manière générale dans votre base de données. Comme précédent vous pouvez modifier la visualisation de ces dernières, notamment en modifiant les icônes associées.\nLa troisième partie contient des raccourcis vers groupes dynamiques ou tags que vous avez créés. Ces dernières ressources sont des paramètres que vous pouvez associer à des entrées et/ou groupes et qui permettent d’avoir des accès simplifiés, un peu comme des raccourcis. Un détail intéressant est que cette partie regroupe aussi des onglets permettant de diagnostiquer l’état de certains de vos mots de passe, notamment en faisant des recherches sur les mots de passe expirés ou encore de faibles niveaux de sécurité (par exemple si votre mot de passe est très court en termes de nombre de caractères).\nLa dernière partie est l’onglet de prévisualisation, qui vous permet de vous un résumé par exemple du contenu des entrées.\nConcernant la barre d’outils, elle se divise en 5 parties (figure 11).\n\n\n\nFigure 11 : Interface de la barre d’outils\n\n\nLa partie 1 comporte des onglets pour ouvrir une base de données, sauvegarder la base active ou encore la verrouiller.\nLa partie 2 permet de créer des entrées ou les modifier (ajout et/ou suppression).\nLa partie 3 permet d’utiliser des raccourcis pour copier certains éléments des entrées sélectionnées.\nLa partie 4 permet d’avoir accès aux paramètres et rapports en lien avec la base de données, mais aussi au générateur de mots de passe.\nLa dernière partie permet d’avoir accès à une barre de recherche.\n\n\n2.2 - Création d’une entrée\nPour créer une nouvelle entrée, il suffit de cliquer sur l’icône + dans la section 2 de la barre d’outils. Par défaut nous étions dans le groupe “Racine”, par conséquent cette entrée sera localisée dans ce groupe. Ici, nous allons faire un exemple avec des identifiants de mon compte CNRS. Ici le minimum à renseigner pour créer une entrée est le “Titre”, le “Nom d’utilisateur” et le “mot de passe” (figure 12). On laisse vide pour le moment le champ “URL” que nous utiliserons plus tard pour le remplissage automatique des champs via le navigateur. Notez que vous avez beaucoup d’autres options, comme par exemple le menu “Icône” sur le côté ou encore le champ “Notes” qui vous permet d’ajouter des commentaires ou indications à votre entrée. Par ailleurs vous constatez que par défaut le mot de passe est masqué. Cela est très pratique, car l’utilisation de ces mots de passe par la suite, ne nécessite pas d’avoir la visibilité de ce dernier (utile notamment si vous sommes dans des lieux publics).\n\n\n\nFigure 12 : Création d’une entrée\n\n\nUne fois l’action validée, on retrouve bien l’entrée dans notre base de données (figure 13). Pour améliorer la lisibilité de mon interface, j’ai même changé le nom du groupe “Racine” par “cnrs”.\n\n\n\nFigure 13 : Interface avec entrée\n\n\nMaintenant si je veux copier une partie de mon entrée, par exemple le nom d’utilisateur ou encore le mot de passe, il me suffit d’utiliser les boutons de la section 3 de la barre d’outils. Il est a noté que dans le cas de la copie d’un mot de passe (le bouton avec la clé), vous disposez d’un temps limité pour utiliser ce dernier avec qu’il soit supprimé de votre “mémoire pour copie” (= presse-papiers, figure 14). Vous pouvez configurer ce temps dans le menu “Paramètres”, au niveau de l’onglet “Sécurité”, section “Délais d’attente” et l’option “Effacer le presse-papiers après”.\n\n\n\nFigure 14 : Temps presse-papiers",
    "crumbs": [
      "Liens utiles",
      "Support global",
      "Gestionnaire de mots de passe"
    ]
  },
  {
    "objectID": "pages/support/gestionnaire_mots_de_passe.html#intégration-aux-navigateurs",
    "href": "pages/support/gestionnaire_mots_de_passe.html#intégration-aux-navigateurs",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "3 - Intégration aux navigateurs",
    "text": "3 - Intégration aux navigateurs\nL’une des options les plus pratiques et l’intégration de votre coffre-fort à votre navigateur. Plus concrètement, cela veut dire que vous allez pouvoir effectuer des remplissages semi-automatiques des noms d’utilisateur et des mots de passe quand vous allez vous rendre sur les sites internet associés.\nKeePassXC propose des intégrations avec les navigateurs suivants :\n\nSur base Chrome, Chromium, Vivaldi et Brave,\nSur base Mozilla Firefox et Tor-Browser,\nSur base Microsoft Egde.\n\nLa première chose à faire est d’activer l’option d’association dans les paramètres de KeePassXC. Pour cela il suffit de vous rendre dans les paramètres au niveau de l’onglet “Intégration aux navigateurs” (figure 15).\n\n\n\nFigure 15 : Intégration aux navigateurs\n\n\nPour mon cas d’exemple, je vais faire un test avec le navigateur Egde, mais le principe reste le même pour les autres et vous pouvez même en associer plusieurs à la fois.\nLa seconde étape est d’installer l’extension sur le navigateur. Cliquez sur les liens juste toujours au niveau de l’onglet “Intégration aux navigateurs”. Vous devriez être redirigé vers un page d’installation (toujours ici avec l’exemple de Microsoft Egde, figure 16).\n\n\n\nFigure 16 : Installation extension navigateur\n\n\nAprès l’installation, redémarrez votre navigateur et vous devriez avoir l’extension sous cette forme (figure 17, la base de données KeePassXC doit être déverrouillée).\n\n\n\nFigure 17 : Configuration extension navigateur\n\n\nMaintenant cliquer sur le bouton “Connecter” puis sur la fenêtre de votre base de données indiquez un nom à la demande d’association de clé (figure 18).\n\n\n\nFigure 18 : Association clé extension navigateur\n\n\nVotre extension devrait maintenant être correctement configurée (figure 19).\n\n\n\nFigure 19 : Configuration extension navigateur complete\n\n\nPour la suite, nous allons tester le remplissage semi-automatique sur l’entrée que j’ai créée précédent en lien avec mes identifiants CNRS. Pour cela je me rends sur une page de connexion du CNRS (figure 20).\n\n\n\nFigure 20 : Page de connexion CNRS\n\n\nIci je vais copier l’URL de cette page afin de la renseigner au niveau de mon entrée de ma base de données. Vous remarquerez que déjà l’extension à détecter la possibilité d’ajouter des champs en lien avec une entrée de ma base de données (via l’onglet grisé de l’extension). Par ailleurs, pour l’URL, pas besoin de copier l’intégralité de cette dernière, il suffit de s’arrêter après le .fr. Vous pouvez appliquer cette règle pour les autres URL à savoir que cela permet de généraliser la détection du remplissage automatique et qu’il y a quand même de rares cas où cela ne fonctionne pas. Dans notre cas, on va juste utiliser l’URL “https://janus.cnrs.fr/” que nous allons ajouter dans le champ “URL” de notre entrée précédente créée (figure 21).\n\n\n\nFigure 21 : Ajout URL au niveau de notre entrée\n\n\nMaintenant, actualisez la page de votre navigateur (en étant sur la page de connexion du CNRS) ou cliquez sur l’icône de l’extension dans le navigateur, puis cliquez sur “Redétecter les champs d’identification”. Vous devriez avoir la fenêtre suivante de KeePassXC qui s’affiche (figure 22).\n\n\n\nFigure 22 : Acceptation de l’association de l’URL\n\n\nIl vous suffit maintenant de cocher les cases “Mémoriser” et “Permettre les éléments sélectionnés”. Maintenant à chaque fois que vous arriverez sur une page portant en début d’URL “https://janus.cnrs.fr/”, KeePassXC vous proposera en remplissage semi-automatique des champs, en lien avec ce que vous avez renseigné dans votre base de données (figure 23).\n\n\n\nFigure 23 : Remplissage automatique\n\n\nUne dernière petite astuce, plutôt que de cliquer sur l’icône d’extension ou sur le champ afin de sélectionner l’entrée correspondante dans la base de données, vous pouvez utiliser des fonctions de raccourci clavier. Vous les trouverez dans l’onglet paramètre de l’extension du navigateur (en cliquant sur la route crantée verte, figure 24), onglet “Général”, section “Raccourcis-clavier”. Ils sont configurables et par exemple dans mon exemple par défaut (sous Windows) il faut utiliser Alt + Maj + U pour saisir le nom d’utilisateur et le mot de passe.\n\n\n\nFigure 24 : Paramètres extension navigateur",
    "crumbs": [
      "Liens utiles",
      "Support global",
      "Gestionnaire de mots de passe"
    ]
  },
  {
    "objectID": "pages/support/gestionnaire_mots_de_passe.html#sychronisation-entre-plusieurs-appareils",
    "href": "pages/support/gestionnaire_mots_de_passe.html#sychronisation-entre-plusieurs-appareils",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "4 - Sychronisation entre plusieurs appareils",
    "text": "4 - Sychronisation entre plusieurs appareils\nPour cette dernière partie, nous allons configurer notre base de données afin qu’elle puisse se synchroniser entre plusieurs appareils. Cette partie est légèrement plus technique donc il est important de ne pas se décourager et pour faire simple de “ne pas lâcher la rampe”. N’oubliez pas qu’en cas de besoin vous pouvez revenir vers moi.\nIci pour l’exemple nous allons configurer deux configurations qui rempliront surement la plupart de vos cas d’usages et besoins :\n\nune synchronisation entre un ordinateur et un smartphone,\nune synchronisation entre deux ordinateurs.\n\nPar ailleurs, vous constaterez que les exemples ci-dessous ont été réalisés sous système d’exploitation Windows pour les ordinateurs et Android pour le smartphone. Quand cela a été identifié, des alternatives aux autres OS seront recensées, mais sans garantie d’avoir été testé jusqu’au bout de l’objectif de la procédure.\n\n4.1 - Le logiciel Syncthing\nLa première étape est d’installer un logiciel sur nos appareils qui vont nous permettre d’effectuer nos synchronisations. Pour cela nous utiliserons Syncthing qui est un logiciel libre et gratuit qui synchronise les fichiers entre appareils en temps réel, sans serveur central. Il est privé, sécurisé, crypté et facile à utiliser.\nPoint important, comme cité précédemment, ce logiciel ne fonctionne pas via un serveur central. Concrètement cela veut dire que lors des processus de synchronisation il est nécessaire que les appareils soient connectés en même temps. Dans le cas de deux ordinateurs, cette condition peut être compliquée à remplir, surtout si on utilise l’un sur notre lieu de travail et le second à la maison pour le télétravail. C’est pourquoi, dans notre configuration c’est notre téléphone sera l’équivalent de notre “serveur central” car dernier aura “plus de change” d’être connecté en même temps que les ordinateurs.\nSur le site officiel de l’application, rendez-vous dans la section “Downloads”. Vous constaterez que vous disposez de plusieurs distributions en fonction de votre système d’exploitation.\nÀ titre indicatif, le processus pour l’installer sur un système Linux est disponible via le lien suivant. Suivez les instructions et lancez les lignes de commandes associées. Vous devriez avoir deux raccourcis vers l’application :\n\n“Start Syncthing” qui va vous permettre de lancer le logiciel.,\n“Syncthing Web UI” qui va vous amener sur le page de configuration du logiciel (voir la section suivante pour plus de détail).\n\nPour finir concernant Linux, contrairement à Windows qui lance automatiquement Syncthing lors du démarrage de l’OS, vous allez devoir configurer ce démarrage automatique, si vous le souhaitez, sous Linux (via par exemple le l’exécution du raccourci “Start Syncthing” à chaque démarrage).\n\n\n4.2 - Installation et configuration du client Syncthing sous Windows\nNous allons commencer par l’installer sur notre ordinateur en sélectionnant l’intégration “Syncthing Windows Setup” qui permet de l’installer sous Windows. Pour faire simple rendez-vous sur ce lien et téléchargez l’exécutable .exe (figure 25, actuellement la dernière version est la 1.29.0).\n\n\n\nFigure 25 : Dernière version de ‘Syncthing Windows Setup’\n\n\nLors de l’installation, effectuée si possible avec les droits administrateur, suivez la configuration suivante :\n\nlorsque que la fenêtre “Select Destination Location” apparait, changer le chemin d’accès par un chemin plus “simple” comme par exemple “C:\\Syncthing” (figure 26),\n\n\n\n\nFigure 26 : Dossier d’installation\n\n\n\nau niveau de la fenêtre “Select Additional Tasks”, cochez la case “Create desktop shortcut for Syncthing configuration page” en plus des cases déjà cochées (figure 27),\n\n\n\n\nFigure 27 : Fenêtre taches additionnelles\n\n\n\ncliquez sur oui quand on vous demande de créer une règle pour le pare-feu (figure 28),\n\n\n\n\nFigure 28 : Regle pare-feu\n\n\n\npour finir, cochez la case “Open Syncthing configuration page” (figure 29).\n\n\n\n\nFigure 29 : Last stand\n\n\nUne fois le logiciel installé, vous devriez voir la fenêtre principale de l’application (figure 30). Vous pouvez y accéder via votre navigateur à l’adresse suivante 127.0.0.1:8384 (si vous n’avez pas touché à ces paramètres lors de l’installation) ou en cliquant sur le raccourci “Syncthing Configuration Page” qui c’est ajouté sur votre bureau. Suivant votre navigateur, ce dernier est susceptible de vous informer que la page que vous souhaitez afficher (127.0.0.1) présente un risque probable de sécurité. Vous pouvez passer outre ce conseil et l’afficher quand même (via par exemple le bouton “Avancé” et quelque chose comme “Poursuivre vers la page”).\nSur cette première page, il est possible que l’application vous conseille d’ajouter un nom d’utilisateur et un mot de passe afin d’accéder à l’interface. D’un point de vue sécuritaire c’est un plus, mais dans un souci d’accessibilité et en partant du principe que votre ordinateur est verrouillé par un mot de passe et que vous ne quittez pas votre poste sans le verrouiller, nous n’allons pas configurer d’accès authentifié.\n\n\n\nFigure 30 : Syncthing page globale\n\n\nMaintenant que notre logiciel est installé, la prochaine étape est d’ajouter un dossier de partage qui contiendra notre base de données KeePassXC. Pour effectuer cela, il suffit de cliquer sur le bouton “Ajouter un partage” disponible sur l’écran d’accueil. Sur l’écran de configuration (figure 31), nous allons lui donner un nom (il peut être différent entre les appareils), ainsi qu’un identifiant de partage (il doit être IDENTIQUE entre les appareils) et pour finir le chemin d’accès du partage, qui sera ici l’emplacement du dossier ou est stocké ma base de données.\n\n\n\nFigure 31 : Configuration d’un dossier de partage\n\n\n\n\n4.3 - Installation et configuration du client Syncthing sous Android\nPour configurer Syncthing sous notre smartphone Android, nous allons récupérer l’application directement depuis le store. Veillez à bien récupéré le bon qui s’appelle “Syncthing-Fork”.\nLors du lancement de l’application, vous devez autoriser l’application à accéder à plusieurs éléments de votre téléphone :\n\nl’accès au stockage, qui va lui permettre d’avoir un accès à votre base de données stocké en local sur votre téléphone (figure 32)\n\n\n\n\nFigure 32 : Autorisation accès stockage téléphone\n\n\n\nconcernant l’optimisation de la batterie, il est conseillé d’arrêter l’optimisation de la batterie (figure 33). Ici nous avons besoin que notre téléphone ne ferme pas automatiquement l’application, par exemple si elle reste ouverte plus longtemps qu’une application “basique”. Il est à note quand même que théoriquement, la désactivation de l’optimisation de la batterie pourrait avoir des récupércutions sur l’autonomie de cette dernière. Il faut bien sûr prendre cela on considération via d’autres variables, comme les espacements entre les synchronisations ou le type de connexion (via données mobiles ou wifi par exemple) mais pour le moment via mon exemple d’utilisation exigent (synchronisation toujours fonctionnelle via les données mobiles), l’impact selon moi n’est pas une signification sur l’autonomie de ma batterie.\n\n\n\n\nFigure 33 : Autorisation arrêt optimisation batterie\n\n\n\npour les permissions de localisation, il est aussi conseillé de l’accorder (figure 34). Comme indiqué dans les commentaires, la localisation va servir uniquement pour la sélection des réseaux wifi, si vous désirez effectuer des synchronisations uniquement sur des réseaux wifi prédéfinis (celui de votre domicile par exemple).\n\n\n\n\nFigure 34 : Autorisation localisation\n\n\n\npour finir, autoriser aussi les notifications de l’application (figure 35) afin que cette dernière puisse vous informer des détails des synchronisations.\n\n\n\n\nFigure 35 : Autorisation notifications\n\n\nMaintenant que l’application est correctement installée, par défaut les conditions d’exécution des synchronisations sont réglées pour se faire uniquement en wifi. Pour mon utilisation personnelle et afin de tester directement mes processus de synchronisation, j’ai choisi d’activer l’exécuteur des synchronisations depuis les données mobiles (via 4G ou 5G par exemple). Libre a vous de faire cela aussi (avec aussi en mémoire l’impact que cela peut avoir sur la batterie, mais surtout sur votre forfait mobile), mais dans tous les cas je laisse décoché “Ecécuter en itinérance” afin que la synchronisation ne se fasse pas quand je suis pas exemple à l’étranger ou les données mobiles peuvent être décomptées de manière très importante dans mon forfait (le logiciel passera en veille à ce moment-là). Pour configurer cela il vous suffit de vous rendre dans l’onglet “Paramètres” via les 3 barres eu haut à gauche, de cliquer sur “Conditions d’exécution” (figure 36), puis de cocher/décocher les cases correspondantes (figure 37).\n\n\n\n\n\nFigure 36 : Paramètres synchronisation\n\n\n\n\n\n\nFigure 37 : Autorisation données mobiles\n\n\n\n\nToujours dans les paramètres de l’application, il serait judicieux de cocher dans la section “Comportement” la case “Démarrage automatique” (figure 38) afin que ce dernier lancement automatique dans les processus de synchronisation dès que le téléphone s’allume.\n\n\n\nFigure 38 : Démarrage automatique de l’application\n\n\n\n\n4.4 - Appariement d’un ordinateur avec un téléphone Android\nL’application correctement installée et configurée sur notre ordinateur et notre téléphone, il nous reste maintenant à appareiller nos appareils. Pour cela, le plus simple est de passer par des QR codes d’identification. Sur votre ordinateur ou nous avons configuré Syncthing (section 4.2), ouvrir la fenêtre de configuration (adresse 127.0.0.1:8384 par défaut ou raccourci “Syncthing Configuration Page” sur le bureau) et cliquez sur l’onglet “Actions” puis sur “Afficher mon ID” (figure 39).\n\n\n\nFigure 39 : Affichage QR code\n\n\nRetourner sur l’application Syncthing sur votre téléphone, cliquez sur l’onglet “APPAREILS” puis sur le bouton en haut à droite avec un + pour ajouter un nouvel appareil. Dans la nouvelle fenêtre, cliquez que l’icône de QR code en haut à droite, et acceptez que l’application accède à votre appareil photo (figure 40).\n\n\n\nFigure 40 : Autorisation accès appareil photo\n\n\nDonner un nom à cet appareil (ici j’ai choisi “pc_cnrs”) et cocher la case “Initiateur” (figure 41).\n\n\n\nFigure 41 : Ajout ordinateur\n\n\nMaintenant vous devriez voir une demande d’ajout sur la page de configuration de votre ordinateur (figure 42).\n\n\n\nFigure 42 : Demande ajout ordinateur\n\n\nAccepté là en cliquant sur “Ajouter l’appareil”. Dans l’onglet “Général” donnez-lui un nom convivial (pour mon exemple ce sera “portable_android_mat”, figure 43).\n\n\n\nFigure 43 : Demande ajout téléphone\n\n\nCliquer ensuite sur l’onglet “Partages” et cocher la case correspondant au dossier partager que nous avons créé précédemment (figure 44).\n\n\n\nFigure 44 : Autorisation partage téléphone\n\n\nMaintenant, il nous reste à créer de la même manière que sur notre ordinateur (section 4.2) un dossier partagé contenant notre base de données sur notre téléphone. Pour cela, retour sur notre téléphone, onglet “PARTAGES”, création d’un nouveau partage via le bouton + en haut à droite, et configurer les paramètres. À savoir que :\n\ncomme précédemment, vous pouvez le lui donner le nom que vous voulez (ici ce sera “KeePass”),\nidem vous devez indiquer le même identifiant que celui de votre dossier partagé sur votre ordinateur. Dans mon cas c’est “keepass”,\nvous devez renseigner un emplacement sur votre téléphone ou sera stocké votre base de données. Pour cela, cliquez sur la petite roue crantée. Pour mon exemple et ma configuration personnelle, je serais dans le dossier “/storage/emulated/0/DCIM/KeePass” (j’ai créé le dossier “KeePass” avec le petit + en haut à droite),\nj’ai activé le partage avec l’appareil “pc_cnrs” qui est le pc que j’ai appareillé précédemment.\non valide à la fin avec l’icône en haut à droite.\n\nPour information, vous devriez avoir une configuration du type de la figure 45.\n\n\n\nFigure 45 : Création partage sur téléphone\n\n\nFélicitation, vous appariement et la synchronisation entre vos dossiers devrait être fonctionnel (figure 46 et figure 47).\n\n\n\n\n\nFigure 46 : Sychronisation sur Android\n\n\n\n\n\n\nFigure 47 : Sychronisation sur ordinateur\n\n\n\n\n\n\n4.5 - Appariement de deux ordinateurs\nCette section est un bonus, mais peut être utile par exemple si vous voulez synchroniser votre base de données avec deux ordinateurs, l’un présent sur votre lieu de travail et le second présent à votre domicile, pour le télétravail.\nMaintenant que vous avez synchronisé un ordinateur et un téléphone portable, cette étape sera un jeu d’enfant :\n\neffectué l’installation et la configuration du client Synchting sous Windows sur votre second ordinateur (section 4.2). N’oubliez pas que l’identifiant du partage doit être identique à celui effectué sur l’autre ordinateur et par association avec votre téléphone portable (dans mon exemple ce sera “keepass”),\nréitérer l’étape de la section 4.5 avec le second ordinateur.\n\nÀ l’issue de cette manipulation, vous devriez voir votre second appareil à côté du premier (figure 48).\n\n\n\nFigure 48 : Sychronisation second ordinateur",
    "crumbs": [
      "Liens utiles",
      "Support global",
      "Gestionnaire de mots de passe"
    ]
  },
  {
    "objectID": "pages/support/gestionnaire_mots_de_passe.html#installation-de-lapplication-keepass-sur-android",
    "href": "pages/support/gestionnaire_mots_de_passe.html#installation-de-lapplication-keepass-sur-android",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "5 - Installation de l’application KeePass sur Android",
    "text": "5 - Installation de l’application KeePass sur Android\nPremièrement, félicitations d’être arrivé jusqu’ici, vous avez fait le plus dur. Dans cette dernière partie, nous allons installer une application Android sur notre téléphone qui va nous permettre d’accéder à notre base de données sur ce dernier, mais aussi nous faciliter le remplissage des mots de passe sur les sites internet (même principe que dans la section 3 pour notre ordinateur).\nConcrètement, vous allez avoir le choix entre :\n\nKeePassDX et KeePass2Android pour Android,\nStrongbox et KeePassium pour iOS.\n\nDans notre exemple, je vais utiliser KeePassDX qui a selon moi l’avantage d’avoir une interface légèrement plus agréable que KeePass2Android.\n\n5.1 - Installation et configuration de l’application KeePassDX\nUne fois que vous avez installé l’application KeePassDX sur votre téléphone Android, vous devriez avoir cette première fenêtre (figure 49).\n\n\n\nFigure 49 : KeePassDX\n\n\nIl vous suffit de cliquer sur l’onglet “Ouvrir un coffre-fort existant” puis de sélectionner votre base de données. Dans mon exemple rappelez-vous, elle se trouve dans le dossier “/storage/emulated/0/DCIM/KeePass”. Rentrez votre mot de passe (figure 50) et acceptez l’autorisation de notification (figure 51 et 52).\n\n\n\n\n\nFigure 50 : Déverrouillage avec mot de passe\n\n\n\n\n\n\nFigure 51 : Autorisation notifications\n\n\n\n\n\n\nFigure 52 : Autorisation notifications bis\n\n\n\n\nFélicitations ! Vous avez maintenant accès à votre base de données. Juste une petite mise en garde, vérifiez bien dans le volet des notifications de votre téléphone que votre base de données est bien verrouillée si vous n’en aviez plus besoin. Par défaut, elle devrait se verrouiller automatiquement lors de certaines actions (comme le verrouillage de l’écran), mais cela va dépendre de vos configurations.\nAvant de partir boire un café, il nous reste juste quelques configurations de l’application à effectuer afin notamment de simplifier nos interactions avec cette dernière.\nUne bonne idée est d’activer le déverrouillage biométrique de l’application ce qui nous permettra de déverrouiller cette dernière via notre empreinte par exemple, au lieu de notre mot de passe. Pour cela, rendez-vous dans les paramètres de l’application (cliquez sur les 3 barres en haut à gauche, puis sur l’onglet “Paramètres”), section “Déverrouillage de l’appareil” puis cochez les cases “Déverrouillage biométrique” et “Ouvrir automatiquement l’in..” (figure 53). Lors de la prochaine connexion à la base, votre mot de passe sera demandé encore une fois et il vous suffira de cliquer sur “Liaison avec déverrouillage de l’appareil” en bas (figure 54) pour terminer l’association biométrique (figure 55).\n\n\n\n\n\nFigure 53: Déverrouillage biométrique\n\n\n\n\n\n\nFigure 54 : Premier déverrouillage biométrique\n\n\n\n\n\n\nFigure 55 : Déverrouillage biométrique fonctionnel\n\n\n\n\nLa seconde option intéressante est l’activation du “Magiclavier” qui va permettre d’aide grandement le remplissage automatique des champs des sites internet depuis notre téléphone. Pour l’active, rendez-vous encore une fois dans les paramètres, mais dans l’onglet “Remplissage de formulaire”. Dans cette section, cliquez sur “Paramètres du clavier de l’appareil” sélectionnez l’autorisation pour le “Magiclavier (KeePassDX)”, revenez en arrière et dans la section “Paramètres Magiclavier”, cocher la case “Écran d’authentification de l..” de la sous-section “changement de clavier” (figure 56).\n\n\n\nFigure 56 : Paramètres Magiclavier\n\n\nMaintenant, quand vous arriverez sur un site où vous devez renseigner vos credentials, vous pourrez changer de clavier via le bouton en bas à droite de votre clavier (figure 57), ce qui vous permettra d’avoir accès à un menu connecté à votre base de données afin de renseigner plus simples les champs demandés (figure 58).\n\n\n\n\n\nFigure 57 : Changement de clavier\n\n\n\n\n\n\nFigure 58 : Magiclavier",
    "crumbs": [
      "Liens utiles",
      "Support global",
      "Gestionnaire de mots de passe"
    ]
  },
  {
    "objectID": "pages/contribution.html",
    "href": "pages/contribution.html",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "Vous faites partir de l’UMR, ou non, et vous avez des bouts de codes, documentations techniques ou n’importe quelles ressources informatiques que vous aimeriez tester, standardiser ou même mutualiser ? Vous avez une idée et vous demandez si le processus associé n’a pas déjà été développé par quelqu’un ? Vous êtes au bon endroit !\nCe site, et par addition les ressources associées, sont le fruit de nombreuses heures de travail et de réflexions communes sur des sujets qui au final sont souvent transervaux entre les personnes. Son but est vraiment de centraliser et standardiser au maximum ce qui a été fait et son succès ne dépend que de la synergie que nous mettons en œuvre pour créer du contenu. Par ailleurs, ces ressources ne sont que la partie émergée de l’iceberg qui favorise les relations et les liens que nous pouvons créer entre nous sur nos travaux.\nSi vous voulez contribuer d’une manière ou d’une autre, la clé est vraiment de ne pas se décourager par la tache globale qui peut faire peur, mais vraiment de commencer par un premier pas. Vous constaterez rapidement que derrière un problème ou un obstacle, vous trouverez ici une communauté riche et bienveillante qui saura vous aider, toujours avec un objectif de mutualisation et d’optimisation des ressources informatiques.\nDerrière la multitude de types de contenu que nous pouvons partagé entre nous, qui va d’une documentation en markdown jusqu’a des packages ou des logiciels développés par la communauté, l’idée est d’établir entre nous certains standards permettant de garantir l’intégrité et l’interopérabilité des contenus et ressources disponibles. Ces standards peuvent être vus comme des règles, mais en aucun cas ils ne doivent être assimilés à des freins à votre implication. Par exemple si certains points sont bloquants (par exemple la traduction d’une procédure dans une autre langue ou la méconnaissance de l’utilisation des forges telles que les git), tournés vers la communauté et vous trouverez tout l’aide dont vous avez besoin.\nDe manière générale voici quelques lignes directrices à prendre en compte avant de publier des ressources :\n\nles ressources de ce site sont dédiées à être utilisé par tous le personnel de l’UMR, mais potentiellement les partenaires associés. Par défaut le contenu doit être publié en français, mais aussi en anglais afin de garantir l’accessibilité au “maximum”. Certains contenus, comme les formations, peuvent s’abroger de règles si cela est pertinent. Encore une fois ne vous laissez pas bloqué par la barrière de la langue, vous trouverez forcément quelqu’un de notre communauté qui peut vous aider pour traduire.\nsuivante le type de contenu que vous voulez publiez, le mieux est parfois de ce tourner vers des personnes-ressources ou référentes qui pourront vous apporter des solutions ou des propositions pour vous guider dans la mutualisation de vos ressources. La liste de ces personnes clés sera mise à disposition sous peu et en attendant si vous ne savez pas vers qui vous tourner vous pouvez envoyer un mail aux administrateurs du DEN.\ntoujours dans un but de mutualisation et globalement d’harmonie des templates seront proposés pour les différents types de ressources. En attendant, n’hésitez pas à échanger avec les personnes de la communauté pour essayer de trouver, autant que possible, une structure commune.\nmême si l’utilisation des ressources informatique au sein de l’UMR doit vraiment être vu de manière transversale et sans “frontières” associées, la mutualisation et l’accessibilité de ces derniers est vraiment en lien avec le Dispositif d’Ecologie Numérique, ou DEN. Cette entité, transversale au niveau de l’UMR à comme objectifs la mise en place, la coordination et la mutualisation des moyens techniques ainsi que l’échange de méthodologies et de nouvelles approches en support aux aspects numériques des travaux de recherche scientifique. Vous rapprocher de ce dispositif et des sous-entités qui le composent peut être judicieux et vous apporter un support non négligeable au sein de vos activités.\nde par sa nature, ce site est voué à évoluer en lien avec les besoins. N’hésitez pas à faire des suggestions d’améliorations, proposer de nouvelles sections ou même une organisation différente. Au final cela ne pourra être que bénéfique à la communauté.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Je veux contribuer !"
    ]
  },
  {
    "objectID": "pages/formations/index_formations.html",
    "href": "pages/formations/index_formations.html",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "Cette section est dédié à référencer les formations et supports associés mis à disposition de l’UMR et de ses partenaires. En lien avec le caractère spécifique des formations, il est possible que les supports associés ne soient pas disponibles en plusieurs langues. Par ailleurs en suivante ce lien à définir vous trouverez une liste des formations dispensée par l’UMR et surtout les prochaines dates de réalisation.\nPour information, la plupart des sous-sections suivantes renvoi vers des dépôts Git ou sont stockées sur les ressources des formations. Si vous avez des questions en rapport avec ces dernières, le mieux est d’utiliser les services mis à disposition du dépôt (la section “Issues” par exemple) ou à défaut de contacter directement la ou les personnes-ressources associées.\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Formations"
    ]
  },
  {
    "objectID": "pages/formations/tidyverse.html",
    "href": "pages/formations/tidyverse.html",
    "title": "Formation tidyverse",
    "section": "",
    "text": "Formation tidyverse\n\n\nLe code source de la formation tidyverse est accessible sur le dépot GitHub.\nLa présentation associée est disponible à l’adresse suivante.\nLa dernière session a eu lieu le 3 et 4 mars 2025.\nDes précisions seront communiquées ultérieurement concernant les prochaines sessions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Formations",
      "Formation Tidyverse"
    ]
  },
  {
    "objectID": "pages/git/miroir_github_git.html",
    "href": "pages/git/miroir_github_git.html",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "Dès lors que l’on commence à vouloir travailler en équipe sur des bouts de code, voir de manière générale sur des développements informatiques, l’utilisation d’un outil de contrôle de version est rapidement un outil incontournable et un allié précieux pour toute personne soucieuse de gérer efficacement son travail. Ici nous n’aborderons pas les caractéristiques d’un git, ou système de contrôle de version, mais nous proposons une solution pouvant aider à résoudre une question que l’on se pose souvent, à savoir vers quel système, ou forge, se tourner.\nUn rapide coup d’œil sur internet vous montrera qu’il existe plusieurs forges. L’une des plus populaires est GitHub mais il en existe d’autres comme GitLab ou encore Bitbucket. Il est aussi tout à fait possible que votre institut ou organisme utilise l’un de ces systèmes pour héberger sa propre forge (jeter un coup d’œil ici). Chaque système présente des avantages et des inconvénients et votre choix doit être guidé par vos besoins. À titre d’exemple vous trouverez un rapide comparatif des principales forges dans le tableau ci-dessous.\n\n\n\n\n\n\n\n\n\n\nCritères\nGitHub\nGitLab\nBitbucket\nGitea\n\n\n\n\nPopularité\nTrès élevée\nÉlevée\nMoyenne\nFaible\n\n\nCI/CD intégré\nGitHub Actions (simple et puissant)\nTrès robuste et flexible\nIntégré, mais limité\nDépends de l’intégration manuelle\n\n\nOpen source\nNon\nOui\nNon\nOui\n\n\nHébergement gratuit\nDépôt privé gratuit illimité\nDépôt privé gratuit illimité\nDépôt privé gratuit illimité\nNécessite un serveur\n\n\nAutohébergement\nNon\nOui\nOui\nOui\n\n\nFocus équipes privées\nMoyen\nFort\nTrès fort (intégré à Jira)\nAdapté",
    "crumbs": [
      "Liens utiles",
      "Système de contrôle de version",
      "Miroir depuis Github vers un dépôt git"
    ]
  },
  {
    "objectID": "pages/git/miroir_github_git.html#pourquoi-utiliser-une-forge-git",
    "href": "pages/git/miroir_github_git.html#pourquoi-utiliser-une-forge-git",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "Dès lors que l’on commence à vouloir travailler en équipe sur des bouts de code, voir de manière générale sur des développements informatiques, l’utilisation d’un outil de contrôle de version est rapidement un outil incontournable et un allié précieux pour toute personne soucieuse de gérer efficacement son travail. Ici nous n’aborderons pas les caractéristiques d’un git, ou système de contrôle de version, mais nous proposons une solution pouvant aider à résoudre une question que l’on se pose souvent, à savoir vers quel système, ou forge, se tourner.\nUn rapide coup d’œil sur internet vous montrera qu’il existe plusieurs forges. L’une des plus populaires est GitHub mais il en existe d’autres comme GitLab ou encore Bitbucket. Il est aussi tout à fait possible que votre institut ou organisme utilise l’un de ces systèmes pour héberger sa propre forge (jeter un coup d’œil ici). Chaque système présente des avantages et des inconvénients et votre choix doit être guidé par vos besoins. À titre d’exemple vous trouverez un rapide comparatif des principales forges dans le tableau ci-dessous.\n\n\n\n\n\n\n\n\n\n\nCritères\nGitHub\nGitLab\nBitbucket\nGitea\n\n\n\n\nPopularité\nTrès élevée\nÉlevée\nMoyenne\nFaible\n\n\nCI/CD intégré\nGitHub Actions (simple et puissant)\nTrès robuste et flexible\nIntégré, mais limité\nDépends de l’intégration manuelle\n\n\nOpen source\nNon\nOui\nNon\nOui\n\n\nHébergement gratuit\nDépôt privé gratuit illimité\nDépôt privé gratuit illimité\nDépôt privé gratuit illimité\nNécessite un serveur\n\n\nAutohébergement\nNon\nOui\nOui\nOui\n\n\nFocus équipes privées\nMoyen\nFort\nTrès fort (intégré à Jira)\nAdapté",
    "crumbs": [
      "Liens utiles",
      "Système de contrôle de version",
      "Miroir depuis Github vers un dépôt git"
    ]
  },
  {
    "objectID": "pages/git/miroir_github_git.html#pourquoi-se-tourner-vers-github",
    "href": "pages/git/miroir_github_git.html#pourquoi-se-tourner-vers-github",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "Pourquoi se tourner vers GitHub ?",
    "text": "Pourquoi se tourner vers GitHub ?\nLa procédure que vous êtes en train de lire vous propose une solution afin de copier de manière automatique le contenu d’un dépôt GitHub vers le dépôt d’une autre forge, tel que GitLab. Sans rentrer trop dans les délais et toujours en gardant à l’esprit que la selection de votre forge doit se faire en accord avec vos besoins, pourquoi avons-nous fait le choix de se tourner vers GitHub.\nLa raison principale est que GitHub propose par défaut un écosystème riche et surtout des intégrations natives, notamment via les GitHub actions. Ces outils sont vraiment des alliés très efficaces pour vos développements et facilitent grandement les processus d’intégration/déploiement continus. De nombreuses communautés, tels que la celle de R, a déjà mis à disposition de nombreuses “Github actions”. Ces dernières permettent d’automatiser de nombreux processus, qui vont aussi bien de la vérification de votre code, que de la publication de documentation associée aux développements/packages. De plus, une grande partie des workflows peut être centralisée via GitHub, ce qui réduit considérable la dépendance à d’autres outils tiers.\nPar ailleurs, GitHub est la forge la plus utilisée au monde, avec une immense communauté d’utilisateur. Concrètement il est très difficile pour une autre forge de rivaliser au niveau du référencement ou de la visibilité de GitHub. De plus, de nombreuses fonctionnalités, comme la section Discussions ou encore l’affichage ouvert des contributions, renforcent la collaboration et son interface est souvent perçue comme étant la plus simple et intuitive parmi les forges.\nOutre le fait qu’il soit largement adopté par les entreprises et les projets open source, le volet IA de GitHub, via son utilitaire GitHub Copilot, peut être une aide dans la construction de vos ressources.\nPour finir, la version gratuite est déjà très performante et présente l’avantage de proposer des dépôts privés illimités ainsi que la collaboration avec plusieurs contributeurs sans frais supplémentaires.",
    "crumbs": [
      "Liens utiles",
      "Système de contrôle de version",
      "Miroir depuis Github vers un dépôt git"
    ]
  },
  {
    "objectID": "pages/git/miroir_github_git.html#pourquoi-ne-pas-utiliser-uniquement-github",
    "href": "pages/git/miroir_github_git.html#pourquoi-ne-pas-utiliser-uniquement-github",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "Pourquoi ne pas utiliser uniquement GitHub ?",
    "text": "Pourquoi ne pas utiliser uniquement GitHub ?\nAu vu de la section précédente, on peut se demander pourquoi ne pas utiliser uniquement GitHub qui semble être le choix le plus judicieux. Malgré tous ces avantages, il ne faut pas oublier que GitHub reste la propriété de Microsoft et que par conséquent il est possible qu’un futur changement de la politique commerciale de Microsoft ne devienne pénalisant ou même incompatible avec votre travail. Même s’il est peu probable qu’une telle évolution soit “brutale” au point de ne pas vous permettre de prendre les mesures nécessaires, il peut être judicieux de réfléchir à des solutions permettant en quelque sorte de profiter du meilleur des mondes mis à notre disposition.\nL’objectif de cette procédure est donc de fournir une solution qui permet de copier, de manière automatique, l’intégralité d’un dépôt GitHub vers une autre forge. Pour ce tutoriel nous prendrons l’exemple d’une forge GitLab hébergé par l’IRD.",
    "crumbs": [
      "Liens utiles",
      "Système de contrôle de version",
      "Miroir depuis Github vers un dépôt git"
    ]
  },
  {
    "objectID": "pages/git/miroir_github_git.html#procédure-pour-créer-un-miroir-entre-deux-dépôts-github-vers-gitlab-ird",
    "href": "pages/git/miroir_github_git.html#procédure-pour-créer-un-miroir-entre-deux-dépôts-github-vers-gitlab-ird",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "Procédure pour créer un miroir entre deux dépôts (GitHub vers GitLab IRD)",
    "text": "Procédure pour créer un miroir entre deux dépôts (GitHub vers GitLab IRD)\n\nPrérequis et cadre de la procédure\nAfin de suivre au mieux la procédure, il est conseillé d’être un minimum familiarisé avec l’utilisation d’une forge git, idéalement GitHub. Par ailleurs, nous partirons du principe que vous disposez d’un compte correctement configuré sur GitHub et la forge de destination (pour l’exemple ici le GitLab de l’IRD). Au besoin, vous trouverez l’adresse mail de la personne ressource à l’origine de cette procédure en haut de la page. N’hésitez pas à la contacter si vous avez besoin d’aide.\nPour informatique, les images en lien avec la procédure ont été générées via des interfaces en anglais, ce qui devrait être la configuration par défaut sur la majorité des logiciels concernés.\n\nTableau 1 : État des tests de la procédure.\n\n\n\n\n\n\n\nSystème d’exploitation\nProcédure fonctionnelle\nÉdition et version\n\n\n\n\nWindows\nOui\n11 Professionnel, version 23H2\n\n\nMac\nNon testée\n\n\n\nLinux\nNon testée\n\n\n\n\n\n\n1. Initialisation des dépôts\n\n1.1 Création d’un dépôt source sur GitHub\nTout d’abord nous allons créer un dépôt source sur la forge GitHub. Pour l’exemple ici nous avons créé un dépôt public nommé “my_github_repository” avec des paramètres initiaux configuré globalement pour abriter des codes R (figure 1).\n\n\n\n\nFigure 1 : Configuration du dépôt source GitHub\n\n\n\nPour information notre test ici créer un dépôt “public”, car nous sommes parties du principe que notre contenu en développement a vocation à être partagé avec tout le monde et ne présente aucun caractère confidentiel ou privé. Vous pouvez tout à fait appliquer cette procédure sur un dépôt “private” (à tester, peut-être certains paramètres en lien avec les secrets cités plus loin devront être modifiés), mais dans ce cas il est judicieux de réfléchir à la véracité d’utiliser GitHub pour des données qui présentent un caractère privé. Cela ne veut pas dire de ne jamais publier des répertoires privés sur GitHub, mais de ne pas oublier que malgré tous les bénéfices, GitHub reste une forge propriétaire de Microsoft.\n\n\n1.2 Création d’un dépôt cible sur une autre forge\nLa seconde étape est de créer un second dépôt cible sur une autre forge. Comme cité précédemment, nous allons utiliser une forge GitLab hébergé par l’IRD, auquel les personnels de l’UMR peuvent avoir accès. Vous trouverez dans la figure 2 ci-dessous un exemple de configuration.\n\n\n\n\nFigure 2 : Configuration du dépôt cible GitLab\n\n\n\nVous noterez, en opposition à notre configuration de notre dépôt source GitHub, que notre dépôt est ici publié en “private”. Cela se justifie afin de minimiser les “interactions” que les utilisateurs peuvent avoir sur ce dépôt. Vous allez voir par la suite que nous allons automatiser le flux de données entre notre dépôt source (GitHub) et notre dépôt cible (GitLab de l’IRD) et au final vous n’allez pas interagir directement sur le dépôt cible, comme l’on va le faire sur notre dépôt source au cours de sa vie. Encore pire, le flux de données que nous allons créer va être un flux unidirectionnel vers notre dépôt source, des modifications directes sur ce dépôt ne seront surement pas sauvegardées, risqueraient de provoquer des troubles dans l’automatisation et seraient même contraires à la logique de la procédure.\n\n\n\n2. Connexion entre les deux forges\nMaintenant que nous avons créé les deux dépôts, il va falloir établir une connexion entre eux. Il y a plusieurs manières de faire, mais ce que nous allons utiliser ici s’appelle la création d’un jeton d’accès, ou “token”. Certains d’entre vous ont déjà dû effectuer cette action, notamment si vous avez fait une connexion entre un git et Rstudio. Nous n’allons pas rentrer dans les détails de la création d’un jeton d’accès et si besoin une procédure plus détaillée pourra être réalisée Juste pour résumer, nous allons créer un jeton d’accès depuis la forge du dépôt cible, que nous allons renseigner ensuite au niveau du dépôt source.\n\n2.1 Création d’un jeton d’accès sur le dépôt cible\nPour effectuer cela, il suffit de se placer au niveau de la racine de notre dépôt cible (ici celui que nous avons appelé “my_gitlabird_repository”). Dans le menu à gauche vous devriez voir une section “Settings” et une sous-section “Access tokens”. Cela devrait sous amener sur l’onglet de la figure 3.\n\n\n\n\nFigure 3 : Onglet “Access tokens”\n\n\n\nPour créer un nouveau jeton d’accès, il suffit de cliquer sur l’onglet “Add new token”. Dans la nouvelle fenêtre, vous trouverez plusieurs onglets à renseigner :\n\n“Token name”, le nom du jeton d’accès. Idéalement le nom doit être assez explicite et vous permettre de comprendre à quoi il sert. La plupart d’entre nous n’auront pas plus d’un jeton d’accès par dépôt, mais il est possible d’en ajouter plusieurs et dans ce cas il faut pouvoir les identifier.\n“Expiration date”, il s’agit de la date d’expiration du jeton d’accès. D’un point de vue sécuritaire, il peut être dangereux de créer un jeton qui ne possède pas de date d’expiration (si on clique sur la croix à droite de la date). Au-delà de la simplicité de faire cela (on n’a plus à s’occuper de notre connexion), créer une connexion via un jeton d’accès va créer une “faille” potentielle dans la sécurité de votre dépôt qui pourra servir de point d’entrée à de potentielles attaques malveillantes. Il ne faut pas devenir paranoïaque, mais l’idée est plus d’avoir une réflexion sur la durée de vie de votre jeton. Mon projet est-il un projet à court terme ? Y a-t-il une échéance future qui est susceptible de modifier la pertinence de ce jeton (par exemple modification de l’intégrité du dépôt source) ? concrètement vais-je penser à supprimer mon jeton d’accès si je n’en ai plus besoin. Libre à vous de fixer vos propres règles. Ici par exemple nous avons identifié un jeton qui sera valide jusqu’au 01/05/2025.\n“Select a role”. Dans le cas de l’utilisation d’un jeton d’accès personnel pour effectuer des actions de miroir depuis GitHub vers GitLab, nous n’avons pas besoin de nous concentrer directement sur les rôles, car les “scopes” de la section suivante sont ce qui détermine les permissions du jeton. Cependant, le rôle associé à un jeton d’accès personnel peut influencer certaines permissions d’accès à des projets ou des groupes. Si l’on veut être rigoureux, le plus judicieux est de choisir un rôle comme “Developer”. Un développeur va être une entité qui peut pousser du code, créer des branches, faire des “pull requests” et gérer les dépôts (ce que nous voulons faire ici).\n“Selected scopes”. Cette dernière section celle qui va définir les permissions et concrètement à quoi l’on peut avoir accès grâce à notre jeton. Pour faire un miroir, nous avons besoin de 3 droits spécifiques :\n\n“api” : permets d’effectuer toutes les actions de l’API, y compris la gestion des dépôts, des projets, etc.\n“write_repository” : permets de pousser dans les dépôts GitLab (nécessaire pour le miroir).\n“read_repository” : permets de lire les dépôts GitLab (si nécessaire pour la configuration ou la vérification).\n\n\n\n\n\n\nFigure 4 : Configuration du jeton d’accés\n\n\n\nValider votre configuration via le bouton “Create project access token” en bas.\nLa prochaine page qui s’affiche devrait vous indiquer la validation de la création de votre jeton d’accès, mais aussi vous présenter sa valeur. Vous pouvez l’afficher en cliquant sur bouton en forme d’œil. Juste en dessous de votre jeton, vous remarquerez un message vous indiquant que ce jeton ne sera dévoilé uniquement maintenant et il ne sera plus possible par la suite de la visualiser (dans un souci de sécurité). L’idée est de le copier (cliquez que le bouton situé à droite de celui en forme d’œil), de le stocker quelque part (par exemple dans un gestionnaire de mots de passe) car nous allons devoir le renseigner dans notre a source GitHub.\n\n\n2.2 Renseignement de notre jeton d’accès sur le dépôt source\nMaintenant que nous avons notre jeton d’accès pour notre dépôt cible, il va falloir le renseigner au niveau de notre dépôt source. Pour cela, il faut se rendre sur la page de notre dépôt source (dans l’exemple, le dépôt GitHub que nous avons appelé “my_github_repository”), de cliquer sur l’onglet “Settings”, la section “Secrets and variables” et la sous-section “Actions”. Dans la nouvelle page qui s’affiche, cliquez sur le bouton “New respository secret” situé dans la partie “Repository secrets”. Il vous suffit ensuite de renseigner un nom pour ce secret (comme précédent il doit être parlant pour l’utilisateur) et de coller la valeur de votre jeton dans la partie “Secret” (figure 5).\n\n\n\n\nFigure 5 : Configuration d’un secret associé à un dépôt GitHub\n\n\n\n\n\n\n3. Création du processus de miroir et automatisation\n\n3.1 Création du script “GitHub Action”\nNos deux dépôts étant connectés, nous pouvons maintenant commencer à travailler sur la création du processus de miroir ainsi que son automatisation. Pour faire cela, nous allons créer une “GitHub action”. Nous en avons parlé précédemment, mais ce type de processus va nous permettre d’exécuter des processus en arrière-plan et surtout d’automatiser le lancement de ces derniers.\nPour faire cela, nous avons deux possibilités, (1) créer et adapter manuellement notre fichier yaml associé à la “GitHub Action” ou (2) utiliser une fonction du package sparck qui va nous simplifier les étapes de création.\n\n3.1.1 Création et adaptation manuelle de la “GitHub Action”\nConcrètement pour cela, nous devons nous rendre à la racine de notre dépôt source GitHub et de créer un dossier “.github” ainsi qu’un sous dossier “workflows”. À l’intérieur de ce dernier dossier, nous allons copier le code ci-dessous dans un éditeur de code source (type Notepad ou encore Visual Studio Code).\nname: GitHub to GitLab IRD mirror with release assets\n\non:\n  push: \n    branches:\n      - '**'\n    tags:\n      - '**'\n  pull_request:\n    branches:\n      - '**'\n  delete:\n    branches:\n      - '**'\n    tags:\n      - '**'\n  release:\n    types:\n      - created\n      - published\n      - edited\n      - deleted\n\njobs:\n  mirror:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Clone repository as bare\n        run: |\n          git clone --bare &lt;github_repository_source_url&gt;.git my-github-repository.git\n\n      - name: Set up Git\n        run: |\n          git config --global user.name \"GitHub Actions\"\n          git config --global user.email \"github-actions@users.noreply.github.com\"\n\n      - name: Add forge remote\n        run: |\n          cd my-github-repository.git\n          git remote add mirror https://oauth2:${{ secrets.&lt;secret_token_name&gt; }}@&lt;git_repository_target_url&gt;.git\n  \n      - name: Push to forge\n        run: |\n          cd my-github-repository.git\n          git push --mirror mirror\n\n  download-release-assets:\n      runs-on: ubuntu-latest\n      needs: mirror\n\n      steps:\n        - name: Set up Git (Authentication)\n          run: |\n            git config --global user.name \"GitHub Actions\"\n            git config --global user.email \"github-actions@users.noreply.github.com\"\n\n        - name: Fetch release(s) from GitHub\n          id: fetch_releases\n          run: |\n            RESPONSE=$(curl -s -H \"Authorization: token ${{ secrets.GITHUB_TOKEN }}\" \\\n              \"https://api.github.com/repos/&lt;github_repository_source_url_api&gt;/releases\")\n          \n            RELEASE_IDS_NAMES=$(echo \"$RESPONSE\" | jq -r '.[] | \"\\(.id) \\(.name)\"')\n\n            if [ -z \"$RELEASE_IDS_NAMES\" ]; then\n              echo \"No release found. No action required.\"\n              echo \"SKIP_NEXT_STEP=true\" &gt;&gt; $GITHUB_ENV\n              exit 0\n            fi\n\n            NUM_RELEASES=$(echo \"$RELEASE_IDS_NAMES\" | wc -l)\n            echo \"Number of releases found: $NUM_RELEASES\"\n            echo \"NUM_RELEASES=$NUM_RELEASES\" &gt;&gt; $GITHUB_ENV\n\n            RELEASE_IDS=\"\"\n            RELEASE_NAMES=\"\"\n            \n            while IFS= read -r line; do\n              RELEASE_ID=$(echo \"$line\" | awk '{print $1}')\n              RELEASE_NAME=$(echo \"$line\" | awk '{print $2}')\n              RELEASE_IDS=\"$RELEASE_IDS$RELEASE_ID,\"\n              RELEASE_NAMES=\"$RELEASE_NAMES$RELEASE_NAME,\"\n            done &lt;&lt;&lt; \"$RELEASE_IDS_NAMES\"\n\n            RELEASE_IDS=${RELEASE_IDS%,}\n            RELEASE_NAMES=${RELEASE_NAMES%,}\n\n            echo \"RELEASE_IDS=$RELEASE_IDS\" &gt;&gt; $GITHUB_ENV\n            echo \"RELEASE_NAMES=$RELEASE_NAMES\" &gt;&gt; $GITHUB_ENV\n\n        - name: Download release(s) asset(s) from GitHub\n          id: download_assets\n          if: ${{ env.SKIP_NEXT_STEP != 'true' }}\n          run: |\n            ASSETS_FOUND=false\n            NUM_RELEASES=${{ env.NUM_RELEASES }}\n            RELEASE_IDS=${{ env.RELEASE_IDS }}\n            RELEASE_NAMES=${{ env.RELEASE_NAMES }}\n            IFS=',' read -ra RELEASE_IDS_ARRAY &lt;&lt;&lt; \"$RELEASE_IDS\"\n            IFS=',' read -ra RELEASE_NAMES_ARRAY &lt;&lt;&lt; \"$RELEASE_NAMES\"\n            for num_release in $(seq 0 $((NUM_RELEASES - 1))); do\n              RELEASE_ID=\"${RELEASE_IDS_ARRAY[$num_release]}\"\n              RELEASE_NAME=\"${RELEASE_NAMES_ARRAY[$num_release]}\"\n              echo \"Processing release ID: $RELEASE_ID with Name: $RELEASE_NAME\"\n              ASSETS=$(curl -s \\\n                -H \"Authorization: token ${{ secrets.GITHUB_TOKEN }}\" \\\n                \"https://api.github.com/repos/&lt;github_repository_source_url_api&gt;/releases/$RELEASE_ID/assets\" \\\n                | jq -r '.[].browser_download_url')\n              if [ -z \"$ASSETS\" ]; then\n                echo \"No assets found for release $RELEASE_ID ($RELEASE_NAME). Skipping download step.\"\n                continue\n              else\n                ASSETS_FOUND=true\n                mkdir -p \"release-assets/$RELEASE_ID\"_\"$RELEASE_NAME\"\n                cd \"release-assets/$RELEASE_ID\"_\"$RELEASE_NAME\"\n        \n                for URL in $ASSETS; do\n                  echo \"Downloading $URL\"\n                  curl -L -o \"$(basename \"$URL\")\" -H \"Authorization: token ${{ secrets.GITHUB_TOKEN }}\" \"$URL\"\n                done\n        \n                cd -\n              fi\n            done\n            if [ \"$ASSETS_FOUND\" = false ]; then\n              echo \"No assets found for any release. Exiting.\"\n              echo \"SKIP_NEXT_STEP=true\" &gt;&gt; $GITHUB_ENV\n              exit 0\n            fi\n\n        - name: Push asset(s) to mirror repository\n          id: push_mirror\n          if: ${{ env.SKIP_NEXT_STEP != 'true' }}\n          run: |\n            git clone https://oauth2:${{ secrets.&lt;secret_token_name&gt; }}@&lt;git_repository_target_url&gt;.git\n            cd test_miroir_github\n\n            if [ -d \"release-assets\" ]; then\n              echo \"Removing existing release-assets directory from the mirror repository.\"\n              rm -rf release-assets\n            fi\n\n            echo \"Copying local release-assets directory to the mirror repository.\"\n            cp -r \"../release-assets\" .\n\n            git add .\n            git commit -m \"Add release assets from GitHub releases\"\n\n            BRANCH_NAME=$(git symbolic-ref --short HEAD)\n\n            git push origin \"$BRANCH_NAME\"\nDans ce script il sera nécessaire d’adapter certaines variables en fonction de votre environnement :\n\n&lt;github_repository_source_url&gt; pour l’adresse URL de votre répertoire source GitHub. Pour l’exemple ici on aura la valeur “https://github.com/umr-marbec/my_github_repository” (sans les guillemets, idem pour toutes les variables suivantes).\n&lt;secret_token_name&gt; qui va renseigner le nom du secret que nous avons identifié au niveau du dépôt source GitHub (lien section 2.2). Ici nous utiliserons “TOKEN_MY_GITLABIRD_REPOSITORY”. Attention, si vous remarquez dans la figure 5, le nom de mon secret était en minuscule. Par défaut, GitHub passe tous les caractères en majuscule.\n&lt;git_repository_target_url&gt; pour l’adresse ULR de votre dépôt cible, sans la valeur “https://” en début de chaine. Par exemple ici pour la forge de l’IRD on utilisera la valeur “forge.ird.fr/marbec/private/depetris-mathieu/my_gitlabird_repository”.\n&lt;github_repository_source_url_api&gt; pour l’adresse URD du répertoire source GitHub, mais en version “light” (sans “https://github.com/”). Pour notre exemple la valeur sera “umr-marbec/my_github_repository”.\n\nUne fois que vous avez correctement remplacé ces variables, il vous suffit d’enregistrer le fichier au format YAML (au besoin l’extension à renseigner est .yml). Pour notre exemple ici, mon fichier s’appellera mirror_github_to_irdgitlab.yml et il sera placé comme indiqué précédemment dans le répertoire “workflows” que nous créer sur le dépôt cible GitHub.\n\n\n3.1.2 Utilisation de la fonction add_github_action() du package sparck\nSi vous préférez utiliser une approche simplifiée, vous pouvez utiliser comme cité précédemment le package R sparck et plus précisément la fonction associée add_github_action().\nPour cela, il faut commencer par l’installer sous R via la commande suivante :\n# Vous allez avoir besoin du package devtools pour récupérer le package sparck qui se trouve un dépôt GitHub\n# Si besoin utilisez install.packages(\"devtools\")\ndevtools::install_github(\"https://github.com/umr-marbec/sparck\")\nPour la suite, il faut définir le répertoire de travail de R comme étant celui de votre dépôt. Si vous utilisez un dépôt pour des codes en lien avec R, il est possible que vous ayez un fichier .Rproj dans ce dernier qui vous permet de lancer une session R directement dans le dépôt.\nLa dernière étape est de lancer la fonction add_github_action() avec les paramètres de configurations en lien avec votre environnement. Si nous reprenons notre exemple pour cette procédure, la ligne de commande sera la suivante :\nadd_github_action(github_action_name = \"mirror_github_git\",\n                  arguments = c(\"github_repository_source_url\" = \"https://github.com/umr-marbec/my_github_repository\",\n                                \"secret_token_name\" = \"TOKEN_MY_GITLABIRD_REPOSITORY\",\n                                \"git_repository_target_url\" = \"https://forge.ird.fr/marbec/private/depetris-mathieu/my_gitlabird_repository\"))\nEn comparaison d’une modification manuelle de notre “GitHub Action” (étape en 3.1.1), vous constaterez que les variables à renseigner sont beaucoup plus “simple” et que la fonction s’occupe automatiquement du formatage et de la création du dossier “.github” et sous-dossier “workflows” dans votre répertoire de travail (vous devez pour cela avoir les droits associés pour modifier votre système de fichiers).\n\n\n\n3.2 Configuration de la branche principale du dépôt cible\nÀ ce stage de la procédure, votre “GitHub action” devrais être fonctionnelle. Cependant si elle se lance (par exemple en faisant une modification, comme un “push”, sur notre dépôt source GitHub) vous devriez avoir une erreur comme celle illustrée sur la figure 6.\n\n\n\n\nFigure 6 : Erreur en lien avec une branche protégée\n\n\n\nRapidement cette erreur vous indique que la branche de notre dépôt cible est protégée et ne permet pas à notre processus de procéder à une synchronisation. Pour résoudre ce problème, il suffit de se rendre sur le dépôt cible, comme précédemment se aller sur l’onglet “Settings”, section “Repository” et sous-section “Protected branches” (figure 7).\n\n\n\n\nFigure 7 : Page “Protected branches”\n\n\n\nDe manière générale, les branches par défaut des gits sont souvent protégées. Cela permet à la majorité des utilisateurs d’appliquer automatique des mesures se sécurité qui permettent d’éviter d’opérer par mégarde des actes pouvant toucher à l’intégrité du dépôt. Dans notre cas, nous savons ce que nous voulons faire et nous avons besoin de lever ces protections afin de pouvoir effectuer notre miroir. Pour cela il suffit de cliquer sur le bouton rouge “Unprotect” sur votre branche par défaut (à ce stade vous ne devriez en avoir qu’une) et de l’action dans le popup qui s’affiche.\n\n\n\n4. Petit mot de la fin\nFélicitations, si vous êtes arrivé à ce point, vous devriez avoir un miroir fonctionnel entre vos deux dépôts, qui lance son processus associé à chaque modification sur le dépôt source.\nQuelques petits conseils pour la suite :\n\nn’hésitez pas à faire des retours sur cette procédure, surtout si vous avez des suggestions d’améliorations. Par exemple, le test de cette procédure sur plusieurs systèmes d’exploitation ou encore avec des spécifications différentes de celles cadrées ici (comme le test sur un dépôt source privée) seraient des retours très enrichissants.\nlors des tests ad hoc, nous avons noté certains ratés dans les processus de miroir. Concrètement vos actions “ordinaires” liées à l’intégration de codes, la création de branches ou la majorité des actions basiques n’ont montré aucune défaillance. Par contre quand vous allez commencer à effectuer des “realeases”, ajouter des “assets” à ces dernières, jouer un peu avec les limites en supprimant ces dernières, les “tags” associés …. il est arrivé que le miroir ne se déclenche pas. Normalement la chose est rapidement compensée par le prochain miroir sur un “commit” par exemple, mais n’hésitez pas à faire remonter des défaillances afin que nous puissions améliorer la procédure.",
    "crumbs": [
      "Liens utiles",
      "Système de contrôle de version",
      "Miroir depuis Github vers un dépôt git"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bienvenue !",
    "section": "",
    "text": "Bienvenue !\nL’objectif de ce site est de centraliser et mettre facilement à disposition des ressources informatiques, procédures et autres supports permettant d’appuyer de manière globale les travaux des personnelles et personnes associées de l’UMR MARBEC. Cette structuration s’appuie notamment sur Dispositif d’Ecologie Numérique, ou DEN, qui est une structure transversale associée à l’UMR. Ces missions sont la mise en place, la coordination et la mutualisation des moyens techniques ainsi que l’échange de méthodologies et de nouvelles approches en support aux aspects numériques des travaux de recherche scientifique.\nVous disposez aussi d’une section Issues vous permettant par exemple de faire remonter un problème dans le code source du site ou encore proposer une amélioration ou du contenu. Ces “GitHub Issues” sont vraiment à voir comme des objets s’apparentent davantage à des éléments « à faire » et sont axées sur les tâches à accomplir (par exemple via la création de branche dédié au sujet).\nDe plus, vous trouverez un forum de discussion afin d’échanger sur des sujets ou des problématiques communes. Les discussions sont destinées aux conversations qui doivent être transparentes et accessibles, mais qui n’ont pas besoin d’être suivies sur un projet et qui ne sont pas liées au code, contrairement aux “GitHub Issues”.\nPour information, l’UMR dispose aussi d’un serveur Rocket chat accessible via l’URL suivante https://tchat.ird.fr/home. Il est possible d’accéder à l’espace de travail directement depuis l’URL ou en installant un client lourd (=logiciel) sur votre ordinateur et en ajoutant l’URL dans la section “add workspace”.\nPar ailleurs, afin de faciliter l’accès et l’utilisation par le plus grand nombre, vous trouverez ce site et les ressources associées en français (par défaut) mais aussi en anglais (utilisez le bouton à gauche de barre de recherche pour changer de langue).\nN’hésitez pas visiter aussi la section “Je veux contribuer !” si vous disposez de ressources susceptibles d’alimenter celles disponibles via ce site ou même de manière générale si vous voulez contribuer à la mise a disposition de ressources communes.\nEn cas de besoin spécifique, vous pouvez contacter les représentant(e)s et référent(e)s du DEN à l’adresse suivante : marbec-den-admin@listes.ird.fr\nPour information, ce site a été généré via le système de publication Quarto.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/git/index_git.html",
    "href": "pages/git/index_git.html",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "Vous trouverez dans cette section tous les ressources en lien avec l’utilisation des systèmes de controle de version. Au niveau de l’UMR plusieurs forges sont utilisées, à savoir :\n\nGitHub MARBEC\nGitLab IRD\nGitLab Ifremer\n\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Système de contrôle de version"
    ]
  },
  {
    "objectID": "pages/liens.html",
    "href": "pages/liens.html",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "UMR MARBEC\n“Issues” du dépôt GitHub\nForum de discussion du dépôt GitHub\nULR du serveur rocket chat de l’UMR\nContact reférent(e)s du DEN\n\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/formations/r_package_developpement.html",
    "href": "pages/formations/r_package_developpement.html",
    "title": "Formation developpement de package R",
    "section": "",
    "text": "Formation developpement de package R\n\n\nLe code source de la formation est accessible sur le dépot GitHub.\nLa présentation associée sous la forme d’une livre est disponible à l’adresse suivante.\nLa formation est en cours de création et devra être finalisée courant 2025.\nIl est prévu qu’une première session de formation soit organisée, au plus tard fin 2025.\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Formations",
      "Formation developpement de package R"
    ]
  },
  {
    "objectID": "pages/formations/git.html",
    "href": "pages/formations/git.html",
    "title": "Atelier Git",
    "section": "",
    "text": "Atelier Git\nLe code source de la formation Git est accessible sur GitHub. La formation est accessible ci-dessous.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Formations",
      "Formation Git"
    ]
  },
  {
    "objectID": "pages/calendrier/calendrier.html",
    "href": "pages/calendrier/calendrier.html",
    "title": "Calendrier",
    "section": "",
    "text": "Calendrier\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Calendrier"
    ]
  },
  {
    "objectID": "pages/support/index_support.html",
    "href": "pages/support/index_support.html",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "Cette section est dédiée aux procédures et processus permettant d’apporter un support global aux personnelles de l’UMR. Cela va aussi bien de l’aide à la configuration de certains logiciels (comme les clients lourds de messagerie) ou encore des processus plus généraux comme la mise en place de solution de sauvegarde quotidienne ou encore par exemple des suggestions pour la gestion des mots de passe.\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Support global"
    ]
  },
  {
    "objectID": "pages/packages_logiciels/index_packages_logiciels.html",
    "href": "pages/packages_logiciels/index_packages_logiciels.html",
    "title": "Ressources et supports du Dispositif d’Écologie Numérique (DEN)",
    "section": "",
    "text": "Vous trouverez dans cette section tous les packages, logiciels ou de manière générale les ressources informatiques developés ou utilisés par les personnels et partenaires associés de l’UMR MARBEC.\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Packages et logiciels"
    ]
  },
  {
    "objectID": "pages/packages_logiciels/r_package_sparck.html",
    "href": "pages/packages_logiciels/r_package_sparck.html",
    "title": "Package R sparck",
    "section": "",
    "text": "Le package sparck est un package développé pour le logiciel R. Ses objectifs sont de fournir des fonctions et processus standradrisés permettant, de manière générale, d’appuyer le travail des personnes de l’UMR et pas extension de ses partenaires. Les fonctions associées vont aussi bien de sujets comme la manipulation de données, l’analyse de données ou encore la configuration de l’environnement de travail. Loin de l’idée d’aborder de manière exhaustive l’ensemble des thématiques ou sujets, sa vocation est vraiment d’apporter un standard en termes de développement afin d’améliorer la transversalité des actions et améliorer les liens associés.\nEn lien notamment avec la section “Je veux contribuer !”, n’hesitez pas à jeter un coup d’oeil à la documentation générale mais aussi la section issues du dépôt GitHub.",
    "crumbs": [
      "Liens utiles",
      "Packages et logiciels",
      "Package R sparck"
    ]
  },
  {
    "objectID": "pages/packages_logiciels/r_package_sparck.html#support-package-for-analysis-research-collaboration-and-knowledge",
    "href": "pages/packages_logiciels/r_package_sparck.html#support-package-for-analysis-research-collaboration-and-knowledge",
    "title": "Package R sparck",
    "section": "",
    "text": "Le package sparck est un package développé pour le logiciel R. Ses objectifs sont de fournir des fonctions et processus standradrisés permettant, de manière générale, d’appuyer le travail des personnes de l’UMR et pas extension de ses partenaires. Les fonctions associées vont aussi bien de sujets comme la manipulation de données, l’analyse de données ou encore la configuration de l’environnement de travail. Loin de l’idée d’aborder de manière exhaustive l’ensemble des thématiques ou sujets, sa vocation est vraiment d’apporter un standard en termes de développement afin d’améliorer la transversalité des actions et améliorer les liens associés.\nEn lien notamment avec la section “Je veux contribuer !”, n’hesitez pas à jeter un coup d’oeil à la documentation générale mais aussi la section issues du dépôt GitHub.",
    "crumbs": [
      "Liens utiles",
      "Packages et logiciels",
      "Package R sparck"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/basic_command.html",
    "href": "pages/serveurs/marbec_gpu/basic_command.html",
    "title": "Main commands in marbec-gpu Terminal",
    "section": "",
    "text": "Main commands in marbec-gpu Terminal\nThe first thing to keep in mind is that marbec-gpu has Ubuntu installed, so the commands listed below will be the same as the ones used in that OS. This article will show a description of the main usage modes for each command, but if you have any additional requirements, you can always search in forums like Stackoverflow or check the help for each command, which consists of placing the command name followed by --help. For example, if I want to know the help for the ls command, just run ls --help in the Terminal.\n\n\n\n\n\n\nNoteUpper and lower case\n\n\n\nAs in R or Python, the use of upper or lower case when indicating an option does matter. For example, ls -D is not equivalent to ls -d, so be carefull.\n\n\n\nBrowsing within folders\n\nCommand: cd\nUsage: cd path/folder\n\nTo indicate a previous position (folder), you will use the statement .. as follows: ../path/folder1 (this indicates that there is a folder called path from the folder where you are, and that that has a folder called folder1 as well).\n\n\nCreate a folder\n\nCommand: mkdir\nUsage: mkdir path/folder\n\n\n\nGet the content of a folder as a list\n\nCommand: ls\nUsage: ls path/folder/\n\nMain options:\n\n--all (o -a): Displays all files and subfolders, including those protected (hidden) by the system.\n\n\n\nGenerate a list of files/folders and display the size of each item\n\nCommand: du\nUsage: du path/to/file.csv o du path/to/folder\n\nMain options:\n\n--human-readable (o -h): changes the units dynamically to avoid displaying all Kb. This is especially useful when you have large objects (subfolders or files).\n--summary (o -s): displays a summary table, i.e. it only includes the subfolders and files present at the first search level. This is useful when we just want to take a quick look and avoid displaying a complete listing of ALL internal subfolders.\n\nIf I want to get a list of all the files and folders inside a folder with their respective sizes (the three options are equivalent):\ndu ruta/de/folder/* --human-readable --summarize\ndu ruta/de/folder/* -h -s\ndu ruta/de/folder/* -hs\n\n\nCopy-paste\nFor this, the simplest way is through the cp command and making use of the navigation commands cited in this post (e.g. .. to indicate a previous folder). The basic syntax is the following: cp path/origin /path/destination, but there are different possible cases:\n\nCopy a file into the same folder, but with a different name (create duplicate): cp file1.csv file1-dup.csv.\nCopy a file to another folder: cp path/file1.csv path/destination.\nCopy more than one file to another folder: cp path/file1.csv path/file2.csv folder/destination\nCopy a folder to another folder: cp path/folder1 path/folder2 --recursive or cp path/folder1 path/folder2 -r.\n\n\n\n\n\n\n\nNote\n\n\n\nBy default, cp will overwrite any file with the same name. To avoid this, it is possible to add the -n option as follows: cp path/from/file1.csv path/destination -n.\n\n\n\n\nCut-paste (and also rename)\nIt will be very similar to the above, but through the mv command:\n\nRename a file (within the same folder): mv file1.csv file2.csv\nMove a file to another folder: mv path/file1.csv path/to/destination\nMove one file to another folder: mv path/file1.csv path/file2.csv path/destination\nMove one folder to another folder: mv path/old/folder path/new/folder\n\n\n\nDelete\nFor this, we will use the rm command as follows:\n\nDelete a file: rm path/to/file.csv\nDelete a folder (and all its contents): rm path/to/folder -r\n\n\n\n\n\n\n\nCautionNo turning back\n\n\n\nWhile inside Terminal it is always possible to cancel a command using the shortcut Ctrl+C (or Cmd+C on MacOS), once the rm command completes its work, there is no way to revert the deletion or recover it from a recycle garbage can, so be very careful when using it.\n\n\n\n\nDisplay current processes\n\nCommand: top\n\nWhen you run it, it will show in interactive mode in Terminal the processes that are running, as well as the resources used by each of them (basically like a Task Manager). To exit this interactive mode, just press the q key.\n\n\nStop a process\nIf we want to force the closing or the cancellation of a process already started, we can use the shortcut Ctrl+C (or Cmd+C in MacOS). It is important to keep in mind that forcing the closing of a process that had in progress the handling of files or folders (creation, copy, etc.) can leave the generated files unusable.\n\n\nViewing a plain text file\nBy default, there are two tools available from Terminal: vi and nano. The syntax for their execution is as simple as vi path/file1.txt or nano path/file1.txt, where file1.txt can be any plain text file (e.g. an R or Python script). The navigation shortcuts within each of these environments are different, but documentation is abundant on the Internet. Choose the one you like best.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Guide des Commandes Utiles"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/wich_ressource.html",
    "href": "pages/serveurs/marbec_gpu/wich_ressource.html",
    "title": "Choisir les Ressources : CPUs / MEM / GPU",
    "section": "",
    "text": "Si vous avez suivi les guides précédents, vous avez déjà appris à soumettre un job SLURM. Maintenant, il est temps de choisir les ressources appropriées pour votre job. Le point est brièvement abordé dans le FAD.\nMARBEC-GPU est une ressource partagée avec une grande liberté d’utilisation (pas de quota d’heure de calcul ou nombre de jobs simultanés) et un ordonnancement simple : premier arrivé.e, premier servi.e. Il est donc primordial de correctement choisir les ressources allouées.\nIMPORTANT : Le temps d’exécution d’un job dépend de plusieurs facteurs, notamment la taille de vos données, des ressources utilisées mais principalement de la manière dont vous avez écrit votre code ou/et des packages utilisés. La plupart des codes ne permettent pas de paralléliser les calculs (utiliser plusieurs curs CPU en même) et encore moins de les exécuter sur GPU. Ainsi, quand bien même vous demandez 10 coeurs CPU et un GPU, il est tout à fait possible que votre job n’utilise qu’un seul coeur CPU et sans toucher au GPU. Ensuite, prendre deux fois plus de CPU ne diminue pas par deux le temps d’exécution, à vous de tester et de trouver un bon compromis entre ressources allouées et temps d’exécution.\n\n\n\nSe renseigner sur le code exécuté\n\nAvant d’exécuter votre job sur MARBEC-GPU, vérifiez si votre code parallélise les calculs et/ou utilise le GPU. Si vous apercevez les paramètres comme : “workers”, “n_jobs”, “n_cpus”, “device” ou “gpu” dans la documentation, c’est un bon signe que le code peut paralléliser les calculs et/ou utiliser le GPU. Vous pouvez aussi vous rendre sur la documentation des packages utilisés (pour des packages couramment utilisés, les LLM sauront vous répondre, pour des packages ou langages niche n’hésitez pas à demander à l’auteur/autrice). Si vous ne trouvez pas ces paramètres, il est probable que le code n’utilise pas ces ressources.\n\nChoisir les ressources allouées\n\nCPU : Si votre code parallélise les calculs, vous pouvez allouer plusieurs coeurs CPU. Pour des utilisations classiques en Python ou R pour du machine-learning, de l’extraction de données, etc., choisir entre 2 et 16 coeurs CPU est souvent suffisant. Pour des utilisations plus spécifiques\nMEM : Les quantité de RAM demandée dépend principalement de la taille de vos données et/ou la taille des modèles utilisés. Pour des utilisations classiques, entre 8 et 64 Go de RAM est souvent suffisant. Pour des traitements de données plus lourds, vous pouvez aller jusqu’à 256 Go de RAM.\nGPU : Si votre code utilise le GPU, vous pouvez allouer 1 GPU.\n\nVérifier l’utilisation des ressources\n\nUne allocation parfaite est une allocation où 100% des ressources sont utilisées. Lorsque votre job est terminé, il est possible de vérifier le pourcentage d’utilisation effective des ressources allouées avec la commande reportseff --user &lt;username&gt; (pour plus d’informations sur la commande faites reportseff --help)\n\n\n\n\n\n\nNote\n\n\n\nAttention les jobs de session (nomées pawner-jupyterhub) apparaissent aussi dans le reportseff, vous pouvez les ignorer.\n\n\nEnsuite, ajustez en fonction de l’utilisation effective et du temps de calcul les prochaines allocations.\nSi malgré tout vous avez des doutes, n’hésitez pas à demander de l’aide sur le RocketChatIRD.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Choisir les Ressources : CPUs / MEM / GPU"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/wich_ressource.html#bonnes-pratiques",
    "href": "pages/serveurs/marbec_gpu/wich_ressource.html#bonnes-pratiques",
    "title": "Choisir les Ressources : CPUs / MEM / GPU",
    "section": "",
    "text": "Se renseigner sur le code exécuté\n\nAvant d’exécuter votre job sur MARBEC-GPU, vérifiez si votre code parallélise les calculs et/ou utilise le GPU. Si vous apercevez les paramètres comme : “workers”, “n_jobs”, “n_cpus”, “device” ou “gpu” dans la documentation, c’est un bon signe que le code peut paralléliser les calculs et/ou utiliser le GPU. Vous pouvez aussi vous rendre sur la documentation des packages utilisés (pour des packages couramment utilisés, les LLM sauront vous répondre, pour des packages ou langages niche n’hésitez pas à demander à l’auteur/autrice). Si vous ne trouvez pas ces paramètres, il est probable que le code n’utilise pas ces ressources.\n\nChoisir les ressources allouées\n\nCPU : Si votre code parallélise les calculs, vous pouvez allouer plusieurs coeurs CPU. Pour des utilisations classiques en Python ou R pour du machine-learning, de l’extraction de données, etc., choisir entre 2 et 16 coeurs CPU est souvent suffisant. Pour des utilisations plus spécifiques\nMEM : Les quantité de RAM demandée dépend principalement de la taille de vos données et/ou la taille des modèles utilisés. Pour des utilisations classiques, entre 8 et 64 Go de RAM est souvent suffisant. Pour des traitements de données plus lourds, vous pouvez aller jusqu’à 256 Go de RAM.\nGPU : Si votre code utilise le GPU, vous pouvez allouer 1 GPU.\n\nVérifier l’utilisation des ressources\n\nUne allocation parfaite est une allocation où 100% des ressources sont utilisées. Lorsque votre job est terminé, il est possible de vérifier le pourcentage d’utilisation effective des ressources allouées avec la commande reportseff --user &lt;username&gt; (pour plus d’informations sur la commande faites reportseff --help)\n\n\n\n\n\n\nNote\n\n\n\nAttention les jobs de session (nomées pawner-jupyterhub) apparaissent aussi dans le reportseff, vous pouvez les ignorer.\n\n\nEnsuite, ajustez en fonction de l’utilisation effective et du temps de calcul les prochaines allocations.\nSi malgré tout vous avez des doutes, n’hésitez pas à demander de l’aide sur le RocketChatIRD.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Choisir les Ressources : CPUs / MEM / GPU"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/marbec-data_folders.html",
    "href": "pages/serveurs/marbec_gpu/marbec-data_folders.html",
    "title": "🚀 Accéder aux dossiers de MARBEC-DATA dans JupyterHub",
    "section": "",
    "text": "Le serveur MARBEC-DATA est dédié au stockage des données et est connecté au serveur MARBEC-GPU, qui sert pour les calculs.\nLes dossiers stockés dans MARBEC-DATA sont toujours accessibles en ligne de commande\n🔍 Vous pouvez voir les dossiers disponibles en tapant :\nls /marbec-data/\nou naviguer directement vers un dossier spécifique :\ncd /marbec-data/&lt;your_folder&gt;\nCependant, ces dossiers n’apparaissent pas directement dans l’arborescence des fichiers.\nPour les voir dans l’explorateur de fichiers de Jupyter, il faut créer un lien symbolique.\n\n\n\nOuvrir un terminal dans JupyterHub.\nSe positionner dans l’endroit où vous voulez voir apparaître le dossier :\n\ncd /home/your_username/\n\nCréer le lien symbolique, le nom de votre dossier dans MARBEC-DATA :\n\nln -s /marbec-data/&lt;your_folder&gt;\n\nActualiser l’interface de Jupyter pour voir le dossier apparaître.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Accéder aux dossiers de MARBEC-DATA"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/marbec-data_folders.html#créer-un-lien-symbolique",
    "href": "pages/serveurs/marbec_gpu/marbec-data_folders.html#créer-un-lien-symbolique",
    "title": "🚀 Accéder aux dossiers de MARBEC-DATA dans JupyterHub",
    "section": "",
    "text": "Ouvrir un terminal dans JupyterHub.\nSe positionner dans l’endroit où vous voulez voir apparaître le dossier :\n\ncd /home/your_username/\n\nCréer le lien symbolique, le nom de votre dossier dans MARBEC-DATA :\n\nln -s /marbec-data/&lt;your_folder&gt;\n\nActualiser l’interface de Jupyter pour voir le dossier apparaître.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU",
      "Accéder aux dossiers de MARBEC-DATA"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/index_marbec_gpu.html",
    "href": "pages/serveurs/marbec_gpu/index_marbec_gpu.html",
    "title": "Documentation Marbec-GPU",
    "section": "",
    "text": "Bienvenue dans la documentation du cluster Marbec-GPU. Ce document fournit un aperçu du cluster, de ses capacités et des guides disponibles pour apprendre à bien l’utiliser.\nLe cluster Marbec-GPU est conçu pour fournir des ressources informatiques de hautes performances pour l’exécution de code, Python et R notamment. Il est basé sur le noyau Linux-Ubuntu et dispose d’une interface Jupyter pour faciliter son utilisation. Plusieurs outils y sont installés, notamment Python, R, Git, Conda, CUDA et RStudio.\n\n\n\nRessources\n\n2 NVIDIA A40 GPUs\n2 Intel Xeon Platinum 8380 CPUs, 2x40 cores, 2x80 threads\n1,48 To de RAM\nInterconnexions MARBEC-DATA\n\n\n\n\n\nPour commencer à utiliser le cluster Marbec-GPU, vous devrez rejoindre le groupe Marbec-DEN. Contactez les Administrateurs pour plus de détails : Contacts administrateurs DEN\n\n\n\nPour des instructions détaillées sur l’utilisation du cluster Marbec-GPU, veuillez vous référer aux sections suivantes :\n\nGuide d’initiation (arrive bientôt)\nGuide des Commandes Linux utiles (english only)\nExécution d’un Script Basique R/Python (via SLURM)\nExécution R (english only)\nChoisir les Ressource : CPUs / MEM / GPU\n\n\n\n\nSi vous rencontrez des problèmes ou avez des questions, veillez intéragir avec le RocketChatIRD.\n\n\n\n\nDe quelles ressources ai-je besoin d’allouer?\n\nBonne question ! Cela dépend de vos données d’entrée (taille et type), de votre modèle (stochastique, statistique, réseau de neurones, etc.), de votre tâche mais surtout des packages utilisés. Par exmple, certains packages ne permettent pas de faire les calculs sur GPU, d’autres ne peuvent pas paralléliser sur plusieurs CPU. Renseigner vous donc sur les packages pour ne pas allouer des ressources qui ne seront pas utlisées et adaptez vos script en conséquent. Quelques exemples d’allocation : Entraînement Pytorch YOLO : --mem=64G, --c=16 et --gres=gpu:1 ; Exécution HSMC (TensorFlow) : --mem=64GB, --cpus-per-task=30 et --gpus-per-node=1\n\nMon script est-il compatible GPU ?\n\nNon, pas directement. Cependant, certaines bibliothèques sont compatibles GPU. Si votre framework ou script n’utilise pas spécifiquement le GPU, votre code NE tirera PAS parti du matériel GPU. Principaux exemples de bibliothèques compatibles GPU : PyTorch, TensorFlow, Keras, Theano, Caffe, etc.\n\nComment annuler un job soumis ?\n\nUtilisez la commande scancel JOBID, où JOBID est l’identifiant du job que vous souhaitez annuler. Vous pouvez trouver l’identifiant du job dans la sortie de la commande sbatch lorsque vous soumettez un job, ou en utilisant la commande squeue comme mentionné dans la question précédente, pour plus de details documentation SLURM scancel.\n\nComment accéder à la file d’attente des jobs ?\n\nUtilisez la commande suivante : squeue -O NAME,UserName,TimeUsed,tres-per-node,state,JOBID. Cette commande affiche une liste détaillée des jobs en attente, y compris le nom du job (par exemple, spawner-jupyterhub dessigne une “session-job”; sinon, le nom spécifié dans l’argument #SBATCH --job-name), le nom d’utilisateur, le temps d’exécution, le nom du noeud (eg., gres:gpu:1 pour une allocation GPU, gres:gpu:0 pour une allocation CPU), l’état du job (par exemple, PENDING pour les jobs en attente de démarrage en raison de la disponibilité des ressources ou de la planification, ou RUNNING pour les jobs en cours d’exécution) et JOBID (un identifiant unique pour chaque job), se référer à la documentation SLURM squeue pour plus de détails.\n\nComment soumettre plusieurs jobs sans bloquer les autres utilisateurs ?\n\nToute la communauté MarbecGPU vous remercie pour votre démarche coopérative et amicale. Vous pouvez utiliser le paramètre #SBATCH --dependency=afterany:JOBID, où JOBID est l’identifiant du job que vous souhaitez attendre (par exemple, 4391). Vous pouvez trouver l’identifiant du job dans la sortie de la commande sbatch lorsque vous soumettez un job, ou en utilisant la commande squeue comme mentionné dans la question précédente. Selon la documentation SLURM sbatch ce paramètre garantit que le démarrage de votre job est différé jusqu’à ce que la dépendance spécifiée soit satisfaite. Pour des dépendances basées sur des fichiers ou des cas plus complexes, vous pouvez explorer d’autres mécanismes pour retarder ou séquencer l’exécution de votre job selon vos besoins.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#caractéristiques",
    "href": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#caractéristiques",
    "title": "Documentation Marbec-GPU",
    "section": "",
    "text": "Ressources\n\n2 NVIDIA A40 GPUs\n2 Intel Xeon Platinum 8380 CPUs, 2x40 cores, 2x80 threads\n1,48 To de RAM\nInterconnexions MARBEC-DATA",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#inscription",
    "href": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#inscription",
    "title": "Documentation Marbec-GPU",
    "section": "",
    "text": "Pour commencer à utiliser le cluster Marbec-GPU, vous devrez rejoindre le groupe Marbec-DEN. Contactez les Administrateurs pour plus de détails : Contacts administrateurs DEN",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#documentation",
    "href": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#documentation",
    "title": "Documentation Marbec-GPU",
    "section": "",
    "text": "Pour des instructions détaillées sur l’utilisation du cluster Marbec-GPU, veuillez vous référer aux sections suivantes :\n\nGuide d’initiation (arrive bientôt)\nGuide des Commandes Linux utiles (english only)\nExécution d’un Script Basique R/Python (via SLURM)\nExécution R (english only)\nChoisir les Ressource : CPUs / MEM / GPU",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#support",
    "href": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#support",
    "title": "Documentation Marbec-GPU",
    "section": "",
    "text": "Si vous rencontrez des problèmes ou avez des questions, veillez intéragir avec le RocketChatIRD.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#faq_french",
    "href": "pages/serveurs/marbec_gpu/index_marbec_gpu.html#faq_french",
    "title": "Documentation Marbec-GPU",
    "section": "",
    "text": "De quelles ressources ai-je besoin d’allouer?\n\nBonne question ! Cela dépend de vos données d’entrée (taille et type), de votre modèle (stochastique, statistique, réseau de neurones, etc.), de votre tâche mais surtout des packages utilisés. Par exmple, certains packages ne permettent pas de faire les calculs sur GPU, d’autres ne peuvent pas paralléliser sur plusieurs CPU. Renseigner vous donc sur les packages pour ne pas allouer des ressources qui ne seront pas utlisées et adaptez vos script en conséquent. Quelques exemples d’allocation : Entraînement Pytorch YOLO : --mem=64G, --c=16 et --gres=gpu:1 ; Exécution HSMC (TensorFlow) : --mem=64GB, --cpus-per-task=30 et --gpus-per-node=1\n\nMon script est-il compatible GPU ?\n\nNon, pas directement. Cependant, certaines bibliothèques sont compatibles GPU. Si votre framework ou script n’utilise pas spécifiquement le GPU, votre code NE tirera PAS parti du matériel GPU. Principaux exemples de bibliothèques compatibles GPU : PyTorch, TensorFlow, Keras, Theano, Caffe, etc.\n\nComment annuler un job soumis ?\n\nUtilisez la commande scancel JOBID, où JOBID est l’identifiant du job que vous souhaitez annuler. Vous pouvez trouver l’identifiant du job dans la sortie de la commande sbatch lorsque vous soumettez un job, ou en utilisant la commande squeue comme mentionné dans la question précédente, pour plus de details documentation SLURM scancel.\n\nComment accéder à la file d’attente des jobs ?\n\nUtilisez la commande suivante : squeue -O NAME,UserName,TimeUsed,tres-per-node,state,JOBID. Cette commande affiche une liste détaillée des jobs en attente, y compris le nom du job (par exemple, spawner-jupyterhub dessigne une “session-job”; sinon, le nom spécifié dans l’argument #SBATCH --job-name), le nom d’utilisateur, le temps d’exécution, le nom du noeud (eg., gres:gpu:1 pour une allocation GPU, gres:gpu:0 pour une allocation CPU), l’état du job (par exemple, PENDING pour les jobs en attente de démarrage en raison de la disponibilité des ressources ou de la planification, ou RUNNING pour les jobs en cours d’exécution) et JOBID (un identifiant unique pour chaque job), se référer à la documentation SLURM squeue pour plus de détails.\n\nComment soumettre plusieurs jobs sans bloquer les autres utilisateurs ?\n\nToute la communauté MarbecGPU vous remercie pour votre démarche coopérative et amicale. Vous pouvez utiliser le paramètre #SBATCH --dependency=afterany:JOBID, où JOBID est l’identifiant du job que vous souhaitez attendre (par exemple, 4391). Vous pouvez trouver l’identifiant du job dans la sortie de la commande sbatch lorsque vous soumettez un job, ou en utilisant la commande squeue comme mentionné dans la question précédente. Selon la documentation SLURM sbatch ce paramètre garantit que le démarrage de votre job est différé jusqu’à ce que la dépendance spécifiée soit satisfaite. Pour des dépendances basées sur des fichiers ou des cas plus complexes, vous pouvez explorer d’autres mécanismes pour retarder ou séquencer l’exécution de votre job selon vos besoins.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec GPU"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/manage_files.html",
    "href": "pages/serveurs/marbec_data/manage_files.html",
    "title": "Managing files from/to marbec-data",
    "section": "",
    "text": "Image credits: Declan Sun at Unplash",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA",
      "Gestion des Fichiers"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/manage_files.html#create-a-shared-work-folder",
    "href": "pages/serveurs/marbec_data/manage_files.html#create-a-shared-work-folder",
    "title": "Managing files from/to marbec-data",
    "section": "Create a shared work folder",
    "text": "Create a shared work folder\n[Content in preparation]",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA",
      "Gestion des Fichiers"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/manage_files.html#linking-a-working-folder-to-marbec-gpu.",
    "href": "pages/serveurs/marbec_data/manage_files.html#linking-a-working-folder-to-marbec-gpu.",
    "title": "Managing files from/to marbec-data",
    "section": "Linking a working folder to marbec-gpu.",
    "text": "Linking a working folder to marbec-gpu.\n[Content in preparation]",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA",
      "Gestion des Fichiers"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/manage_files.html#managing-files-between-marbec-data-and-our-pc-filezilla",
    "href": "pages/serveurs/marbec_data/manage_files.html#managing-files-between-marbec-data-and-our-pc-filezilla",
    "title": "Managing files from/to marbec-data",
    "section": "Managing files between marbec-data and our PC (FileZilla)",
    "text": "Managing files between marbec-data and our PC (FileZilla)\n\nInstalling FileZilla and connecting to marbec-data.\nThe easiest way to move (copy, cut and paste) files from our PC to one of our shared work folders or to our marbec-gpu user folder is through the (free) FileZilla software. To download the installer, just go to its official website https://filezilla-project.org/ and select the Download FileZilla Client button.\n\nThen, by default we will be offered to download the version corresponding to the operating system (OS) where we are running our browser, but we can always choose the most appropriate version in the section More download options.\n\n\n\n\n\n\n\nCautionOperating systems and CPU architectures\n\n\n\nIn recent years, processors with ARM architecture have been incorporated into the PC market. The most recent and famous example is Apple’s Mx series (e.g. M1); however, in recent months laptops with ARM processors (from the Snapdragon brand, for instance) have also appeared. Software compiled for an ARM architecture will not work on an x86 architecture (which is the architecture manufactured by brands such as Intel or AMD) and vice versa, so it will always be important to know not only which OS our PC is running (Windows, MacOS or Linux), but also the architecture of our processor.\n\n\nOnce the file has been downloaded, it will be enough to run it leaving most of the options by default (except those that offer us to install some additional program that we do not need, e.g. Chrome). After that, we will be able to run the program and we will obtain an environment that will look like this:\n\nThe next thing we will do is to establish a connection to marbec-data. To do this, at the top, we will fill in the following fields:\n\nServer: marbec-data.ird.fr\nUser: youruser\nPassword: yourpassword\nPort: 22\n\nIf all goes well, a message indicating that the connection has been successful will be displayed in the panel immediately below. In addition, the next two lower panels to the right will show those folders already linked and available in our marbec-data account.\n\n\n\n\n\n\n\nNote\n\n\n\nIt is not necessary to log in every time we log back into FileZilla. We could save our login and skip the above steps by clicking the small arrow to the right of Quick Login and selecting our saved login. Of course, allowing our login credentials to be saved should ONLY occur on our personal PC.\n\n\n\nAnd that is all! In the left panels, we will be able to navigate in the directories of our PC, while in the right panels we will be able to do it in the marbec-gpu and marbec-data ones.\n\n\nCopying files and folders\nIt will be as simple as dragging the element between the left and right panels. The process will start and the bottom pane (the last one) will show the queued, completed and failed transfers.\n\nAlso, if at any time FileZilla detects that there are repeated items, it will show a small window with multiple options available (overwrite and skip, verify differences in sizes or names, apply the selected option to future cases in the transfer queue, etc.).",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA",
      "Gestion des Fichiers"
    ]
  },
  {
    "objectID": "pages/serveurs/marbec_data/manage_files.html#manage-files-within-marbec-data.",
    "href": "pages/serveurs/marbec_data/manage_files.html#manage-files-within-marbec-data.",
    "title": "Managing files from/to marbec-data",
    "section": "Manage files within marbec-data.",
    "text": "Manage files within marbec-data.\nWhile the marbec-data web environment explorer offers the options to copy, paste, delete, etc., it is not an efficient method when our files are medium or large (&gt;10 MB). Here is how to perform these operations from Terminal.\n\nCopy-paste\nFor this, the simplest way is through the cp command and making use of the navigation commands cited in this post (e.g. .. to indicate a previous folder). The basic syntax is the following: cp path/origin /path/destination, but there are different possible cases:\n\nCopy a file into the same folder, but with a different name (create duplicate): cp file1.csv file1-dup.csv.\nCopy a file to another folder: cp path/file1.csv path/destination.\nCopy more than one file to another folder: cp path/file1.csv path/file2.csv folder/destination\nCopy a folder to another folder: cp path/folder1 path/folder2 --recursive or cp path/folder1 path/folder2 -r.\n\n\n\n\n\n\n\nNote\n\n\n\nBy default, cp will overwrite any file with the same name. To avoid this, it is possible to add the -n option as follows: cp path/from/file1.csv path/destination -n.\n\n\n\n\nCut-paste (and also rename)\nIt will be very similar to the above, but through the mv command:\n\nRename a file (within the same folder): mv file1.csv file2.csv\nMove a file to another folder: mv path/file1.csv path/to/destination\nMove one file to another folder: mv path/file1.csv path/file2.csv path/destination\nMove one folder to another folder: mv path/old/folder path/new/folder\n\n\n\nDelete\nFor this, we will use the rm command as follows:\n\nDelete a file: rm path/to/file.csv\nDelete a folder (and all its contents): rm path/to/folder -r\n\n\n\n\n\n\n\nCautionNo turning back\n\n\n\nWhile inside Terminal it is always possible to cancel a command using the shortcut Ctrl+C (or Cmd+C on MacOS), once the rm command completes its work, there is no way to revert the deletion or recover it from a recycle garbage can, so be very careful when using it.",
    "crumbs": [
      "Liens utiles",
      "Serveurs",
      "Marbec DATA",
      "Gestion des Fichiers"
    ]
  }
]